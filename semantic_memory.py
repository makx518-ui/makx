"""
ConsciousAI v5.0 - Semantic Memory
–°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å - —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –∑—ë—Ä–µ–Ω

–ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- –•—Ä–∞–Ω–µ–Ω–∏–µ –∑—ë—Ä–µ–Ω –≤ –≥—Ä–∞—Ñ-—Å—Ç—Ä—É–∫—Ç—É—Ä–µ
- –ê—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–≤—è–∑—ã–≤–∞–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –∑—ë—Ä–µ–Ω
- –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –±–µ–∑ —Ç—è–∂—ë–ª—ã—Ö –º–æ–¥–µ–ª–µ–π
"""

import json
import sqlite3
from typing import List, Dict, Any, Optional, Set, Tuple
from datetime import datetime, timedelta
from collections import defaultdict
import math

from semantic_kernel import SemanticKernel, KernelType, SemanticCompressor


class SemanticMemory:
    """
    –°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å - –≥—Ä–∞—Ñ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –∑—ë—Ä–µ–Ω

    –§—É–Ω–∫—Ü–∏–∏:
    1. –•—Ä–∞–Ω–µ–Ω–∏–µ –∑—ë—Ä–µ–Ω
    2. –ü–æ–∏—Å–∫ –ø–æ —Å–º—ã—Å–ª—É (–∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫)
    3. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–≤—è–∑—ã–≤–∞–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –∑—ë—Ä–µ–Ω
    4. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç—å—é (–∑–∞–±—ã–≤–∞–Ω–∏–µ –Ω–µ–≤–∞–∂–Ω–æ–≥–æ)
    """

    def __init__(self, db_path: str = "semantic_memory.db"):
        self.db_path = db_path
        self.compressor = SemanticCompressor()
        self._init_database()

    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # –¢–∞–±–ª–∏—Ü–∞ –∑—ë—Ä–µ–Ω
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS kernels (
                id TEXT PRIMARY KEY,
                essence TEXT NOT NULL,
                concepts TEXT NOT NULL,
                kernel_type TEXT NOT NULL,
                importance REAL NOT NULL,
                timestamp TEXT NOT NULL,
                activation_count INTEGER DEFAULT 0,
                last_accessed TEXT,
                metadata TEXT
            )
        ''')

        # –¢–∞–±–ª–∏—Ü–∞ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∑—ë—Ä–Ω–∞–º–∏
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS connections (
                kernel_id TEXT NOT NULL,
                connected_kernel_id TEXT NOT NULL,
                strength REAL DEFAULT 1.0,
                connection_type TEXT,
                created_at TEXT NOT NULL,
                PRIMARY KEY (kernel_id, connected_kernel_id),
                FOREIGN KEY (kernel_id) REFERENCES kernels(id),
                FOREIGN KEY (connected_kernel_id) REFERENCES kernels(id)
            )
        ''')

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_importance ON kernels(importance DESC)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON kernels(timestamp DESC)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_type ON kernels(kernel_type)')

        conn.commit()
        conn.close()

    def store(self, kernel: SemanticKernel, auto_connect: bool = True) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–µ—Ä–Ω–æ –≤ –ø–∞–º—è—Ç—å

        Args:
            kernel: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –∑–µ—Ä–Ω–æ
            auto_connect: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞—Ç—å —Å –ø–æ—Ö–æ–∂–∏–º–∏ –∑—ë—Ä–Ω–∞–º–∏

        Returns:
            ID —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ –∑–µ—Ä–Ω–∞
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT OR REPLACE INTO kernels
            (id, essence, concepts, kernel_type, importance, timestamp,
             activation_count, last_accessed, metadata)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            kernel.id,
            kernel.essence,
            json.dumps(kernel.concepts),
            kernel.kernel_type.value,
            kernel.importance,
            kernel.timestamp.isoformat(),
            kernel.activation_count,
            kernel.last_accessed.isoformat() if kernel.last_accessed else None,
            json.dumps(kernel.metadata)
        ))

        conn.commit()
        conn.close()

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞—Ç—å —Å –ø–æ—Ö–æ–∂–∏–º–∏
        if auto_connect:
            self._auto_connect(kernel)

        return kernel.id

    def retrieve(self, kernel_id: str, activate: bool = True) -> Optional[SemanticKernel]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∑–µ—Ä–Ω–æ –ø–æ ID

        Args:
            kernel_id: ID –∑–µ—Ä–Ω–∞
            activate: –£–≤–µ–ª–∏—á–∏—Ç—å —Å—á—ë—Ç—á–∏–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–π

        Returns:
            SemanticKernel –∏–ª–∏ None
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            SELECT id, essence, concepts, kernel_type, importance, timestamp,
                   activation_count, last_accessed, metadata
            FROM kernels WHERE id = ?
        ''', (kernel_id,))

        row = cursor.fetchone()

        if not row:
            conn.close()
            return None

        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–µ—Ä–Ω–æ
        kernel = self._row_to_kernel(row)

        # –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å
        if activate:
            kernel.activate()
            cursor.execute('''
                UPDATE kernels
                SET activation_count = ?, last_accessed = ?
                WHERE id = ?
            ''', (kernel.activation_count, kernel.last_accessed.isoformat(), kernel.id))
            conn.commit()

        conn.close()
        return kernel

    def search(
        self,
        query: str,
        limit: int = 10,
        min_importance: float = 0.3,
        kernel_types: Optional[List[KernelType]] = None
    ) -> List[Tuple[SemanticKernel, float]]:
        """
        –ê—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∑—ë—Ä–µ–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            min_importance: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –∑—ë—Ä–µ–Ω
            kernel_types: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø–∞–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –°–ø–∏—Å–æ–∫ (–∑–µ—Ä–Ω–æ, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å) –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        """
        # –°–∂–∞—Ç—å –∑–∞–ø—Ä–æ—Å –≤ –∑–µ—Ä–Ω–æ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        query_kernel = self.compressor.compress(query)

        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑—ë—Ä–Ω–∞ (—Ñ–∏–ª—å—Ç—Ä—É—è –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ —Ç–∏–ø—É)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        sql = 'SELECT * FROM kernels WHERE importance >= ?'
        params = [min_importance]

        if kernel_types:
            type_placeholders = ','.join('?' * len(kernel_types))
            sql += f' AND kernel_type IN ({type_placeholders})'
            params.extend([kt.value for kt in kernel_types])

        cursor.execute(sql, params)
        rows = cursor.fetchall()
        conn.close()

        # –í—ã—á–∏—Å–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–µ—Ä–Ω–∞
        results = []
        for row in rows:
            kernel = self._row_to_kernel(row)
            relevance = self._calculate_relevance(query_kernel, kernel)
            results.append((kernel, relevance))

        # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        results.sort(key=lambda x: x[1], reverse=True)

        return results[:limit]

    def find_similar(
        self,
        kernel: SemanticKernel,
        limit: int = 5,
        min_similarity: float = 0.3
    ) -> List[Tuple[SemanticKernel, float]]:
        """
        –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ –∑—ë—Ä–Ω–∞

        Args:
            kernel: –ò—Å—Ö–æ–¥–Ω–æ–µ –∑–µ—Ä–Ω–æ
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            min_similarity: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ

        Returns:
            –°–ø–∏—Å–æ–∫ (–∑–µ—Ä–Ω–æ, —Å—Ö–æ–¥—Å—Ç–≤–æ)
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑—ë—Ä–Ω–∞ –∫—Ä–æ–º–µ —Å–µ–±—è
        cursor.execute('SELECT * FROM kernels WHERE id != ?', (kernel.id,))
        rows = cursor.fetchall()
        conn.close()

        # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ
        results = []
        for row in rows:
            other_kernel = self._row_to_kernel(row)
            similarity = self._calculate_similarity(kernel, other_kernel)

            if similarity >= min_similarity:
                results.append((other_kernel, similarity))

        # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å
        results.sort(key=lambda x: x[1], reverse=True)

        return results[:limit]

    def connect(
        self,
        kernel_id1: str,
        kernel_id2: str,
        strength: float = 1.0,
        connection_type: str = "related"
    ):
        """
        –°–æ–∑–¥–∞—Ç—å —Å–≤—è–∑—å –º–µ–∂–¥—É –¥–≤—É–º—è –∑—ë—Ä–Ω–∞–º–∏

        Args:
            kernel_id1: ID –ø–µ—Ä–≤–æ–≥–æ –∑–µ—Ä–Ω–∞
            kernel_id2: ID –≤—Ç–æ—Ä–æ–≥–æ –∑–µ—Ä–Ω–∞
            strength: –°–∏–ª–∞ —Å–≤—è–∑–∏ (0.0 - 1.0)
            connection_type: –¢–∏–ø —Å–≤—è–∑–∏ (related, causes, depends_on, etc.)
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT OR REPLACE INTO connections
            (kernel_id, connected_kernel_id, strength, connection_type, created_at)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            kernel_id1,
            kernel_id2,
            strength,
            connection_type,
            datetime.now().isoformat()
        ))

        # –°–æ–∑–¥–∞—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å (–≥—Ä–∞—Ñ –Ω–µ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
        cursor.execute('''
            INSERT OR REPLACE INTO connections
            (kernel_id, connected_kernel_id, strength, connection_type, created_at)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            kernel_id2,
            kernel_id1,
            strength,
            connection_type,
            datetime.now().isoformat()
        ))

        conn.commit()
        conn.close()

    def get_connected(self, kernel_id: str, min_strength: float = 0.3) -> List[Tuple[SemanticKernel, float]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∑—ë—Ä–Ω–∞

        Args:
            kernel_id: ID –∑–µ—Ä–Ω–∞
            min_strength: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∏–ª–∞ —Å–≤—è–∑–∏

        Returns:
            –°–ø–∏—Å–æ–∫ (–∑–µ—Ä–Ω–æ, —Å–∏–ª–∞ —Å–≤—è–∑–∏)
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            SELECT k.*, c.strength
            FROM connections c
            JOIN kernels k ON c.connected_kernel_id = k.id
            WHERE c.kernel_id = ? AND c.strength >= ?
            ORDER BY c.strength DESC
        ''', (kernel_id, min_strength))

        rows = cursor.fetchall()
        conn.close()

        results = []
        for row in rows:
            kernel = self._row_to_kernel(row[:-1])  # –ü–æ—Å–ª–µ–¥–Ω–µ–µ –ø–æ–ª–µ - strength
            strength = row[-1]
            results.append((kernel, strength))

        return results

    def forget_unimportant(self, days_old: int = 30, importance_threshold: float = 0.3):
        """
        –ó–∞–±—ã—Ç—å —Å—Ç–∞—Ä—ã–µ –Ω–µ–≤–∞–∂–Ω—ã–µ –∑—ë—Ä–Ω–∞ (–æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏)

        Args:
            days_old: –£–¥–∞–ª–∏—Ç—å –∑—ë—Ä–Ω–∞ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
            importance_threshold: –£–¥–∞–ª–∏—Ç—å –∑—ë—Ä–Ω–∞ —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞
        """
        cutoff_date = datetime.now() - timedelta(days=days_old)

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –Ω–µ–≤–∞–∂–Ω—ã–µ –∑—ë—Ä–Ω–∞
        cursor.execute('''
            DELETE FROM kernels
            WHERE importance < ? AND timestamp < ?
        ''', (importance_threshold, cutoff_date.isoformat()))

        deleted_count = cursor.rowcount

        # –£–¥–∞–ª–∏—Ç—å —Å–≤—è–∑–∏ —Å —É–¥–∞–ª—ë–Ω–Ω—ã–º–∏ –∑—ë—Ä–Ω–∞–º–∏
        cursor.execute('''
            DELETE FROM connections
            WHERE kernel_id NOT IN (SELECT id FROM kernels)
               OR connected_kernel_id NOT IN (SELECT id FROM kernels)
        ''')

        conn.commit()
        conn.close()

        return deleted_count

    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞–º—è—Ç–∏"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # –í—Å–µ–≥–æ –∑—ë—Ä–µ–Ω
        cursor.execute('SELECT COUNT(*) FROM kernels')
        total_kernels = cursor.fetchone()[0]

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º
        cursor.execute('''
            SELECT kernel_type, COUNT(*)
            FROM kernels
            GROUP BY kernel_type
        ''')
        type_distribution = dict(cursor.fetchall())

        # –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å
        cursor.execute('SELECT AVG(importance) FROM kernels')
        avg_importance = cursor.fetchone()[0] or 0

        # –í—Å–µ–≥–æ —Å–≤—è–∑–µ–π
        cursor.execute('SELECT COUNT(*) FROM connections')
        total_connections = cursor.fetchone()[0]

        # –¢–æ–ø –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º—ã—Ö –∑—ë—Ä–µ–Ω
        cursor.execute('''
            SELECT id, essence, activation_count
            FROM kernels
            ORDER BY activation_count DESC
            LIMIT 5
        ''')
        top_activated = cursor.fetchall()

        conn.close()

        return {
            "total_kernels": total_kernels,
            "total_connections": total_connections,
            "type_distribution": type_distribution,
            "average_importance": avg_importance,
            "top_activated": [
                {"id": row[0], "essence": row[1], "activations": row[2]}
                for row in top_activated
            ]
        }

    def _auto_connect(self, kernel: SemanticKernel):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞—Ç—å –∑–µ—Ä–Ω–æ —Å –ø–æ—Ö–æ–∂–∏–º–∏"""
        similar = self.find_similar(kernel, limit=5, min_similarity=0.5)

        for similar_kernel, similarity in similar:
            self.connect(
                kernel.id,
                similar_kernel.id,
                strength=similarity,
                connection_type="similar"
            )

    def _calculate_similarity(self, kernel1: SemanticKernel, kernel2: SemanticKernel) -> float:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –∑—ë—Ä–Ω–∞–º–∏

        –ú–µ—Ç–æ–¥—ã:
        1. –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π (–ñ–∞–∫–∫–∞—Ä–∞)
        2. –°—Ö–æ–∂–µ—Å—Ç—å —Ç–∏–ø–∞
        3. –ë–ª–∏–∑–æ—Å—Ç—å –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        """
        similarity = 0.0

        # 1. –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π (–≤–µ—Å 70%)
        concepts1 = set(kernel1.concepts)
        concepts2 = set(kernel2.concepts)

        if concepts1 or concepts2:
            intersection = len(concepts1 & concepts2)
            union = len(concepts1 | concepts2)
            jaccard = intersection / union if union > 0 else 0
            similarity += jaccard * 0.7

        # 2. –°—Ö–æ–∂–µ—Å—Ç—å —Ç–∏–ø–∞ (–≤–µ—Å 20%)
        if kernel1.kernel_type == kernel2.kernel_type:
            similarity += 0.2

        # 3. –ë–ª–∏–∑–æ—Å—Ç—å –≤–∞–∂–Ω–æ—Å—Ç–∏ (–≤–µ—Å 10%)
        importance_diff = abs(kernel1.importance - kernel2.importance)
        importance_similarity = 1 - importance_diff
        similarity += importance_similarity * 0.1

        return min(similarity, 1.0)

    def _calculate_relevance(self, query_kernel: SemanticKernel, target_kernel: SemanticKernel) -> float:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–µ—Ä–Ω–∞ –∫ –∑–∞–ø—Ä–æ—Å—É

        –£—á–∏—Ç—ã–≤–∞–µ—Ç:
        1. –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        2. –í–∞–∂–Ω–æ—Å—Ç—å –∑–µ—Ä–Ω–∞
        3. –ß–∞—Å—Ç–æ—Ç—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        """
        relevance = 0.0

        # 1. –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π (–≤–µ—Å 60%)
        query_concepts = set(query_kernel.concepts)
        target_concepts = set(target_kernel.concepts)

        if query_concepts:
            intersection = len(query_concepts & target_concepts)
            concept_score = intersection / len(query_concepts)
            relevance += concept_score * 0.6

        # 2. –í–∞–∂–Ω–æ—Å—Ç—å (–≤–µ—Å 30%)
        relevance += target_kernel.importance * 0.3

        # 3. –ß–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–≤–µ—Å 10%)
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å activation_count (–ª–æ–≥–∞—Ä–∏—Ñ–º –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è)
        activation_score = min(math.log(target_kernel.activation_count + 1) / 5, 1.0)
        relevance += activation_score * 0.1

        return min(relevance, 1.0)

    def _row_to_kernel(self, row: Tuple) -> SemanticKernel:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É –ë–î –≤ SemanticKernel"""
        return SemanticKernel(
            id=row[0],
            essence=row[1],
            concepts=json.loads(row[2]),
            kernel_type=KernelType(row[3]),
            importance=row[4],
            timestamp=datetime.fromisoformat(row[5]),
            activation_count=row[6],
            last_accessed=datetime.fromisoformat(row[7]) if row[7] else None,
            metadata=json.loads(row[8]) if row[8] else {}
        )


class KnowledgeGraph:
    """
    –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∑—ë—Ä–Ω–∞–º–∏

    –ú–µ—Ç–æ–¥—ã:
    - –û–±—Ö–æ–¥ –≥—Ä–∞—Ñ–∞
    - –ü–æ–∏—Å–∫ –ø—É—Ç–µ–π –º–µ–∂–¥—É –∑—ë—Ä–Ω–∞–º–∏
    - –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ—Ö–æ–∂–∏—Ö –∑—ë—Ä–µ–Ω
    """

    def __init__(self, memory: SemanticMemory):
        self.memory = memory

    def find_path(
        self,
        start_kernel_id: str,
        end_kernel_id: str,
        max_depth: int = 5
    ) -> Optional[List[str]]:
        """
        –ù–∞–π—Ç–∏ –ø—É—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –∑—ë—Ä–Ω–∞–º–∏ (BFS)

        Args:
            start_kernel_id: –ù–∞—á–∞–ª—å–Ω–æ–µ –∑–µ—Ä–Ω–æ
            end_kernel_id: –ö–æ–Ω–µ—á–Ω–æ–µ –∑–µ—Ä–Ω–æ
            max_depth: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –ø–æ–∏—Å–∫–∞

        Returns:
            –°–ø–∏—Å–æ–∫ ID –∑—ë—Ä–µ–Ω –≤ –ø—É—Ç–∏ –∏–ª–∏ None
        """
        if start_kernel_id == end_kernel_id:
            return [start_kernel_id]

        visited = set()
        queue = [(start_kernel_id, [start_kernel_id])]

        while queue:
            current_id, path = queue.pop(0)

            if len(path) > max_depth:
                continue

            if current_id in visited:
                continue

            visited.add(current_id)

            # –ü–æ–ª—É—á–∏—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∑—ë—Ä–Ω–∞
            connected = self.memory.get_connected(current_id)

            for kernel, _ in connected:
                if kernel.id == end_kernel_id:
                    return path + [kernel.id]

                if kernel.id not in visited:
                    queue.append((kernel.id, path + [kernel.id]))

        return None

    def get_clusters(self, min_cluster_size: int = 3) -> List[List[SemanticKernel]]:
        """
        –ù–∞–π—Ç–∏ –∫–ª–∞—Å—Ç–µ—Ä—ã –ø–æ—Ö–æ–∂–∏—Ö –∑—ë—Ä–µ–Ω

        Args:
            min_cluster_size: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–∫–∞–∂–¥—ã–π –∫–ª–∞—Å—Ç–µ—Ä - —Å–ø–∏—Å–æ–∫ –∑—ë—Ä–µ–Ω)
        """
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑—ë—Ä–Ω–∞
        conn = sqlite3.connect(self.memory.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM kernels')
        rows = cursor.fetchall()
        conn.close()

        kernels = [self.memory._row_to_kernel(row) for row in rows]

        # –ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ —Ç–∏–ø—É –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º
        clusters_dict = defaultdict(list)

        for kernel in kernels:
            # –ö–ª—é—á –∫–ª–∞—Å—Ç–µ—Ä–∞: —Ç–∏–ø + —Ç–æ–ø-2 –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
            cluster_key = (
                kernel.kernel_type.value,
                tuple(sorted(kernel.concepts[:2]))
            )
            clusters_dict[cluster_key].append(kernel)

        # –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –º–∞–ª–µ–Ω—å–∫–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã
        clusters = [
            cluster for cluster in clusters_dict.values()
            if len(cluster) >= min_cluster_size
        ]

        return clusters


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üß† Semantic Memory - –°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å\n")

    # –°–æ–∑–¥–∞—Ç—å –ø–∞–º—è—Ç—å
    memory = SemanticMemory(db_path="test_memory.db")
    compressor = SemanticCompressor()

    # –ü—Ä–∏–º–µ—Ä 1: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑—ë—Ä–Ω–∞
    print("–ü—Ä–∏–º–µ—Ä 1: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑—ë—Ä–µ–Ω")

    messages = [
        "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç —Å–æ–∑–¥–∞—Ç—å AI —Å –º–µ—Ç–∞-—Å–æ–∑–Ω–∞–Ω–∏–µ–º",
        "–†–µ—à–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏–∑ 5 —Å–ª–æ—ë–≤",
        "–°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å —Å–∂–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ 20-50 —Ä–∞–∑",
        "–ù—É–∂–µ–Ω –ø—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å",
        "AI –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ 24/7"
    ]

    kernel_ids = []
    for msg in messages:
        kernel = compressor.compress(msg, language="ru")
        kernel_id = memory.store(kernel)
        kernel_ids.append(kernel_id)
        print(f"  ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {kernel.essence[:50]}...")

    # –ü—Ä–∏–º–µ—Ä 2: –ü–æ–∏—Å–∫
    print("\n–ü—Ä–∏–º–µ—Ä 2: –ê—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫")
    results = memory.search("–∞–≤—Ç–æ–Ω–æ–º–Ω–∞—è —Ä–∞–±–æ—Ç–∞ AI", limit=3)
    for kernel, relevance in results:
        print(f"  üìå [{relevance:.2f}] {kernel.essence}")

    # –ü—Ä–∏–º–µ—Ä 3: –ü–æ—Ö–æ–∂–∏–µ –∑—ë—Ä–Ω–∞
    print("\n–ü—Ä–∏–º–µ—Ä 3: –ü–æ—Ö–æ–∂–∏–µ –∑—ë—Ä–Ω–∞")
    first_kernel = memory.retrieve(kernel_ids[0])
    similar = memory.find_similar(first_kernel, limit=3)
    for kernel, similarity in similar:
        print(f"  üîó [{similarity:.2f}] {kernel.essence}")

    # –ü—Ä–∏–º–µ—Ä 4: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n–ü—Ä–∏–º–µ—Ä 4: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏")
    stats = memory.get_statistics()
    print(f"  –í—Å–µ–≥–æ –∑—ë—Ä–µ–Ω: {stats['total_kernels']}")
    print(f"  –í—Å–µ–≥–æ —Å–≤—è–∑–µ–π: {stats['total_connections']}")
    print(f"  –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å: {stats['average_importance']:.2f}")
    print(f"  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º: {stats['type_distribution']}")

    # –ü—Ä–∏–º–µ—Ä 5: –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π
    print("\n–ü—Ä–∏–º–µ—Ä 5: –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π")
    graph = KnowledgeGraph(memory)
    if len(kernel_ids) >= 2:
        path = graph.find_path(kernel_ids[0], kernel_ids[-1])
        if path:
            print(f"  –ü—É—Ç—å –Ω–∞–π–¥–µ–Ω: {len(path)} —à–∞–≥–æ–≤")
        else:
            print("  –ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω")

    print("\n‚úÖ –°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å —Ä–∞–±–æ—Ç–∞–µ—Ç!")
