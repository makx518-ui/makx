=== ConsciousAI v5.1 - –ü–û–õ–ù–´–ô –ö–û–î –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê GPT-5 ===

–°–¢–†–£–ö–¢–£–†–ê –ü–ê–ö–ï–¢–ê:
conscious_ai/__init__.py
conscious_ai/core/__init__.py
conscious_ai/interface/__init__.py
conscious_ai/memory/__init__.py
conscious_ai/memory/base.py
conscious_ai/memory/sqlite_store.py
conscious_ai/reasoning/__init__.py
conscious_ai/utils/__init__.py
conscious_ai/utils/exceptions.py
conscious_ai/utils/logger.py

======================================
–§–ê–ô–õ: conscious_ai/__init__.py
======================================
"""
ConsciousAI v5.1 - –ú–µ—Ç–∞-–°–æ–∑–Ω–∞—Ç–µ–ª—å–Ω—ã–π AI
–ï–¥–∏–Ω—ã–π –ø–∞–∫–µ—Ç —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –°–æ–∑–¥–∞—Ç—å –µ–¥–∏–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–º—ë–Ω

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
‚îú‚îÄ‚îÄ core/        - –Ø–¥—Ä–æ —Å–∏—Å—Ç–µ–º—ã (Pipeline, AI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä)
‚îú‚îÄ‚îÄ memory/      - –°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å (–∑—ë—Ä–Ω–∞, —Ö—Ä–∞–Ω–∏–ª–∏—â–∞)
‚îú‚îÄ‚îÄ reasoning/   - –†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è (–º–µ—Ç–∞-–∫–æ–≥–Ω–∏—Ü–∏—è, –∏–Ω—Å–∞–π—Ç—ã)
‚îú‚îÄ‚îÄ interface/   - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
‚îî‚îÄ‚îÄ utils/       - –£—Ç–∏–ª–∏—Ç—ã (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, –æ—à–∏–±–∫–∏)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    from conscious_ai import ConsciousAI
    ai = ConsciousAI()
    response = await ai.think("–ß—Ç–æ —Ç–∞–∫–æ–µ —Å–æ–∑–Ω–∞–Ω–∏–µ?")

    # –ò–ª–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    from conscious_ai.memory import SemanticKernel, InMemoryStore
    from conscious_ai.utils import get_logger, ConsciousAIError
"""

__version__ = "5.1.0"
__author__ = "Claude & GPT-5 Collaboration"
__license__ = "MIT"

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –ø–æ–¥–º–æ–¥—É–ª–µ–π
from .utils import (
    get_logger,
    set_log_level,
    ConsciousAIError,
    handle_error,
    safe_execute,
)

from .memory import (
    KernelType,
    SemanticKernel,
    SearchQuery,
    SearchResult,
    BaseMemoryStore,
    InMemoryStore,
)

# –õ–µ–Ω–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Ç—è–∂—ë–ª—ã—Ö –º–æ–¥—É–ª–µ–π
def get_memory_store(store_type: str = "memory", **kwargs):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø–∞–º—è—Ç–∏

    Args:
        store_type: "memory", "sqlite", "vector"
        **kwargs: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ö—Ä–∞–Ω–∏–ª–∏—â–∞

    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä BaseMemoryStore

    –ü—Ä–∏–º–µ—Ä:
        store = get_memory_store("memory")
        store = get_memory_store("sqlite", db_path="memory.db")
    """
    if store_type == "memory":
        return InMemoryStore()
    elif store_type == "sqlite":
        # TODO: –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å SQLiteMemoryStore –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤
        from .memory.sqlite_store import SQLiteMemoryStore
        return SQLiteMemoryStore(**kwargs)
    else:
        raise ValueError(f"Unknown store type: {store_type}")


# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–∫–µ—Ç–µ
def info():
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–∫–µ—Ç–µ"""
    print(f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë           üß† ConsciousAI v{__version__}                      ‚ïë
‚ïë                                                       ‚ïë
‚ïë  –ú–µ—Ç–∞-–°–æ–∑–Ω–∞—Ç–µ–ª—å–Ω—ã–π AI —Å —Å–º—ã—Å–ª–æ–≤–æ–π –ø–∞–º—è—Ç—å—é           ‚ïë
‚ïë                                                       ‚ïë
‚ïë  –ú–æ–¥—É–ª–∏:                                              ‚ïë
‚ïë  ‚Ä¢ memory/    - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –∑—ë—Ä–Ω–∞ –∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞     ‚ïë
‚ïë  ‚Ä¢ reasoning/ - –ú–µ—Ç–∞-–∫–æ–≥–Ω–∏—Ü–∏—è –∏ –∏–Ω—Å–∞–π—Ç—ã             ‚ïë
‚ïë  ‚Ä¢ core/      - –Ø–¥—Ä–æ –∏ Pipeline                      ‚ïë
‚ïë  ‚Ä¢ interface/ - CLI –∏ –∫–æ–º–∞–Ω–¥—ã                        ‚ïë
‚ïë  ‚Ä¢ utils/     - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—à–∏–±–∫–∏                ‚ïë
‚ïë                                                       ‚ïë
‚ïë  –ê–≤—Ç–æ—Ä—ã: {__author__}              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)


__all__ = [
    # –í–µ—Ä—Å–∏—è
    '__version__',
    '__author__',
    # –£—Ç–∏–ª–∏—Ç—ã
    'get_logger',
    'set_log_level',
    'ConsciousAIError',
    'handle_error',
    'safe_execute',
    # –ü–∞–º—è—Ç—å
    'KernelType',
    'SemanticKernel',
    'SearchQuery',
    'SearchResult',
    'BaseMemoryStore',
    'InMemoryStore',
    'get_memory_store',
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    'info',
]


======================================
–§–ê–ô–õ: conscious_ai/utils/logger.py
======================================
"""
ConsciousAI - –ï–¥–∏–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
–¶–≤–µ—Ç–Ω–æ–π –≤—ã–≤–æ–¥ + —Ñ–∞–π–ª–æ–≤–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ + —É—Ä–æ–≤–Ω–∏

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –í–≤–µ—Å—Ç–∏ –µ–¥–∏–Ω—ã–π –º–æ–¥—É–ª—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
"""

import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional


class ColoredFormatter(logging.Formatter):
    """–§–æ—Ä–º–∞—Ç—Ç–µ—Ä —Å —Ü–≤–µ—Ç–Ω—ã–º –≤—ã–≤–æ–¥–æ–º –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª"""

    # ANSI —Ü–≤–µ—Ç–∞
    COLORS = {
        'DEBUG': '\033[36m',     # Cyan
        'INFO': '\033[32m',      # Green
        'WARNING': '\033[33m',   # Yellow
        'ERROR': '\033[31m',     # Red
        'CRITICAL': '\033[35m',  # Magenta
        'RESET': '\033[0m',
        'BOLD': '\033[1m',
    }

    def format(self, record: logging.LogRecord) -> str:
        # –î–æ–±–∞–≤–∏—Ç—å —Ü–≤–µ—Ç–∞ –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞–ª–∞
        color = self.COLORS.get(record.levelname, '')
        reset = self.COLORS['RESET']
        bold = self.COLORS['BOLD']

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å timestamp
        timestamp = datetime.fromtimestamp(record.created).strftime('%H:%M:%S')

        # –ö–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –º–æ–¥—É–ª—è
        module = record.name.split('.')[-1][:15]

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        formatted = (
            f"{color}{bold}[{timestamp}]{reset} "
            f"{color}[{record.levelname:8}]{reset} "
            f"[{module:15}] "
            f"{record.getMessage()}"
        )

        # –î–æ–±–∞–≤–∏—Ç—å exception info –µ—Å–ª–∏ –µ—Å—Ç—å
        if record.exc_info:
            formatted += f"\n{self.formatException(record.exc_info)}"

        return formatted


class FileFormatter(logging.Formatter):
    """–§–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è —Ñ–∞–π–ª–æ–≤–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–±–µ–∑ —Ü–≤–µ—Ç–æ–≤)"""

    def format(self, record: logging.LogRecord) -> str:
        timestamp = datetime.fromtimestamp(record.created).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]

        formatted = (
            f"[{timestamp}] "
            f"[{record.levelname:8}] "
            f"[{record.name:30}] "
            f"{record.getMessage()}"
        )

        if record.exc_info:
            formatted += f"\n{self.formatException(record.exc_info)}"

        return formatted


class AILogger:
    """
    –ï–¥–∏–Ω—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è ConsciousAI

    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        from conscious_ai.utils.logger import get_logger

        logger = get_logger(__name__)
        logger.info("–°–æ–æ–±—â–µ–Ω–∏–µ")
        logger.error("–û—à–∏–±–∫–∞", exc_info=True)
    """

    _instance: Optional['AILogger'] = None
    _initialized: bool = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not AILogger._initialized:
            self._setup_root_logger()
            AILogger._initialized = True

    def _setup_root_logger(self):
        """–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä"""
        # –ü–æ–ª—É—á–∏—Ç—å –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä –¥–ª—è conscious_ai
        self.root_logger = logging.getLogger('conscious_ai')
        self.root_logger.setLevel(logging.DEBUG)

        # –û—á–∏—Å—Ç–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ handlers
        self.root_logger.handlers.clear()

        # Console handler (—Ü–≤–µ—Ç–Ω–æ–π)
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(ColoredFormatter())
        self.root_logger.addHandler(console_handler)

        # File handler (–ø–æ–ª–Ω—ã–π –ª–æ–≥)
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)

        log_file = log_dir / f"conscious_ai_{datetime.now().strftime('%Y%m%d')}.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(FileFormatter())
        self.root_logger.addHandler(file_handler)

        # –ù–µ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –ª–æ–≥–∏ –≤ –∫–æ—Ä–Ω–µ–≤–æ–π logger Python
        self.root_logger.propagate = False

    def get_logger(self, name: str) -> logging.Logger:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ª–æ–≥–≥–µ—Ä –¥–ª—è –º–æ–¥—É–ª—è

        Args:
            name: –ò–º—è –º–æ–¥—É–ª—è (__name__)

        Returns:
            –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ª–æ–≥–≥–µ—Ä
        """
        # –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –∏–º—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å conscious_ai
        if not name.startswith('conscious_ai'):
            name = f'conscious_ai.{name}'

        return logging.getLogger(name)

    def set_level(self, level: str):
        """
        –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

        Args:
            level: DEBUG, INFO, WARNING, ERROR, CRITICAL
        """
        level_map = {
            'DEBUG': logging.DEBUG,
            'INFO': logging.INFO,
            'WARNING': logging.WARNING,
            'ERROR': logging.ERROR,
            'CRITICAL': logging.CRITICAL
        }

        log_level = level_map.get(level.upper(), logging.INFO)
        self.root_logger.setLevel(log_level)

        # –û–±–Ω–æ–≤–∏—Ç—å console handler
        for handler in self.root_logger.handlers:
            if isinstance(handler, logging.StreamHandler) and not isinstance(handler, logging.FileHandler):
                handler.setLevel(log_level)

    def add_file_handler(self, filepath: str, level: str = 'DEBUG'):
        """
        –î–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª–æ–≤—ã–π handler

        Args:
            filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            level: –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        handler = logging.FileHandler(filepath, encoding='utf-8')
        handler.setLevel(getattr(logging, level.upper(), logging.DEBUG))
        handler.setFormatter(FileFormatter())
        self.root_logger.addHandler(handler)


# Singleton instance
_logger_instance = AILogger()


def get_logger(name: str) -> logging.Logger:
    """
    –ü–æ–ª—É—á–∏—Ç—å –ª–æ–≥–≥–µ—Ä –¥–ª—è –º–æ–¥—É–ª—è

    Args:
        name: –ò–º—è –º–æ–¥—É–ª—è (–æ–±—ã—á–Ω–æ __name__)

    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ª–æ–≥–≥–µ—Ä

    –ü—Ä–∏–º–µ—Ä:
        logger = get_logger(__name__)
        logger.info("AI –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.debug("–î–µ—Ç–∞–ª–∏ –æ—Ç–ª–∞–¥–∫–∏")
        logger.warning("–í–Ω–∏–º–∞–Ω–∏–µ!")
        logger.error("–û—à–∏–±–∫–∞!", exc_info=True)
    """
    return _logger_instance.get_logger(name)


def set_log_level(level: str):
    """
    –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

    Args:
        level: DEBUG, INFO, WARNING, ERROR, CRITICAL
    """
    _logger_instance.set_level(level)


# –£–¥–æ–±–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
def log_info(message: str):
    """–ë—ã—Å—Ç—Ä–æ–µ INFO —Å–æ–æ–±—â–µ–Ω–∏–µ"""
    get_logger('quick').info(message)


def log_error(message: str, exc_info: bool = False):
    """–ë—ã—Å—Ç—Ä–æ–µ ERROR —Å–æ–æ–±—â–µ–Ω–∏–µ"""
    get_logger('quick').error(message, exc_info=exc_info)


def log_debug(message: str):
    """–ë—ã—Å—Ç—Ä–æ–µ DEBUG —Å–æ–æ–±—â–µ–Ω–∏–µ"""
    get_logger('quick').debug(message)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–æ–∑–¥–∞—Ç—å –ª–æ–≥–≥–µ—Ä
    logger = get_logger(__name__)

    print("üîß –¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è:\n")

    # –†–∞–∑–ª–∏—á–Ω—ã–µ —É—Ä–æ–≤–Ω–∏
    logger.debug("Debug —Å–æ–æ–±—â–µ–Ω–∏–µ (–Ω–µ –≤–∏–¥–Ω–æ –≤ –∫–æ–Ω—Å–æ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
    logger.info("Info —Å–æ–æ–±—â–µ–Ω–∏–µ - –æ–±—ã—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    logger.warning("Warning - –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ")
    logger.error("Error - –æ—à–∏–±–∫–∞")
    logger.critical("Critical - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞")

    # –° exception
    try:
        raise ValueError("–¢–µ—Å—Ç–æ–≤–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ")
    except Exception:
        logger.error("–ü–æ–π–º–∞–Ω–æ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ", exc_info=True)

    # –ò–∑–º–µ–Ω–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å
    print("\nüìä –ú–µ–Ω—è—é —É—Ä–æ–≤–µ–Ω—å –Ω–∞ DEBUG:")
    set_log_level('DEBUG')
    logger.debug("–¢–µ–ø–µ—Ä—å debug –≤–∏–¥–µ–Ω!")

    print("\n‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
    print("üìÅ –õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø–∞–ø–∫—É logs/")


======================================
–§–ê–ô–õ: conscious_ai/utils/exceptions.py
======================================
"""
ConsciousAI - –ò–µ—Ä–∞—Ä—Ö–∏—è –∏—Å–∫–ª—é—á–µ–Ω–∏–π
–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –°–æ–∑–¥–∞—Ç—å BaseError –∏ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∏ –¥–ª—è –º–æ–¥—É–ª–µ–π
"""

from typing import Optional, Dict, Any


class ConsciousAIError(Exception):
    """
    –ë–∞–∑–æ–≤–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö –æ—à–∏–±–æ–∫ ConsciousAI

    –í—Å–µ –æ—à–∏–±–∫–∏ —Å–∏—Å—Ç–µ–º—ã –Ω–∞—Å–ª–µ–¥—É—é—Ç—Å—è –æ—Ç —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞,
    —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª–æ–≤–∏—Ç—å –≤—Å–µ –æ—à–∏–±–∫–∏ –æ–¥–Ω–∏–º except
    """

    def __init__(
        self,
        message: str,
        error_code: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.message = message
        self.error_code = error_code or "UNKNOWN_ERROR"
        self.details = details or {}
        super().__init__(self.message)

    def __str__(self) -> str:
        base = f"[{self.error_code}] {self.message}"
        if self.details:
            base += f" | Details: {self.details}"
        return base

    def to_dict(self) -> Dict[str, Any]:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—à–∏–±–∫–∏"""
        return {
            "error": self.error_code,
            "message": self.message,
            "details": self.details
        }


# ============================================
# –û–®–ò–ë–ö–ò –ü–ê–ú–Ø–¢–ò (Memory)
# ============================================

class MemoryError(ConsciousAIError):
    """–ë–∞–∑–æ–≤–∞—è –æ—à–∏–±–∫–∞ –º–æ–¥—É–ª—è –ø–∞–º—è—Ç–∏"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, "MEMORY_ERROR", details)


class MemoryStorageError(MemoryError):
    """–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ø–∞–º—è—Ç—å"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, details)
        self.error_code = "MEMORY_STORAGE_ERROR"


class MemoryRetrievalError(MemoryError):
    """–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑ –ø–∞–º—è—Ç–∏"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, details)
        self.error_code = "MEMORY_RETRIEVAL_ERROR"


class MemoryNotFoundError(MemoryError):
    """–ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ø–∞–º—è—Ç–∏"""

    def __init__(self, kernel_id: str):
        super().__init__(
            f"Kernel not found: {kernel_id}",
            {"kernel_id": kernel_id}
        )
        self.error_code = "MEMORY_NOT_FOUND"


class MemoryConnectionError(MemoryError):
    """–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —Ö—Ä–∞–Ω–∏–ª–∏—â—É"""

    def __init__(self, storage_type: str, details: Optional[Dict] = None):
        super().__init__(
            f"Cannot connect to {storage_type} storage",
            details
        )
        self.error_code = "MEMORY_CONNECTION_ERROR"


# ============================================
# –û–®–ò–ë–ö–ò –ú–ï–¢–ê-–ö–û–ì–ù–ò–¶–ò–ò (Meta-Cognitive)
# ============================================

class MetaCognitiveError(ConsciousAIError):
    """–ë–∞–∑–æ–≤–∞—è –æ—à–∏–±–∫–∞ –º–µ—Ç–∞-–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–≥–æ –º–æ–¥—É–ª—è"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, "META_COGNITIVE_ERROR", details)


class ReflectionError(MetaCognitiveError):
    """–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, details)
        self.error_code = "REFLECTION_ERROR"


class SelfEvaluationError(MetaCognitiveError):
    """–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∞–º–æ–æ—Ü–µ–Ω–∫–µ"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, details)
        self.error_code = "SELF_EVALUATION_ERROR"


# ============================================
# –û–®–ò–ë–ö–ò –ò–ù–°–ê–ô–¢–û–í (Insights)
# ============================================

class InsightError(ConsciousAIError):
    """–ë–∞–∑–æ–≤–∞—è –æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, "INSIGHT_ERROR", details)


class InsightGenerationError(InsightError):
    """–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Å–∞–π—Ç"""

    def __init__(self, topic: str, reason: str):
        super().__init__(
            f"Cannot generate insight for '{topic}': {reason}",
            {"topic": topic, "reason": reason}
        )
        self.error_code = "INSIGHT_GENERATION_ERROR"


class AnalogyNotFoundError(InsightError):
    """–ê–Ω–∞–ª–æ–≥–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"""

    def __init__(self, concept: str):
        super().__init__(
            f"No analogy found for concept: {concept}",
            {"concept": concept}
        )
        self.error_code = "ANALOGY_NOT_FOUND"


# ============================================
# –û–®–ò–ë–ö–ò –ò–ù–¢–ï–†–§–ï–ô–°–ê (Interface)
# ============================================

class InterfaceError(ConsciousAIError):
    """–ë–∞–∑–æ–≤–∞—è –æ—à–∏–±–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, "INTERFACE_ERROR", details)


class CommandParseError(InterfaceError):
    """–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–º–∞–Ω–¥—ã"""

    def __init__(self, command: str, reason: str):
        super().__init__(
            f"Cannot parse command '{command}': {reason}",
            {"command": command, "reason": reason}
        )
        self.error_code = "COMMAND_PARSE_ERROR"


class InvalidCommandError(InterfaceError):
    """–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞"""

    def __init__(self, command: str):
        super().__init__(
            f"Unknown command: {command}",
            {"command": command}
        )
        self.error_code = "INVALID_COMMAND"


# ============================================
# –û–®–ò–ë–ö–ò –Ø–î–†–ê (Core)
# ============================================

class CoreError(ConsciousAIError):
    """–ë–∞–∑–æ–≤–∞—è –æ—à–∏–±–∫–∞ —è–¥—Ä–∞ AI"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, "CORE_ERROR", details)


class InitializationError(CoreError):
    """–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã"""

    def __init__(self, component: str, reason: str):
        super().__init__(
            f"Cannot initialize {component}: {reason}",
            {"component": component, "reason": reason}
        )
        self.error_code = "INITIALIZATION_ERROR"


class ConfigurationError(CoreError):
    """–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""

    def __init__(self, param: str, value: Any, expected: str):
        super().__init__(
            f"Invalid configuration: {param}={value}, expected {expected}",
            {"param": param, "value": value, "expected": expected}
        )
        self.error_code = "CONFIGURATION_ERROR"


class PipelineError(CoreError):
    """–û—à–∏–±–∫–∞ –≤ pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏"""

    def __init__(self, stage: str, reason: str):
        super().__init__(
            f"Pipeline failed at stage '{stage}': {reason}",
            {"stage": stage, "reason": reason}
        )
        self.error_code = "PIPELINE_ERROR"


# ============================================
# –û–®–ò–ë–ö–ò –í–ê–õ–ò–î–ê–¶–ò–ò (Validation)
# ============================================

class ValidationError(ConsciousAIError):
    """–ë–∞–∑–æ–≤–∞—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, "VALIDATION_ERROR", details)


class InvalidInputError(ValidationError):
    """–ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""

    def __init__(self, field: str, value: Any, reason: str):
        super().__init__(
            f"Invalid input for '{field}': {reason}",
            {"field": field, "value": str(value)[:100], "reason": reason}
        )
        self.error_code = "INVALID_INPUT"


class MissingRequiredFieldError(ValidationError):
    """–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ"""

    def __init__(self, field: str):
        super().__init__(
            f"Missing required field: {field}",
            {"field": field}
        )
        self.error_code = "MISSING_REQUIRED_FIELD"


# ============================================
# –£–¢–ò–õ–ò–¢–´ –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò –û–®–ò–ë–û–ö
# ============================================

def handle_error(func):
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫

    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        @handle_error
        def risky_function():
            ...
    """
    from functools import wraps
    from .logger import get_logger

    logger = get_logger(func.__module__)

    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except ConsciousAIError as e:
            logger.error(f"ConsciousAI Error in {func.__name__}: {e}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in {func.__name__}: {e}", exc_info=True)
            raise CoreError(
                f"Unexpected error in {func.__name__}: {str(e)}",
                details={"original_error": type(e).__name__}
            ) from e

    return wrapper


def handle_error_async(func):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
    from functools import wraps
    from .logger import get_logger

    logger = get_logger(func.__module__)

    @wraps(func)
    async def wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except ConsciousAIError as e:
            logger.error(f"ConsciousAI Error in {func.__name__}: {e}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in {func.__name__}: {e}", exc_info=True)
            raise CoreError(
                f"Unexpected error in {func.__name__}: {str(e)}",
                details={"original_error": type(e).__name__}
            ) from e

    return wrapper


def safe_execute(func, *args, default=None, **kwargs):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å fallback

    Args:
        func: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        *args: –ê—Ä–≥—É–º–µ–Ω—Ç—ã
        default: –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ
        **kwargs: –ò–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –∏–ª–∏ default
    """
    from .logger import get_logger
    logger = get_logger('safe_execute')

    try:
        return func(*args, **kwargs)
    except Exception as e:
        logger.warning(f"Safe execute caught error: {e}")
        return default


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üîß –¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –∏—Å–∫–ª—é—á–µ–Ω–∏–π:\n")

    # –¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
    try:
        raise ConsciousAIError("–¢–µ—Å—Ç–æ–≤–∞—è –æ—à–∏–±–∫–∞", "TEST_001", {"key": "value"})
    except ConsciousAIError as e:
        print(f"‚úÖ –ë–∞–∑–æ–≤–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
        print(f"   Dict: {e.to_dict()}\n")

    # –¢–µ—Å—Ç –æ—à–∏–±–∫–∏ –ø–∞–º—è—Ç–∏
    try:
        raise MemoryNotFoundError("kernel-123")
    except MemoryError as e:
        print(f"‚úÖ –û—à–∏–±–∫–∞ –ø–∞–º—è—Ç–∏: {e}\n")

    # –¢–µ—Å—Ç –æ—à–∏–±–∫–∏ –∏–Ω—Å–∞–π—Ç–∞
    try:
        raise InsightGenerationError("AI –ø–∞–º—è—Ç—å", "–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö")
    except InsightError as e:
        print(f"‚úÖ –û—à–∏–±–∫–∞ –∏–Ω—Å–∞–π—Ç–∞: {e}\n")

    # –¢–µ—Å—Ç –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞
    @handle_error
    def failing_function():
        raise ValueError("–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞")

    try:
        failing_function()
    except CoreError as e:
        print(f"‚úÖ –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –ø–æ–π–º–∞–ª: {e}\n")

    # –¢–µ—Å—Ç safe_execute
    def divide(a, b):
        return a / b

    result = safe_execute(divide, 10, 0, default=-1)
    print(f"‚úÖ Safe execute: 10/0 = {result} (fallback)\n")

    print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π —Ä–∞–±–æ—Ç–∞–µ—Ç!")


======================================
–§–ê–ô–õ: conscious_ai/memory/base.py
======================================
"""
ConsciousAI - –ë–∞–∑–æ–≤—ã–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –¥–ª—è –ø–∞–º—è—Ç–∏
–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å MemoryStore
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from enum import Enum
import uuid


class KernelType(Enum):
    """–¢–∏–ø—ã —Å–º—ã—Å–ª–æ–≤—ã—Ö –∑—ë—Ä–µ–Ω"""
    FACT = "fact"
    INSIGHT = "insight"
    DECISION = "decision"
    PATTERN = "pattern"
    GOAL = "goal"
    RELATIONSHIP = "relationship"
    PREFERENCE = "preference"
    CONTEXT = "context"
    EMOTION = "emotion"
    REFLECTION = "reflection"


@dataclass
class SemanticKernel:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–º—ã—Å–ª–æ–≤–æ–≥–æ –∑–µ—Ä–Ω–∞

    –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pydantic
    TODO: –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –Ω–∞ pydantic –≤ —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    essence: str = ""
    concepts: List[str] = field(default_factory=list)
    kernel_type: KernelType = KernelType.FACT
    importance: float = 0.5
    connections: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)
    activation_count: int = 0
    last_accessed: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    # –ù–æ–≤—ã–µ –ø–æ–ª—è –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ GPT-5
    ttl: Optional[int] = None  # Time-to-live –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    priority: int = 0  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç (0-10)
    tags: List[str] = field(default_factory=list)  # –¢–µ–≥–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    source: str = "user"  # –ò—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

    def activate(self):
        """–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –∑–µ—Ä–Ω–æ (—É–≤–µ–ª–∏—á–∏—Ç—å —Å—á—ë—Ç—á–∏–∫)"""
        self.activation_count += 1
        self.last_accessed = datetime.now()

    def is_expired(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ç—ë–∫ –ª–∏ TTL"""
        if self.ttl is None:
            return False
        elapsed = (datetime.now() - self.timestamp).total_seconds()
        return elapsed > self.ttl

    def to_dict(self) -> Dict[str, Any]:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        data = asdict(self)
        data['kernel_type'] = self.kernel_type.value
        data['timestamp'] = self.timestamp.isoformat()
        if self.last_accessed:
            data['last_accessed'] = self.last_accessed.isoformat()
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SemanticKernel':
        """–î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        data = data.copy()
        data['kernel_type'] = KernelType(data['kernel_type'])
        data['timestamp'] = datetime.fromisoformat(data['timestamp'])
        if data.get('last_accessed'):
            data['last_accessed'] = datetime.fromisoformat(data['last_accessed'])
        return cls(**data)


@dataclass
class SearchQuery:
    """
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

    –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –î–æ–±–∞–≤–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∏ scoring
    """
    text: str = ""
    concepts: List[str] = field(default_factory=list)
    kernel_types: Optional[List[KernelType]] = None
    min_importance: float = 0.0
    max_importance: float = 1.0
    min_priority: int = 0
    tags: Optional[List[str]] = None
    source: Optional[str] = None
    limit: int = 10
    offset: int = 0
    include_expired: bool = False
    sort_by: str = "relevance"  # relevance, importance, timestamp, activation
    sort_order: str = "desc"


@dataclass
class SearchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞"""
    kernel: SemanticKernel
    score: float  # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å 0-1
    match_reason: str = ""


class BaseMemoryStore(ABC):
    """
    –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–∞–º—è—Ç–∏

    –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –í—Å–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å —ç—Ç–æ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

    –ú–µ—Ç–æ–¥—ã:
        save() - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–µ—Ä–Ω–æ
        get() - –ø–æ–ª—É—á–∏—Ç—å –ø–æ ID
        search() - –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É
        delete() - —É–¥–∞–ª–∏—Ç—å
        update() - –æ–±–Ω–æ–≤–∏—Ç—å
        stats() - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    """

    @abstractmethod
    def save(self, kernel: SemanticKernel) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –∑–µ—Ä–Ω–æ

        Args:
            kernel: –ó–µ—Ä–Ω–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

        Returns:
            ID —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ –∑–µ—Ä–Ω–∞

        Raises:
            MemoryStorageError: –ü—Ä–∏ –æ—à–∏–±–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        pass

    @abstractmethod
    def get(self, kernel_id: str, activate: bool = True) -> Optional[SemanticKernel]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∑–µ—Ä–Ω–æ –ø–æ ID

        Args:
            kernel_id: ID –∑–µ—Ä–Ω–∞
            activate: –£–≤–µ–ª–∏—á–∏—Ç—å —Å—á—ë—Ç—á–∏–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–π

        Returns:
            SemanticKernel –∏–ª–∏ None

        Raises:
            MemoryRetrievalError: –ü—Ä–∏ –æ—à–∏–±–∫–µ —á—Ç–µ–Ω–∏—è
        """
        pass

    @abstractmethod
    def search(self, query: SearchQuery) -> List[SearchResult]:
        """
        –ü–æ–∏—Å–∫ –∑—ë—Ä–µ–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É

        Args:
            query: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

        Returns:
            –°–ø–∏—Å–æ–∫ SearchResult –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ score

        Raises:
            MemoryRetrievalError: –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø–æ–∏—Å–∫–∞
        """
        pass

    @abstractmethod
    def delete(self, kernel_id: str) -> bool:
        """
        –£–¥–∞–ª–∏—Ç—å –∑–µ—Ä–Ω–æ

        Args:
            kernel_id: ID –∑–µ—Ä–Ω–∞

        Returns:
            True –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω–æ, False –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        """
        pass

    @abstractmethod
    def update(self, kernel: SemanticKernel) -> bool:
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –∑–µ—Ä–Ω–æ

        Args:
            kernel: –ó–µ—Ä–Ω–æ —Å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

        Returns:
            True –µ—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–æ, False –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        """
        pass

    @abstractmethod
    def stats(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ö—Ä–∞–Ω–∏–ª–∏—â–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π:
            - total_kernels: int
            - by_type: Dict[str, int]
            - avg_importance: float
            - total_connections: int
            - storage_size_bytes: int
        """
        pass

    @abstractmethod
    def cleanup(self, days_old: int = 30, importance_threshold: float = 0.2) -> int:
        """
        –û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –Ω–µ–≤–∞–∂–Ω—ã–µ –∑—ë—Ä–Ω–∞

        Args:
            days_old: –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
            importance_threshold: –£–¥–∞–ª–∏—Ç—å —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –∑—ë—Ä–µ–Ω
        """
        pass

    def save_batch(self, kernels: List[SemanticKernel]) -> List[str]:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑—ë—Ä–µ–Ω (batch –æ–ø–µ—Ä–∞—Ü–∏—è)

        Args:
            kernels: –°–ø–∏—Å–æ–∫ –∑—ë—Ä–µ–Ω

        Returns:
            –°–ø–∏—Å–æ–∫ ID —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –∑—ë—Ä–µ–Ω

        –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ.
        –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
        """
        return [self.save(k) for k in kernels]

    def get_batch(self, kernel_ids: List[str]) -> List[SemanticKernel]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑—ë—Ä–µ–Ω (batch –æ–ø–µ—Ä–∞—Ü–∏—è)

        Args:
            kernel_ids: –°–ø–∏—Å–æ–∫ ID

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑—ë—Ä–µ–Ω
        """
        results = []
        for kid in kernel_ids:
            kernel = self.get(kid, activate=False)
            if kernel:
                results.append(kernel)
        return results

    def connect(self, kernel_id1: str, kernel_id2: str, strength: float = 1.0) -> bool:
        """
        –°–æ–∑–¥–∞—Ç—å —Å–≤—è–∑—å –º–µ–∂–¥—É –∑—ë—Ä–Ω–∞–º–∏

        Args:
            kernel_id1: ID –ø–µ—Ä–≤–æ–≥–æ –∑–µ—Ä–Ω–∞
            kernel_id2: ID –≤—Ç–æ—Ä–æ–≥–æ –∑–µ—Ä–Ω–∞
            strength: –°–∏–ª–∞ —Å–≤—è–∑–∏ (0-1)

        Returns:
            True –µ—Å–ª–∏ —Å–≤—è–∑—å —Å–æ–∑–¥–∞–Ω–∞
        """
        kernel1 = self.get(kernel_id1, activate=False)
        kernel2 = self.get(kernel_id2, activate=False)

        if not kernel1 or not kernel2:
            return False

        # –î–æ–±–∞–≤–∏—Ç—å —Å–≤—è–∑–∏ (–¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ)
        if kernel_id2 not in kernel1.connections:
            kernel1.connections.append(kernel_id2)
            self.update(kernel1)

        if kernel_id1 not in kernel2.connections:
            kernel2.connections.append(kernel_id1)
            self.update(kernel2)

        return True

    def get_connected(self, kernel_id: str) -> List[SemanticKernel]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∑—ë—Ä–Ω–∞

        Args:
            kernel_id: ID –∑–µ—Ä–Ω–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∑—ë—Ä–µ–Ω
        """
        kernel = self.get(kernel_id, activate=False)
        if not kernel:
            return []

        return self.get_batch(kernel.connections)


class InMemoryStore(BaseMemoryStore):
    """
    In-memory —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

    –ë—ã—Å—Ç—Ä–∞—è, –Ω–æ –Ω–µ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞—è
    """

    def __init__(self):
        self._storage: Dict[str, SemanticKernel] = {}

    def save(self, kernel: SemanticKernel) -> str:
        self._storage[kernel.id] = kernel
        return kernel.id

    def get(self, kernel_id: str, activate: bool = True) -> Optional[SemanticKernel]:
        kernel = self._storage.get(kernel_id)
        if kernel and activate:
            kernel.activate()
        return kernel

    def search(self, query: SearchQuery) -> List[SearchResult]:
        results = []

        for kernel in self._storage.values():
            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏—Å—Ç—ë–∫—à–∏–µ
            if not query.include_expired and kernel.is_expired():
                continue

            # –§–∏–ª—å—Ç—Ä—ã
            if kernel.importance < query.min_importance:
                continue
            if kernel.importance > query.max_importance:
                continue
            if kernel.priority < query.min_priority:
                continue
            if query.kernel_types and kernel.kernel_type not in query.kernel_types:
                continue
            if query.tags and not set(query.tags).intersection(set(kernel.tags)):
                continue
            if query.source and kernel.source != query.source:
                continue

            # –í—ã—á–∏—Å–ª–∏—Ç—å score
            score = self._calculate_score(query, kernel)
            if score > 0:
                results.append(SearchResult(
                    kernel=kernel,
                    score=score,
                    match_reason=f"Score: {score:.2f}"
                ))

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
        if query.sort_by == "relevance":
            results.sort(key=lambda r: r.score, reverse=query.sort_order == "desc")
        elif query.sort_by == "importance":
            results.sort(key=lambda r: r.kernel.importance, reverse=query.sort_order == "desc")
        elif query.sort_by == "timestamp":
            results.sort(key=lambda r: r.kernel.timestamp, reverse=query.sort_order == "desc")
        elif query.sort_by == "activation":
            results.sort(key=lambda r: r.kernel.activation_count, reverse=query.sort_order == "desc")

        # –ü–∞–≥–∏–Ω–∞—Ü–∏—è
        return results[query.offset:query.offset + query.limit]

    def _calculate_score(self, query: SearchQuery, kernel: SemanticKernel) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"""
        score = 0.0

        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        if query.text:
            text_lower = query.text.lower()
            if text_lower in kernel.essence.lower():
                score += 0.5
            # –°–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –≤ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è—Ö
            query_words = set(text_lower.split())
            kernel_concepts = set(c.lower() for c in kernel.concepts)
            overlap = len(query_words.intersection(kernel_concepts))
            if query_words:
                score += (overlap / len(query_words)) * 0.3

        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        if query.concepts:
            query_concepts = set(c.lower() for c in query.concepts)
            kernel_concepts = set(c.lower() for c in kernel.concepts)
            overlap = len(query_concepts.intersection(kernel_concepts))
            if query_concepts:
                score += (overlap / len(query_concepts)) * 0.2

        # –ë–æ–Ω—É—Å –∑–∞ –≤–∞–∂–Ω–æ—Å—Ç—å
        score += kernel.importance * 0.1

        return min(score, 1.0)

    def delete(self, kernel_id: str) -> bool:
        if kernel_id in self._storage:
            del self._storage[kernel_id]
            return True
        return False

    def update(self, kernel: SemanticKernel) -> bool:
        if kernel.id in self._storage:
            self._storage[kernel.id] = kernel
            return True
        return False

    def stats(self) -> Dict[str, Any]:
        total = len(self._storage)
        by_type = {}
        total_importance = 0.0
        total_connections = 0

        for kernel in self._storage.values():
            type_name = kernel.kernel_type.value
            by_type[type_name] = by_type.get(type_name, 0) + 1
            total_importance += kernel.importance
            total_connections += len(kernel.connections)

        return {
            "total_kernels": total,
            "by_type": by_type,
            "avg_importance": total_importance / total if total > 0 else 0,
            "total_connections": total_connections // 2,  # –î–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ
            "storage_size_bytes": 0  # In-memory
        }

    def cleanup(self, days_old: int = 30, importance_threshold: float = 0.2) -> int:
        from datetime import timedelta
        cutoff = datetime.now() - timedelta(days=days_old)
        to_delete = []

        for kid, kernel in self._storage.items():
            if kernel.importance < importance_threshold and kernel.timestamp < cutoff:
                to_delete.append(kid)

        for kid in to_delete:
            del self._storage[kid]

        return len(to_delete)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üß† –¢–µ—Å—Ç –±–∞–∑–æ–≤—ã—Ö –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π –ø–∞–º—è—Ç–∏:\n")

    # –°–æ–∑–¥–∞—Ç—å in-memory —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    store = InMemoryStore()

    # –°–æ–∑–¥–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑—ë—Ä–Ω–∞
    kernel1 = SemanticKernel(
        essence="AI —Å –º–µ—Ç–∞-—Å–æ–∑–Ω–∞–Ω–∏–µ–º",
        concepts=["ai", "–º–µ—Ç–∞", "—Å–æ–∑–Ω–∞–Ω–∏–µ"],
        kernel_type=KernelType.GOAL,
        importance=0.9,
        priority=10,
        tags=["core", "vision"]
    )

    kernel2 = SemanticKernel(
        essence="–°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å —Å–∂–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç",
        concepts=["–ø–∞–º—è—Ç—å", "—Å–∂–∞—Ç–∏–µ", "–∫–æ–Ω—Ç–µ–∫—Å—Ç"],
        kernel_type=KernelType.FACT,
        importance=0.7,
        tags=["memory"]
    )

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
    id1 = store.save(kernel1)
    id2 = store.save(kernel2)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ 2 –∑–µ—Ä–Ω–∞")

    # –ü–æ–∏—Å–∫
    query = SearchQuery(
        text="–º–µ—Ç–∞-—Å–æ–∑–Ω–∞–Ω–∏–µ",
        min_importance=0.5,
        limit=5
    )

    results = store.search(query)
    print(f"\nüîç –ü–æ–∏—Å–∫ '–º–µ—Ç–∞-—Å–æ–∑–Ω–∞–Ω–∏–µ':")
    for res in results:
        print(f"  Score: {res.score:.2f} | {res.kernel.essence}")

    # –°–≤—è–∑–∞—Ç—å
    store.connect(id1, id2)
    print(f"\nüîó –°–æ–∑–¥–∞–Ω–∞ —Å–≤—è–∑—å –º–µ–∂–¥—É –∑—ë—Ä–Ω–∞–º–∏")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = store.stats()
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  –í—Å–µ–≥–æ –∑—ë—Ä–µ–Ω: {stats['total_kernels']}")
    print(f"  –ü–æ —Ç–∏–ø–∞–º: {stats['by_type']}")
    print(f"  –°–≤—è–∑–µ–π: {stats['total_connections']}")

    print("\n‚úÖ –ë–∞–∑–æ–≤—ã–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç!")


======================================
–§–ê–ô–õ: conscious_ai/memory/sqlite_store.py
======================================
"""
ConsciousAI - SQLite —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è MemoryStore
–ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å SQL

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –¥–ª—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
"""

import sqlite3
import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from pathlib import Path

from .base import (
    BaseMemoryStore,
    SemanticKernel,
    SearchQuery,
    SearchResult,
    KernelType,
)
from ..utils import get_logger, MemoryStorageError, MemoryRetrievalError, handle_error

logger = get_logger(__name__)


class SQLiteMemoryStore(BaseMemoryStore):
    """
    SQLite —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–∞–º—è—Ç–∏

    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –Ω–∞ –¥–∏—Å–∫)
    - –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    - –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    - Connection pooling (–≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ)
    """

    def __init__(self, db_path: str = "semantic_memory.db"):
        self.db_path = db_path
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SQLite store: {db_path}")
        self._init_database()

    def _init_database(self):
        """–°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã –∏ –∏–Ω–¥–µ–∫—Å—ã"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # –¢–∞–±–ª–∏—Ü–∞ –∑—ë—Ä–µ–Ω
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS kernels (
                    id TEXT PRIMARY KEY,
                    essence TEXT NOT NULL,
                    concepts TEXT NOT NULL,
                    kernel_type TEXT NOT NULL,
                    importance REAL NOT NULL,
                    priority INTEGER DEFAULT 0,
                    timestamp TEXT NOT NULL,
                    activation_count INTEGER DEFAULT 0,
                    last_accessed TEXT,
                    ttl INTEGER,
                    tags TEXT,
                    source TEXT DEFAULT 'user',
                    metadata TEXT
                )
            ''')

            # –¢–∞–±–ª–∏—Ü–∞ —Å–≤—è–∑–µ–π
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS connections (
                    kernel_id TEXT NOT NULL,
                    connected_id TEXT NOT NULL,
                    strength REAL DEFAULT 1.0,
                    created_at TEXT NOT NULL,
                    PRIMARY KEY (kernel_id, connected_id),
                    FOREIGN KEY (kernel_id) REFERENCES kernels(id) ON DELETE CASCADE,
                    FOREIGN KEY (connected_id) REFERENCES kernels(id) ON DELETE CASCADE
                )
            ''')

            # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_importance ON kernels(importance DESC)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON kernels(timestamp DESC)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_type ON kernels(kernel_type)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_priority ON kernels(priority DESC)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_source ON kernels(source)')

            conn.commit()
            conn.close()
            logger.info("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
            raise MemoryStorageError(f"Cannot initialize database: {e}")

    def _get_connection(self) -> sqlite3.Connection:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.execute("PRAGMA foreign_keys = ON")
            return conn
        except Exception as e:
            raise MemoryStorageError(f"Cannot connect to database: {e}")

    @handle_error
    def save(self, kernel: SemanticKernel) -> str:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–µ—Ä–Ω–æ –≤ SQLite"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('''
                INSERT OR REPLACE INTO kernels
                (id, essence, concepts, kernel_type, importance, priority,
                 timestamp, activation_count, last_accessed, ttl, tags, source, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                kernel.id,
                kernel.essence,
                json.dumps(kernel.concepts),
                kernel.kernel_type.value,
                kernel.importance,
                kernel.priority,
                kernel.timestamp.isoformat(),
                kernel.activation_count,
                kernel.last_accessed.isoformat() if kernel.last_accessed else None,
                kernel.ttl,
                json.dumps(kernel.tags),
                kernel.source,
                json.dumps(kernel.metadata)
            ))

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–≤—è–∑–∏
            for connected_id in kernel.connections:
                cursor.execute('''
                    INSERT OR IGNORE INTO connections (kernel_id, connected_id, created_at)
                    VALUES (?, ?, ?)
                ''', (kernel.id, connected_id, datetime.now().isoformat()))

            conn.commit()
            logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∑–µ—Ä–Ω–æ: {kernel.id[:8]}...")
            return kernel.id

        finally:
            conn.close()

    @handle_error
    def get(self, kernel_id: str, activate: bool = True) -> Optional[SemanticKernel]:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–µ—Ä–Ω–æ –ø–æ ID"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('SELECT * FROM kernels WHERE id = ?', (kernel_id,))
            row = cursor.fetchone()

            if not row:
                return None

            # –ü–æ–ª—É—á–∏—Ç—å —Å–≤—è–∑–∏
            cursor.execute(
                'SELECT connected_id FROM connections WHERE kernel_id = ?',
                (kernel_id,)
            )
            connections = [r[0] for r in cursor.fetchall()]

            kernel = self._row_to_kernel(row, connections)

            # –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å
            if activate:
                kernel.activate()
                cursor.execute('''
                    UPDATE kernels
                    SET activation_count = ?, last_accessed = ?
                    WHERE id = ?
                ''', (kernel.activation_count, kernel.last_accessed.isoformat(), kernel.id))
                conn.commit()

            return kernel

        finally:
            conn.close()

    @handle_error
    def search(self, query: SearchQuery) -> List[SearchResult]:
        """–ü–æ–∏—Å–∫ –∑—ë—Ä–µ–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å SQL –∑–∞–ø—Ä–æ—Å
            sql = 'SELECT * FROM kernels WHERE 1=1'
            params = []

            # –§–∏–ª—å—Ç—Ä –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            sql += ' AND importance >= ? AND importance <= ?'
            params.extend([query.min_importance, query.max_importance])

            # –§–∏–ª—å—Ç—Ä –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
            sql += ' AND priority >= ?'
            params.append(query.min_priority)

            # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É
            if query.kernel_types:
                placeholders = ','.join('?' * len(query.kernel_types))
                sql += f' AND kernel_type IN ({placeholders})'
                params.extend([kt.value for kt in query.kernel_types])

            # –§–∏–ª—å—Ç—Ä –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É
            if query.source:
                sql += ' AND source = ?'
                params.append(query.source)

            cursor.execute(sql, params)
            rows = cursor.fetchall()

            # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            for row in rows:
                # –ü–æ–ª—É—á–∏—Ç—å —Å–≤—è–∑–∏
                cursor.execute(
                    'SELECT connected_id FROM connections WHERE kernel_id = ?',
                    (row[0],)
                )
                connections = [r[0] for r in cursor.fetchall()]
                kernel = self._row_to_kernel(row, connections)

                # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏—Å—Ç—ë–∫—à–∏–µ
                if not query.include_expired and kernel.is_expired():
                    continue

                # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–≥–∞–º
                if query.tags:
                    if not set(query.tags).intersection(set(kernel.tags)):
                        continue

                # –í—ã—á–∏—Å–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                score = self._calculate_score(query, kernel)

                if score > 0 or not query.text:  # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞, –≤—Å–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã
                    results.append(SearchResult(
                        kernel=kernel,
                        score=score,
                        match_reason=f"Relevance: {score:.2f}"
                    ))

            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
            if query.sort_by == "relevance":
                results.sort(key=lambda r: r.score, reverse=query.sort_order == "desc")
            elif query.sort_by == "importance":
                results.sort(key=lambda r: r.kernel.importance, reverse=query.sort_order == "desc")
            elif query.sort_by == "timestamp":
                results.sort(key=lambda r: r.kernel.timestamp, reverse=query.sort_order == "desc")
            elif query.sort_by == "activation":
                results.sort(key=lambda r: r.kernel.activation_count, reverse=query.sort_order == "desc")

            # –ü–∞–≥–∏–Ω–∞—Ü–∏—è
            return results[query.offset:query.offset + query.limit]

        finally:
            conn.close()

    def _calculate_score(self, query: SearchQuery, kernel: SemanticKernel) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–µ—Ä–Ω–∞ –∫ –∑–∞–ø—Ä–æ—Å—É"""
        score = 0.0

        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ essence
        if query.text:
            text_lower = query.text.lower()
            essence_lower = kernel.essence.lower()

            # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            if text_lower in essence_lower:
                score += 0.5

            # –°–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
            query_words = set(text_lower.split())
            essence_words = set(essence_lower.split())
            word_overlap = len(query_words.intersection(essence_words))
            if query_words:
                score += (word_overlap / len(query_words)) * 0.2

            # –°–ª–æ–≤–∞ –≤ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è—Ö
            kernel_concepts = set(c.lower() for c in kernel.concepts)
            concept_overlap = len(query_words.intersection(kernel_concepts))
            if query_words:
                score += (concept_overlap / len(query_words)) * 0.2

        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        if query.concepts:
            query_concepts = set(c.lower() for c in query.concepts)
            kernel_concepts = set(c.lower() for c in kernel.concepts)
            overlap = len(query_concepts.intersection(kernel_concepts))
            if query_concepts:
                score += (overlap / len(query_concepts)) * 0.3

        # –ë–æ–Ω—É—Å –∑–∞ –≤–∞–∂–Ω–æ—Å—Ç—å
        score += kernel.importance * 0.1

        return min(score, 1.0)

    @handle_error
    def delete(self, kernel_id: str) -> bool:
        """–£–¥–∞–ª–∏—Ç—å –∑–µ—Ä–Ω–æ"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('DELETE FROM kernels WHERE id = ?', (kernel_id,))
            deleted = cursor.rowcount > 0
            conn.commit()

            if deleted:
                logger.debug(f"–£–¥–∞–ª–µ–Ω–æ –∑–µ—Ä–Ω–æ: {kernel_id[:8]}...")

            return deleted

        finally:
            conn.close()

    @handle_error
    def update(self, kernel: SemanticKernel) -> bool:
        """–û–±–Ω–æ–≤–∏—Ç—å –∑–µ—Ä–Ω–æ"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('''
                UPDATE kernels SET
                    essence = ?,
                    concepts = ?,
                    kernel_type = ?,
                    importance = ?,
                    priority = ?,
                    activation_count = ?,
                    last_accessed = ?,
                    ttl = ?,
                    tags = ?,
                    source = ?,
                    metadata = ?
                WHERE id = ?
            ''', (
                kernel.essence,
                json.dumps(kernel.concepts),
                kernel.kernel_type.value,
                kernel.importance,
                kernel.priority,
                kernel.activation_count,
                kernel.last_accessed.isoformat() if kernel.last_accessed else None,
                kernel.ttl,
                json.dumps(kernel.tags),
                kernel.source,
                json.dumps(kernel.metadata),
                kernel.id
            ))

            updated = cursor.rowcount > 0
            conn.commit()
            return updated

        finally:
            conn.close()

    @handle_error
    def stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            # –í—Å–µ–≥–æ –∑—ë—Ä–µ–Ω
            cursor.execute('SELECT COUNT(*) FROM kernels')
            total_kernels = cursor.fetchone()[0]

            # –ü–æ —Ç–∏–ø–∞–º
            cursor.execute('SELECT kernel_type, COUNT(*) FROM kernels GROUP BY kernel_type')
            by_type = dict(cursor.fetchall())

            # –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å
            cursor.execute('SELECT AVG(importance) FROM kernels')
            avg_importance = cursor.fetchone()[0] or 0

            # –í—Å–µ–≥–æ —Å–≤—è–∑–µ–π
            cursor.execute('SELECT COUNT(*) FROM connections')
            total_connections = cursor.fetchone()[0]

            # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = Path(self.db_path).stat().st_size if Path(self.db_path).exists() else 0

            return {
                "total_kernels": total_kernels,
                "by_type": by_type,
                "avg_importance": avg_importance,
                "total_connections": total_connections // 2,
                "storage_size_bytes": file_size
            }

        finally:
            conn.close()

    @handle_error
    def cleanup(self, days_old: int = 30, importance_threshold: float = 0.2) -> int:
        """–û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –Ω–µ–≤–∞–∂–Ω—ã–µ –∑—ë—Ä–Ω–∞"""
        cutoff_date = datetime.now() - timedelta(days=days_old)

        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('''
                DELETE FROM kernels
                WHERE importance < ? AND timestamp < ?
            ''', (importance_threshold, cutoff_date.isoformat()))

            deleted_count = cursor.rowcount
            conn.commit()

            logger.info(f"–û—á–∏—â–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö –∑—ë—Ä–µ–Ω")
            return deleted_count

        finally:
            conn.close()

    def _row_to_kernel(self, row: tuple, connections: List[str] = None) -> SemanticKernel:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É –ë–î –≤ SemanticKernel"""
        if connections is None:
            connections = []

        return SemanticKernel(
            id=row[0],
            essence=row[1],
            concepts=json.loads(row[2]),
            kernel_type=KernelType(row[3]),
            importance=row[4],
            priority=row[5],
            timestamp=datetime.fromisoformat(row[6]),
            activation_count=row[7],
            last_accessed=datetime.fromisoformat(row[8]) if row[8] else None,
            ttl=row[9],
            tags=json.loads(row[10]) if row[10] else [],
            source=row[11],
            metadata=json.loads(row[12]) if row[12] else {},
            connections=connections
        )


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üóÑÔ∏è  –¢–µ—Å—Ç SQLite MemoryStore:\n")

    store = SQLiteMemoryStore(db_path="test_sqlite_store.db")

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–µ—Ä–Ω–æ
    kernel = SemanticKernel(
        essence="SQLite —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!",
        concepts=["sqlite", "—Ö—Ä–∞–Ω–∏–ª–∏—â–µ", "—Ç–µ—Å—Ç"],
        kernel_type=KernelType.FACT,
        importance=0.8,
        priority=5,
        tags=["test", "sqlite"]
    )

    kid = store.save(kernel)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {kid[:8]}...")

    # –ü–æ–ª—É—á–∏—Ç—å
    retrieved = store.get(kid)
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {retrieved.essence}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = store.stats()
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  –ó—ë—Ä–µ–Ω: {stats['total_kernels']}")
    print(f"  –†–∞–∑–º–µ—Ä –ë–î: {stats['storage_size_bytes']} –±–∞–π—Ç")

    print("\n‚úÖ SQLite MemoryStore —Ä–∞–±–æ—Ç–∞–µ—Ç!")


