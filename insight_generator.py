"""
ConsciousAI v5.0 - Insight Generator
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–Ω—Å–∞–π—Ç–æ–≤ - —Å–æ–∑–¥–∞–Ω–∏–µ –æ–∑–∞—Ä–µ–Ω–∏–π —á–µ—Ä–µ–∑ —Å–∏–Ω—Ç–µ–∑ –∑–Ω–∞–Ω–∏–π

–ú–µ—Ç–æ–¥—ã:
1. –ê–Ω–∞–ª–æ–≥–∏–∏ - –Ω–∞—Ö–æ–¥–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –¥—Ä—É–≥–∏—Ö –æ–±–ª–∞—Å—Ç–µ–π
2. –°–∏–Ω—Ç–µ–∑ - –æ–±—ä–µ–¥–∏–Ω—è—Ç—å –Ω–µ—Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–∏
3. –õ–∞—Ç–µ—Ä–∞–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ - –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å–≤—è–∑–∏
4. –ê–±—Å—Ç—Ä–∞–∫—Ü–∏—è - –ø–æ–¥–Ω—è—Ç–∏–µ –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ
5. –ò–Ω–≤–µ—Ä—Å–∏—è - –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–π –ø–æ–¥—Ö–æ–¥
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from enum import Enum
import random

from semantic_kernel import SemanticKernel, KernelType
from semantic_memory import SemanticMemory, KnowledgeGraph


class InsightType(Enum):
    """–¢–∏–ø—ã –∏–Ω—Å–∞–π—Ç–æ–≤"""
    ANALOGY = "analogy"              # –ê–Ω–∞–ª–æ–≥–∏—è –∏–∑ –¥—Ä—É–≥–æ–π –æ–±–ª–∞—Å—Ç–∏
    SYNTHESIS = "synthesis"          # –°–∏–Ω—Ç–µ–∑ –∏–¥–µ–π
    LATERAL = "lateral"              # –õ–∞—Ç–µ—Ä–∞–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ
    ABSTRACTION = "abstraction"      # –ê–±—Å—Ç—Ä–∞–∫—Ü–∏—è (–≤—ã—à–µ —É—Ä–æ–≤–µ–Ω—å)
    INVERSION = "inversion"          # –ò–Ω–≤–µ—Ä—Å–∏—è (–ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ–µ)
    PATTERN = "pattern"              # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
    CONTRADICTION = "contradiction"  # –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ ‚Üí –Ω–æ–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ


@dataclass
class Insight:
    """
    –ò–Ω—Å–∞–π—Ç - –æ–∑–∞—Ä–µ–Ω–∏–µ, –Ω–æ–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ

    –ü—Ä–∏–º–µ—Ä:
    "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å –ø–æ—Ö–æ–∂–∞ –Ω–∞ ZIP-–∞—Ä—Ö–∏–≤ –¥–ª—è —Å–º—ã—Å–ª–∞:
     —Å–∂–∏–º–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Å—É—Ç–∏!"
    """
    insight_type: InsightType
    content: str
    source_concepts: List[str]
    confidence: float
    novelty: float  # –ù–∞—Å–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ–µ (0-1)
    usefulness: float  # –ù–∞—Å–∫–æ–ª—å–∫–æ –ø–æ–ª–µ–∑–Ω–æ–µ (0-1)
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)

    def get_score(self) -> float:
        """–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∏–Ω—Å–∞–π—Ç–∞"""
        return (
            self.confidence * 0.3 +
            self.novelty * 0.4 +
            self.usefulness * 0.3
        )

    def to_dict(self) -> Dict[str, Any]:
        return {
            "type": self.insight_type.value,
            "content": self.content,
            "source_concepts": self.source_concepts,
            "confidence": self.confidence,
            "novelty": self.novelty,
            "usefulness": self.usefulness,
            "score": self.get_score(),
            "timestamp": self.timestamp.isoformat(),
            "metadata": self.metadata
        }


class AnalogyFinder:
    """
    –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–∏–π - –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –¥—Ä—É–≥–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö

    –ü—Ä–∏–º–µ—Ä:
    –ó–∞–¥–∞—á–∞: "–ö–∞–∫ —Å–∂–∞—Ç—å –ø–∞–º—è—Ç—å AI?"
    –ê–Ω–∞–ª–æ–≥–∏—è: "–ö–∞–∫ ZIP —Å–∂–∏–º–∞–µ—Ç —Ñ–∞–π–ª—ã? –ù–∞—Ö–æ–¥–∏—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã!"
    –ò–Ω—Å–∞–π—Ç: "–ú–æ–∂–Ω–æ —Å–∂–∏–º–∞—Ç—å —Å–º—ã—Å–ª, –Ω–∞—Ö–æ–¥—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏!"
    """

    # –î–æ–º–µ–Ω—ã –∑–Ω–∞–Ω–∏–π
    KNOWLEDGE_DOMAINS = [
        "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
        "–ø—Ä–∏—Ä–æ–¥–∞",
        "–±–∏–æ–ª–æ–≥–∏—è",
        "—Ñ–∏–∑–∏–∫–∞",
        "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞",
        "–º—É–∑—ã–∫–∞",
        "—Å–ø–æ—Ä—Ç",
        "–º–µ–¥–∏—Ü–∏–Ω–∞",
        "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è",
        "—ç–∫–æ–Ω–æ–º–∏–∫–∞",
        "–∏—Å–∫—É—Å—Å—Ç–≤–æ",
        "–∏—Å—Ç–æ—Ä–∏—è"
    ]

    # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –∞–Ω–∞–ª–æ–≥–∏–∏
    COMMON_ANALOGIES = {
        "—Å–∂–∞—Ç–∏–µ": {
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": "ZIP-–∞—Ä—Ö–∏–≤ —Å–∂–∏–º–∞–µ—Ç —Ñ–∞–π–ª—ã, –Ω–∞—Ö–æ–¥—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è",
            "–ø—Ä–∏—Ä–æ–¥–∞": "–î–ù–ö —Å–∂–∏–º–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–º–∞ –≤ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–æ–¥",
            "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è": "–ü–∞–º—è—Ç—å —á–µ–ª–æ–≤–µ–∫–∞ —Å–∂–∏–º–∞–µ—Ç –æ–ø—ã—Ç –≤ –∫–ª—é—á–µ–≤—ã–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è"
        },
        "–ø–æ–∏—Å–∫": {
            "–ø—Ä–∏—Ä–æ–¥–∞": "–ü—á—ë–ª—ã –∏—â—É—Ç —Ü–≤–µ—Ç—ã –ø–æ –∑–∞–ø–∞—Ö—É –∏ —Ç–∞–Ω—Ü—É",
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": "Google –∏—â–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ –∏–Ω–¥–µ–∫—Å—É –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏",
            "–±–∏–æ–ª–æ–≥–∏—è": "–ò–º–º—É–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏—â–µ—Ç –ø–∞—Ç–æ–≥–µ–Ω—ã –ø–æ –∞–Ω—Ç–∏—Ç–µ–ª–∞–º"
        },
        "—Å–≤—è–∑–∏": {
            "–ø—Ä–∏—Ä–æ–¥–∞": "–ú–∏—Ü–µ–ª–∏–π –≥—Ä–∏–±–æ–≤ —Å–≤—è–∑—ã–≤–∞–µ—Ç –¥–µ—Ä–µ–≤—å—è –≤ –ª–µ—Å—É",
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–≤—è–∑—ã–≤–∞–µ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä—ã –≤ —Å–µ—Ç—å",
            "—Å–æ—Ü–∏–æ–ª–æ–≥–∏—è": "–°–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏ —Å–≤—è–∑—ã–≤–∞—é—Ç –ª—é–¥–µ–π"
        },
        "–æ–±—É—á–µ–Ω–∏–µ": {
            "–±–∏–æ–ª–æ–≥–∏—è": "–ù–µ–π—Ä–æ–Ω—ã –æ–±—É—á–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ —É—Å–∏–ª–µ–Ω–∏–µ —Å–∏–Ω–∞–ø—Å–æ–≤",
            "—Å–ø–æ—Ä—Ç": "–ú—ã—à–µ—á–Ω–∞—è –ø–∞–º—è—Ç—å —á–µ—Ä–µ–∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ",
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": "AI –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö"
        }
    }

    def find_analogies(
        self,
        concept: str,
        target_domain: Optional[str] = None
    ) -> List[Tuple[str, str, float]]:
        """
        –ù–∞–π—Ç–∏ –∞–Ω–∞–ª–æ–≥–∏–∏ –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏

        Args:
            concept: –ö–æ–Ω—Ü–µ–ø—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–∏–π
            target_domain: –¶–µ–ª–µ–≤–æ–π –¥–æ–º–µ–Ω (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –°–ø–∏—Å–æ–∫ (–¥–æ–º–µ–Ω, –∞–Ω–∞–ª–æ–≥–∏—è, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        """
        analogies = []

        # –ù–∞–π—Ç–∏ –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∞–Ω–∞–ª–æ–≥–∏—è—Ö
        concept_lower = concept.lower()
        for key, domains in self.COMMON_ANALOGIES.items():
            if key in concept_lower:
                for domain, analogy in domains.items():
                    if target_domain is None or domain == target_domain:
                        analogies.append((domain, analogy, 0.8))

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, —Å–æ–∑–¥–∞—Ç—å –æ–±—â–∏–µ –∞–Ω–∞–ª–æ–≥–∏–∏
        if not analogies:
            for domain in self.KNOWLEDGE_DOMAINS[:3]:  # –¢–æ–ø-3 –¥–æ–º–µ–Ω–∞
                analogy = f"–í –æ–±–ª–∞—Å—Ç–∏ '{domain}' {concept} –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º"
                analogies.append((domain, analogy, 0.3))

        return analogies

    def create_analogy_insight(
        self,
        problem: str,
        source_domain: str,
        analogy: str
    ) -> Insight:
        """
        –°–æ–∑–¥–∞—Ç—å –∏–Ω—Å–∞–π—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–æ–≥–∏–∏

        Args:
            problem: –ü—Ä–æ–±–ª–µ–º–∞
            source_domain: –î–æ–º–µ–Ω-–∏—Å—Ç–æ—á–Ω–∏–∫ –∞–Ω–∞–ª–æ–≥–∏–∏
            analogy: –û–ø–∏—Å–∞–Ω–∏–µ –∞–Ω–∞–ª–æ–≥–∏–∏

        Returns:
            Insight –æ–±—ä–µ–∫—Ç
        """
        content = f"–ê–Ω–∞–ª–æ–≥–∏—è –∏–∑ '{source_domain}': {analogy}\n‚Üí –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ '{problem}'"

        return Insight(
            insight_type=InsightType.ANALOGY,
            content=content,
            source_concepts=[problem, source_domain],
            confidence=0.7,
            novelty=0.6,
            usefulness=0.7,
            metadata={
                "source_domain": source_domain,
                "analogy": analogy
            }
        )


class SynthesisEngine:
    """
    –î–≤–∏–∂–æ–∫ —Å–∏–Ω—Ç–µ–∑–∞ - –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –Ω–µ—Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–∏

    –ü—Ä–∏–º–µ—Ä:
    –ò–¥–µ—è 1: "–°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å —Å–∂–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç"
    –ò–¥–µ—è 2: "–ì—Ä–∞—Ñ —Å–≤—è–∑—ã–≤–∞–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏"
    –°–∏–Ω—Ç–µ–∑: "–ì—Ä–∞—Ñ —Å–º—ã—Å–ª–æ–≤—ã—Ö –∑—ë—Ä–µ–Ω = —Å–∂–∞—Ç–∞—è –ø–∞–º—è—Ç—å + —Å–≤—è–∑–∏!"
    """

    def synthesize(
        self,
        ideas: List[str],
        memory: Optional[SemanticMemory] = None
    ) -> Insight:
        """
        –°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—É—é –∏–¥–µ—é –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö

        Args:
            ideas: –°–ø–∏—Å–æ–∫ –∏–¥–µ–π –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
            memory: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)

        Returns:
            Insight —Å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–¥–µ–µ–π
        """
        if len(ideas) < 2:
            raise ValueError("–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 –∏–¥–µ–∏ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")

        # –ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏–∑ –∫–∞–∂–¥–æ–π –∏–¥–µ–∏
        all_concepts = []
        for idea in ideas:
            words = idea.lower().split()
            concepts = [w for w in words if len(w) > 4][:3]  # –¢–æ–ø-3 —Å–ª–æ–≤–∞
            all_concepts.extend(concepts)

        # –°–æ–∑–¥–∞—Ç—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        synthesis_content = f"–°–∏–Ω—Ç–µ–∑ –∏–¥–µ–π:\n"
        for i, idea in enumerate(ideas, 1):
            synthesis_content += f"  {i}. {idea}\n"

        synthesis_content += f"\n‚Üí –ù–æ–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ: "

        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞
        if len(ideas) == 2:
            synthesis_content += f"–û–±—ä–µ–¥–∏–Ω—è—è '{ideas[0][:30]}...' –∏ '{ideas[1][:30]}...', "
            synthesis_content += f"–ø–æ–ª—É—á–∞–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –æ–±–æ–∏—Ö –ø–æ–¥—Ö–æ–¥–æ–≤"
        else:
            synthesis_content += f"–ö–æ–º–±–∏–Ω–∞—Ü–∏—è {len(ideas)} –∏–¥–µ–π —Å–æ–∑–¥–∞—ë—Ç –º–Ω–æ–≥–æ–≥—Ä–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ"

        return Insight(
            insight_type=InsightType.SYNTHESIS,
            content=synthesis_content,
            source_concepts=all_concepts,
            confidence=0.6,
            novelty=0.7,
            usefulness=0.8,
            metadata={"original_ideas": ideas}
        )


class LateralThinker:
    """
    –õ–∞—Ç–µ—Ä–∞–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ - –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å–≤—è–∑–∏

    –ú–µ—Ç–æ–¥—ã:
    - –°–ª—É—á–∞–π–Ω—ã–µ –≤—Ö–æ–¥—ã (random input)
    - –ü—Ä–æ–≤–æ–∫–∞—Ü–∏—è (—á—Ç–æ –µ—Å–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç?)
    - –°–∫–∞—á–∫–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π (concept jumping)
    """

    def __init__(self, memory: SemanticMemory):
        self.memory = memory

    def random_input(self, problem: str) -> Insight:
        """
        –ú–µ—Ç–æ–¥ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤—Ö–æ–¥–∞ - –¥–æ–±–∞–≤–∏—Ç—å —Å–ª—É—á–∞–π–Ω—É—é –∫–æ–Ω—Ü–µ–ø—Ü–∏—é

        Args:
            problem: –ü—Ä–æ–±–ª–µ–º–∞ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è

        Returns:
            Insight —Å –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –∏–¥–µ–µ–π
        """
        # –°–ª—É—á–∞–π–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –¥–ª—è —Å—Ç–∏–º—É–ª—è—Ü–∏–∏ –º—ã—à–ª–µ–Ω–∏—è
        random_concepts = [
            "–∏–≥—Ä–∞", "–º—É–∑—ã–∫–∞", "–ø—Ä–∏—Ä–æ–¥–∞", "–≤–æ–¥–∞", "–æ–≥–æ–Ω—å",
            "—Ç–∞–Ω–µ—Ü", "—Ü–≤–µ—Ç", "–∑–∞–ø–∞—Ö", "–≤—Ä–µ–º—è", "–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ",
            "–∑–µ—Ä–∫–∞–ª–æ", "–¥–≤–µ—Ä—å", "–º–æ—Å—Ç", "—Ä–µ–∫–∞", "–≥–æ—Ä–∞"
        ]

        random_concept = random.choice(random_concepts)

        content = f"–õ–∞—Ç–µ—Ä–∞–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ: '{problem}' + —Å–ª—É—á–∞–π–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è '{random_concept}'\n\n"
        content += f"–ß—Ç–æ –µ—Å–ª–∏ –ø–æ–¥–æ–π—Ç–∏ –∫ '{problem}' –∫–∞–∫ –∫ '{random_concept}'?\n"

        # –°–æ–∑–¥–∞—Ç—å —Å–≤—è–∑—å
        if random_concept == "–º—É–∑—ã–∫–∞":
            content += "‚Üí –ú–æ–∂–µ—Ç –±—ã—Ç—å, –Ω—É–∂–Ω–∞ –≥–∞—Ä–º–æ–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤? –†–∏—Ç–º —Ä–∞–±–æ—Ç—ã?"
        elif random_concept == "–ø—Ä–∏—Ä–æ–¥–∞":
            content += "‚Üí –ú–æ–∂–µ—Ç –±—ã—Ç—å, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏–π —Ä–æ—Å—Ç? –ê–¥–∞–ø—Ç–∞—Ü–∏—é?"
        elif random_concept == "–≤–æ–¥–∞":
            content += "‚Üí –ú–æ–∂–µ—Ç –±—ã—Ç—å, –Ω—É–∂–Ω–∞ —Ç–µ–∫—É—á–µ—Å—Ç—å? –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ —Ñ–æ—Ä–º–µ?"
        elif random_concept == "–∏–≥—Ä–∞":
            content += "‚Üí –ú–æ–∂–µ—Ç –±—ã—Ç—å, –¥–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã –∏–≥—Ä—ã? –ü—Ä–∞–≤–∏–ª–∞ –∏ —Å–≤–æ–±–æ–¥—É?"
        else:
            content += f"‚Üí –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞ '{random_concept}' –¥–ª—è –Ω–æ–≤—ã—Ö –∏–¥–µ–π"

        return Insight(
            insight_type=InsightType.LATERAL,
            content=content,
            source_concepts=[problem, random_concept],
            confidence=0.4,  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - —ç—Ç–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ
            novelty=0.9,     # –í—ã—Å–æ–∫–∞—è –Ω–æ–≤–∏–∑–Ω–∞
            usefulness=0.5,   # –°—Ä–µ–¥–Ω—è—è –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å
            metadata={"method": "random_input", "random_concept": random_concept}
        )

    def provocation(self, statement: str) -> Insight:
        """
        –ú–µ—Ç–æ–¥ –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–∏ - –ø–µ—Ä–µ–≤–µ—Ä–Ω—É—Ç—å —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ

        Args:
            statement: –£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ

        Returns:
            Insight —Å –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω–æ–π –∏–¥–µ–µ–π
        """
        content = f"–ü—Ä–æ–≤–æ–∫–∞—Ü–∏—è: '{statement}'\n\n"
        content += "–ß—Ç–æ –µ—Å–ª–∏ –ù–ê–û–ë–û–†–û–¢?\n"
        content += f"‚Üí –ü—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –º–æ–∂–µ—Ç –æ—Ç–∫—Ä—ã—Ç—å –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\n"
        content += "  ‚Ä¢ –í–º–µ—Å—Ç–æ —Å–ª–æ–∂–Ω–æ–≥–æ ‚Üí –ø—Ä–æ—Å—Ç–æ–µ\n"
        content += "  ‚Ä¢ –í–º–µ—Å—Ç–æ –±—ã—Å—Ç—Ä–æ–≥–æ ‚Üí –º–µ–¥–ª–µ–Ω–Ω–æ–µ, –Ω–æ –≥–ª—É–±–æ–∫–æ–µ\n"
        content += "  ‚Ä¢ –í–º–µ—Å—Ç–æ –±–æ–ª—å—à–æ–≥–æ ‚Üí –º–∞–ª–µ–Ω—å–∫–æ–µ, –Ω–æ —Ç–æ—á–µ—á–Ω–æ–µ\n"
        content += "  ‚Ä¢ –í–º–µ—Å—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ ‚Üí —Ä—É—á–Ω–æ–µ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º\n"

        return Insight(
            insight_type=InsightType.LATERAL,
            content=content,
            source_concepts=[statement],
            confidence=0.5,
            novelty=0.8,
            usefulness=0.6,
            metadata={"method": "provocation"}
        )

    def concept_jumping(self, start_concept: str, jumps: int = 3) -> Insight:
        """
        –°–∫–∞—á–∫–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π - –ø–µ—Ä–µ–ø—Ä—ã–≥–∏–≤–∞—Ç—å –º–µ–∂–¥—É –∏–¥–µ—è–º–∏

        Args:
            start_concept: –ù–∞—á–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è
            jumps: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫–∞—á–∫–æ–≤

        Returns:
            Insight —Å —Ü–µ–ø–æ—á–∫–æ–π –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        """
        # –ù–∞–π—Ç–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –≤ –ø–∞–º—è—Ç–∏
        search_results = self.memory.search(start_concept, limit=jumps * 2)

        concept_chain = [start_concept]

        for kernel, _ in search_results[:jumps]:
            # –í–∑—è—Ç—å –ø–µ—Ä–≤—É—é –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –∏–∑ –∑–µ—Ä–Ω–∞
            if kernel.concepts:
                concept_chain.append(kernel.concepts[0])

        content = f"–°–∫–∞—á–∫–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π (–æ—Ç '{start_concept}'):\n\n"
        for i, concept in enumerate(concept_chain):
            content += f"  {i+1}. {concept}\n"

        content += f"\n‚Üí –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è '{concept_chain[-1]}' –º–æ–∂–µ—Ç –¥–∞—Ç—å —Å–≤–µ–∂–∏–π –≤–∑–≥–ª—è–¥ –Ω–∞ '{start_concept}'"

        return Insight(
            insight_type=InsightType.LATERAL,
            content=content,
            source_concepts=concept_chain,
            confidence=0.5,
            novelty=0.7,
            usefulness=0.6,
            metadata={"method": "concept_jumping", "chain": concept_chain}
        )


class AbstractionEngine:
    """
    –î–≤–∏–∂–æ–∫ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ - –ø–æ–¥–Ω—è—Ç–∏–µ –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ

    –ü—Ä–∏–º–µ—Ä—ã:
    "–°–æ–∑–¥–∞—Ç—å –≤–µ–±-—Å–∞–π—Ç" ‚Üí "–°–æ–∑–¥–∞—Ç—å –æ–Ω–ª–∞–π–Ω-–ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ"
    "–ù–∞–ø–∏—Å–∞—Ç—å –∫–æ–¥" ‚Üí "–†–µ—à–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É"
    "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º" ‚Üí "–£–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
    """

    # –£—Ä–æ–≤–Ω–∏ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏
    ABSTRACTION_LEVELS = {
        "—Å–æ–∑–¥–∞—Ç—å —Å–∞–π—Ç": [
            "–°–æ–∑–¥–∞—Ç—å –æ–Ω–ª–∞–π–Ω-–ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ",
            "–û–±–µ—Å–ø–µ—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
            "–†–µ—à–∏—Ç—å –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—É—é –∑–∞–¥–∞—á—É"
        ],
        "–Ω–∞–ø–∏—Å–∞—Ç—å –∫–æ–¥": [
            "–†–µ—à–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É",
            "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å",
            "–°–æ–∑–¥–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç"
        ],
        "–æ–±—É—á–∏—Ç—å AI": [
            "–ü–µ—Ä–µ–¥–∞—Ç—å –∑–Ω–∞–Ω–∏—è",
            "–£–ª—É—á—à–∏—Ç—å —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏",
            "–†–∞–∑–≤–∏—Ç—å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"
        ]
    }

    def abstract(self, concrete_task: str, levels: int = 2) -> Insight:
        """
        –ê–±—Å—Ç—Ä–∞–≥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É –Ω–∞ —É—Ä–æ–≤–Ω–∏ –≤—ã—à–µ

        Args:
            concrete_task: –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –∑–∞–¥–∞—á–∞
            levels: –°–∫–æ–ª—å–∫–æ —É—Ä–æ–≤–Ω–µ–π –ø–æ–¥–Ω—è—Ç—å—Å—è

        Returns:
            Insight —Å –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º
        """
        # –ù–∞–π—Ç–∏ –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è—Ö
        abstractions = []
        task_lower = concrete_task.lower()

        for key, abstract_list in self.ABSTRACTION_LEVELS.items():
            if key in task_lower:
                abstractions = abstract_list[:levels]
                break

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, —Å–æ–∑–¥–∞—Ç—å –æ–±—â—É—é –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—é
        if not abstractions:
            abstractions = [
                f"–†–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É –Ω–∞ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–º —É—Ä–æ–≤–Ω–µ",
                f"–î–æ—Å—Ç–∏—á—å —Ü–µ–ª–∏ —á–µ—Ä–µ–∑ '{concrete_task}'"
            ]

        content = f"–ê–±—Å—Ç—Ä–∞–∫—Ü–∏—è –∑–∞–¥–∞—á–∏ '{concrete_task}':\n\n"
        for i, abstract in enumerate(abstractions, 1):
            content += f"  –£—Ä–æ–≤–µ–Ω—å {i}: {abstract}\n"

        content += f"\n‚Üí –ù–∞ –≤—ã—Å—à–µ–º —É—Ä–æ–≤–Ω–µ —ç—Ç–æ –æ: {abstractions[-1]}"

        return Insight(
            insight_type=InsightType.ABSTRACTION,
            content=content,
            source_concepts=[concrete_task] + abstractions,
            confidence=0.7,
            novelty=0.5,
            usefulness=0.7,
            metadata={"abstractions": abstractions}
        )


class PatternDetector:
    """
    –î–µ—Ç–µ–∫—Ç–æ—Ä –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ - –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã

    –í –¥–∞–Ω–Ω—ã—Ö, –ø–æ–≤–µ–¥–µ–Ω–∏–∏, –∫–æ–¥–µ, –¥–∏–∞–ª–æ–≥–∞—Ö
    """

    def detect_in_sequence(self, sequence: List[Any]) -> Optional[Insight]:
        """
        –û–±–Ω–∞—Ä—É–∂–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

        Args:
            sequence: –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç–æ–≤

        Returns:
            Insight –µ—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–∞–π–¥–µ–Ω
        """
        if len(sequence) < 3:
            return None

        # –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥: –Ω–∞–π—Ç–∏ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
        from collections import Counter
        counter = Counter(sequence)

        # –ï—Å—Ç—å –ª–∏ —ç–ª–µ–º–µ–Ω—Ç—ã, –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è 50%+ —Ä–∞–∑?
        threshold = len(sequence) * 0.5
        repeating = [item for item, count in counter.items() if count >= threshold]

        if repeating:
            content = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n\n"
            content += f"–≠–ª–µ–º–µ–Ω—Ç—ã {repeating} –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è –≤ {len(sequence)} —ç–ª–µ–º–µ–Ω—Ç–∞—Ö\n"
            content += f"‚Üí –≠—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —É—Å—Ç–æ–π—á–∏–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –ø–æ–≤–µ–¥–µ–Ω–∏—è"

            return Insight(
                insight_type=InsightType.PATTERN,
                content=content,
                source_concepts=["–ø–∞—Ç—Ç–µ—Ä–Ω", "–ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ"],
                confidence=0.8,
                novelty=0.4,
                usefulness=0.8,
                metadata={"pattern": repeating, "sequence_length": len(sequence)}
            )

        return None


class InsightGenerator:
    """
    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–Ω—Å–∞–π—Ç–æ–≤ - –≥–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å

    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –º–µ—Ç–æ–¥—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤
    """

    def __init__(self, memory: SemanticMemory):
        self.memory = memory
        self.analogy_finder = AnalogyFinder()
        self.synthesis_engine = SynthesisEngine()
        self.lateral_thinker = LateralThinker(memory)
        self.abstraction_engine = AbstractionEngine()
        self.pattern_detector = PatternDetector()
        self.generated_insights: List[Insight] = []

    def generate(
        self,
        topic: str,
        methods: Optional[List[InsightType]] = None,
        limit: int = 5
    ) -> List[Insight]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Å–∞–π—Ç—ã –ø–æ —Ç–µ–º–µ

        Args:
            topic: –¢–µ–º–∞ –¥–ª—è –∏–Ω—Å–∞–π—Ç–æ–≤
            methods: –ú–µ—Ç–æ–¥—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ None - –≤—Å–µ)
            limit: –ú–∞–∫—Å–∏–º—É–º –∏–Ω—Å–∞–π—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –∏–Ω—Å–∞–π—Ç–æ–≤, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ score
        """
        insights = []

        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–µ—Ç–æ–¥—ã
        if methods is None:
            methods = [
                InsightType.ANALOGY,
                InsightType.SYNTHESIS,
                InsightType.LATERAL,
                InsightType.ABSTRACTION
            ]

        # –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Å–∞–π—Ç—ã —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
        if InsightType.ANALOGY in methods:
            analogies = self.analogy_finder.find_analogies(topic)
            for domain, analogy, conf in analogies[:2]:
                insight = self.analogy_finder.create_analogy_insight(
                    topic, domain, analogy
                )
                insights.append(insight)

        if InsightType.LATERAL in methods:
            lateral = self.lateral_thinker.random_input(topic)
            insights.append(lateral)

        if InsightType.ABSTRACTION in methods:
            abstract = self.abstraction_engine.abstract(topic)
            insights.append(abstract)

        if InsightType.SYNTHESIS in methods:
            # –ù–∞–π—Ç–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–∏ –≤ –ø–∞–º—è—Ç–∏
            related = self.memory.search(topic, limit=3)
            if len(related) >= 2:
                ideas = [k.essence for k, _ in related]
                synthesis = self.synthesis_engine.synthesize(ideas)
                insights.append(synthesis)

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã
        self.generated_insights.extend(insights)

        # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ score –∏ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å
        insights.sort(key=lambda i: i.get_score(), reverse=True)

        return insights[:limit]

    def get_best_insights(self, limit: int = 10) -> List[Insight]:
        """–ü–æ–ª—É—á–∏—Ç—å –ª—É—á—à–∏–µ –∏–Ω—Å–∞–π—Ç—ã –≤—Å–µ—Ö –≤—Ä–µ–º—ë–Ω"""
        sorted_insights = sorted(
            self.generated_insights,
            key=lambda i: i.get_score(),
            reverse=True
        )
        return sorted_insights[:limit]


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üí° Insight Generator - –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–Ω—Å–∞–π—Ç–æ–≤\n")

    # –°–æ–∑–¥–∞—Ç—å –ø–∞–º—è—Ç—å –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
    memory = SemanticMemory(db_path="test_insights.db")
    generator = InsightGenerator(memory)

    # –î–æ–±–∞–≤–∏—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–Ω–∞–Ω–∏—è –≤ –ø–∞–º—è—Ç—å
    from semantic_kernel import SemanticCompressor
    compressor = SemanticCompressor()

    knowledge = [
        "–°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å —Å–∂–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –∑—ë—Ä–Ω–∞",
        "–ì—Ä–∞—Ñ —Å–≤—è–∑—ã–≤–∞–µ—Ç –∑—ë—Ä–Ω–∞ –º–µ–∂–¥—É —Å–æ–±–æ–π",
        "–ê—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∑—ë—Ä–Ω–∞",
        "–ú–µ—Ç–∞-–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ"
    ]

    for k in knowledge:
        kernel = compressor.compress(k, language="ru")
        memory.store(kernel)

    # –ü—Ä–∏–º–µ—Ä 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
    print("–ü—Ä–∏–º–µ—Ä 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤")
    topic = "–∫–∞–∫ —É–ª—É—á—à–∏—Ç—å –ø–∞–º—è—Ç—å AI"
    insights = generator.generate(topic, limit=3)

    for i, insight in enumerate(insights, 1):
        print(f"\n  –ò–Ω—Å–∞–π—Ç {i} [{insight.insight_type.value}]:")
        print(f"  {insight.content[:150]}...")
        print(f"  Score: {insight.get_score():.2f} (–Ω–æ–≤–∏–∑–Ω–∞={insight.novelty:.2f}, –ø–æ–ª—å–∑–∞={insight.usefulness:.2f})")

    # –ü—Ä–∏–º–µ—Ä 2: –ê–Ω–∞–ª–æ–≥–∏–∏
    print("\n\n–ü—Ä–∏–º–µ—Ä 2: –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–∏–π")
    analogies = generator.analogy_finder.find_analogies("—Å–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö")
    for domain, analogy, conf in analogies[:2]:
        print(f"\n  [{domain}]: {analogy}")

    # –ü—Ä–∏–º–µ—Ä 3: –õ–∞—Ç–µ—Ä–∞–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ
    print("\n\n–ü—Ä–∏–º–µ—Ä 3: –õ–∞—Ç–µ—Ä–∞–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ")
    lateral = generator.lateral_thinker.random_input("—Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å")
    print(f"  {lateral.content[:200]}...")

    print("\n‚úÖ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–Ω—Å–∞–π—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
