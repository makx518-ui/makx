"""
ğŸ§  ConsciousAI Advanced â€” Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ
Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾:
- ĞŸĞµÑ€ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ (SQLite)
- Ğ¢Ñ€Ğ°Ğ½ÑÑ†ĞµĞ½Ğ´ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ (Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¾ĞºÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ°)
- Multi-Agent ĞºĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ
- Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚ĞµĞ¹
- Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ°
"""

import sqlite3
import asyncio
import time
import math
import json
import os
from collections import deque, defaultdict
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹
import sys
sys.path.insert(0, os.path.dirname(__file__))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# JSON ENCODER Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class EnhancedJSONEncoder(json.JSONEncoder):
    """Encoder Ğ´Ğ»Ñ dataclass Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²"""
    def default(self, obj):
        if hasattr(obj, '__dict__'):
            return obj.__dict__
        if isinstance(obj, (dataclass, )):
            return asdict(obj)
        return super().default(obj)

def safe_json_dumps(obj):
    """Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ°Ñ ÑĞµÑ€Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ² JSON"""
    try:
        return json.dumps(obj, cls=EnhancedJSONEncoder)
    except TypeError:
        # Fallback: convert to string
        return json.dumps(str(obj))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞŸĞ•Ğ Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞĞ¢ĞĞĞ• Ğ¥Ğ ĞĞĞ˜Ğ›Ğ˜Ğ©Ğ• (SQLite)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class PersistentMemory:
    """ĞŸĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ñ SQLite"""

    def __init__(self, db_path: str = "conscious_ai_memory.db"):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self.cursor = self.conn.cursor()
        self._init_db()

    def _init_db(self):
        """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""

        # Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ»ĞµĞ´Ğ¾Ğ²
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS emotional_traces (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content TEXT NOT NULL,
                emotion_type TEXT NOT NULL,
                resonance REAL NOT NULL,
                frequency REAL NOT NULL,
                timestamp REAL NOT NULL,
                context TEXT,
                session_id TEXT
            )
        """)

        # Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ÑƒĞ·Ğ»Ğ¾Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS memory_nodes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content TEXT NOT NULL,
                proposition TEXT,
                resonance REAL NOT NULL,
                timestamp REAL NOT NULL,
                cycle_data TEXT,
                session_id TEXT
            )
        """)

        # Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ÑĞµÑÑĞ¸Ğ¹
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT UNIQUE NOT NULL,
                start_time REAL NOT NULL,
                end_time REAL,
                dominant_emotion TEXT,
                memory_count INTEGER,
                idea_count INTEGER,
                traits TEXT
            )
        """)

        # Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ñ†Ğ¸ĞºĞ»Ğ¾Ğ² Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS reflection_cycles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                task TEXT NOT NULL,
                final_response TEXT,
                resonance REAL,
                confidence REAL,
                risk REAL,
                timestamp REAL NOT NULL,
                session_id TEXT,
                full_data TEXT
            )
        """)

        self.conn.commit()

    def save_emotional_trace(self, trace: Dict[str, Any], session_id: str):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞ»ĞµĞ´"""
        self.cursor.execute("""
            INSERT INTO emotional_traces
            (content, emotion_type, resonance, frequency, timestamp, context, session_id)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            trace['content'],
            trace['emotion_type'],
            trace['resonance'],
            trace['frequency'],
            trace['timestamp'],
            safe_json_dumps(trace.get('context', {})),
            session_id
        ))
        self.conn.commit()

    def save_memory_node(self, node: Dict[str, Any], session_id: str):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ÑƒĞ·ĞµĞ» Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸"""
        self.cursor.execute("""
            INSERT INTO memory_nodes
            (content, proposition, resonance, timestamp, cycle_data, session_id)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (
            str(node.get('content', '')),
            str(node.get('proposition', '')),
            node.get('resonance', 0.5),
            time.time(),
            safe_json_dumps(node.get('cycle_data', {})),
            session_id
        ))
        self.conn.commit()

    def save_session(self, session_data: Dict[str, Any]):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ÑĞµÑÑĞ¸Ñ"""
        self.cursor.execute("""
            INSERT OR REPLACE INTO sessions
            (session_id, start_time, end_time, dominant_emotion, memory_count, idea_count, traits)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            session_data['session_id'],
            session_data['start_time'],
            session_data.get('end_time'),
            session_data.get('dominant_emotion'),
            session_data.get('memory_count', 0),
            session_data.get('idea_count', 0),
            safe_json_dumps(session_data.get('traits', {}))
        ))
        self.conn.commit()

    def save_reflection_cycle(self, cycle: Dict[str, Any], session_id: str):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ†Ğ¸ĞºĞ» Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸"""
        self.cursor.execute("""
            INSERT INTO reflection_cycles
            (task, final_response, resonance, confidence, risk, timestamp, session_id, full_data)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            cycle['task'],
            cycle['output']['final_response'],
            cycle['output']['resonance'],
            cycle['output']['confidence'],
            cycle['output']['risk'],
            cycle['timestamp'],
            session_id,
            safe_json_dumps(cycle)
        ))
        self.conn.commit()

    def load_recent_traces(self, limit: int = 100) -> List[Dict[str, Any]]:
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ½ĞµĞ´Ğ°Ğ²Ğ½Ğ¸Ğµ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ»ĞµĞ´Ñ‹"""
        self.cursor.execute("""
            SELECT content, emotion_type, resonance, frequency, timestamp, context
            FROM emotional_traces
            ORDER BY timestamp DESC
            LIMIT ?
        """, (limit,))

        traces = []
        for row in self.cursor.fetchall():
            traces.append({
                'content': row[0],
                'emotion_type': row[1],
                'resonance': row[2],
                'frequency': row[3],
                'timestamp': row[4],
                'context': json.loads(row[5]) if row[5] else {}
            })

        return traces

    def load_recent_memory(self, limit: int = 100) -> List[Dict[str, Any]]:
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ½ĞµĞ´Ğ°Ğ²Ğ½Ğ¸Ğµ ÑƒĞ·Ğ»Ñ‹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸"""
        self.cursor.execute("""
            SELECT content, proposition, resonance, timestamp, cycle_data
            FROM memory_nodes
            ORDER BY timestamp DESC
            LIMIT ?
        """, (limit,))

        nodes = []
        for row in self.cursor.fetchall():
            nodes.append({
                'content': row[0],
                'proposition': row[1],
                'resonance': row[2],
                'timestamp': row[3],
                'cycle_data': json.loads(row[4]) if row[4] else {}
            })

        return nodes

    def get_sessions_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞµÑÑĞ¸Ğ¹"""
        self.cursor.execute("""
            SELECT session_id, start_time, end_time, dominant_emotion, memory_count, idea_count, traits
            FROM sessions
            ORDER BY start_time DESC
            LIMIT ?
        """, (limit,))

        sessions = []
        for row in self.cursor.fetchall():
            sessions.append({
                'session_id': row[0],
                'start_time': row[1],
                'end_time': row[2],
                'dominant_emotion': row[3],
                'memory_count': row[4],
                'idea_count': row[5],
                'traits': json.loads(row[6]) if row[6] else {}
            })

        return sessions

    def get_stats(self) -> Dict[str, Any]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ"""
        self.cursor.execute("SELECT COUNT(*) FROM emotional_traces")
        total_traces = self.cursor.fetchone()[0]

        self.cursor.execute("SELECT COUNT(*) FROM memory_nodes")
        total_nodes = self.cursor.fetchone()[0]

        self.cursor.execute("SELECT COUNT(*) FROM sessions")
        total_sessions = self.cursor.fetchone()[0]

        self.cursor.execute("SELECT AVG(resonance) FROM emotional_traces")
        avg_resonance = self.cursor.fetchone()[0] or 0.0

        self.cursor.execute("""
            SELECT emotion_type, COUNT(*) as cnt
            FROM emotional_traces
            GROUP BY emotion_type
            ORDER BY cnt DESC
            LIMIT 1
        """)
        dominant = self.cursor.fetchone()
        dominant_emotion = dominant[0] if dominant else 'unknown'

        return {
            'total_traces': total_traces,
            'total_nodes': total_nodes,
            'total_sessions': total_sessions,
            'avg_resonance': round(avg_resonance, 3),
            'dominant_emotion': dominant_emotion
        }

    def close(self):
        """Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚ÑŒ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ"""
        self.conn.close()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¢Ğ ĞĞĞ¡Ğ¦Ğ•ĞĞ”Ğ•ĞĞ¢ĞĞĞ• ĞœĞ«Ğ¨Ğ›Ğ•ĞĞ˜Ğ• (ĞŸĞ°Ñ€Ğ°Ğ´Ğ¾ĞºÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ°)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TranscendentThinking:
    """Ğ’Ñ‹Ñ…Ğ¾Ğ´ Ğ·Ğ° Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‹ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¾ĞºÑÑ‹ Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ñ"""

    def __init__(self):
        self.paradox_history = []

    def think_beyond(self, problem: str, standard_solution: str, context: Dict) -> Dict[str, Any]:
        """Ğ¢Ñ€Ğ°Ğ½ÑÑ†ĞµĞ½Ğ´ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ"""

        # 1. Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ (ÑƒĞ¶Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾)
        standard = standard_solution

        # 2. Ğ˜Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹
        inverted = self._invert_assumptions(problem, standard)

        # 3. ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¾ĞºÑĞ°
        paradox = self._find_paradox(standard, inverted, problem)

        # 4. Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ· Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ğµ
        transcendent = self._synthesize_contradiction(paradox, context)

        result = {
            'standard': standard,
            'inverted': inverted,
            'paradox': paradox,
            'transcendent': transcendent,
            'insight': self._generate_insight(paradox, transcendent)
        }

        self.paradox_history.append(result)

        return result

    def _invert_assumptions(self, problem: str, solution: str) -> str:
        """Ğ˜Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ"""

        inversions = []

        # Ğ˜Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ 1: "Ğ§Ñ‚Ğ¾ ĞµÑĞ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° â€” Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°?"
        if "Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°" in problem.lower() or "Ğ¾ÑˆĞ¸Ğ±ĞºĞ°" in problem.lower():
            inversions.append("Ğ­Ñ‚Ğ¾ Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°, Ğ° ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼ Ğ±Ğ¾Ğ»ĞµĞµ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ¹ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸")

        # Ğ˜Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ 2: "Ğ§Ñ‚Ğ¾ ĞµÑĞ»Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ â€” Ğ°Ğ½Ñ‚Ğ¸Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ?"
        if "Ñ€ĞµÑˆĞ¸Ñ‚ÑŒ" in solution.lower() or "Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ" in solution.lower():
            inversions.append("ĞĞµ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ, Ğ° Ñ€Ğ°ÑÑ‚Ğ²Ğ¾Ñ€Ğ¸Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ")

        # Ğ˜Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ 3: "Ğ§Ñ‚Ğ¾ ĞµÑĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ»Ğ¾Ğ¶Ğ½ÑƒÑ Ğ´Ğ¸Ñ…Ğ¾Ñ‚Ğ¾Ğ¼Ğ¸Ñ?"
        if " Ğ¸Ğ»Ğ¸ " in problem.lower():
            inversions.append("Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¼ĞµĞ¶Ğ´Ñƒ A Ğ¸ B Ğ»Ğ¾Ğ¶ĞµĞ½ â€” Ğ¸ÑÑ‚Ğ¸Ğ½Ğ° Ğ² ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğµ")

        return "; ".join(inversions) if inversions else "Ğ˜Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ: Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° ÑĞ°Ğ¼Ğ¾Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· ÑĞ²Ğ¾Ñ‘ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ"

    def _find_paradox(self, standard: str, inverted: str, problem: str) -> str:
        """ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¾ĞºÑ Ğ² Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ğ¸"""

        # ĞŸĞ°Ñ€Ğ°Ğ´Ğ¾ĞºÑ Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ°ĞµÑ‚ ĞºĞ¾Ğ³Ğ´Ğ° Ğ¾Ğ±Ğ° Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ° Ğ²ĞµÑ€Ğ½Ñ‹ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾
        paradoxes = [
            "Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ ĞµÑÑ‚ÑŒ Ğ½ĞµÑ€ĞµÑˆĞµĞ½Ğ¸Ğµ",
            "ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ñ€Ğ°ÑÑ‚Ğ²Ğ¾Ñ€ÑĞµÑ‚ÑÑ ĞºĞ¾Ğ³Ğ´Ğ° ĞµÑ‘ Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°ĞµÑˆÑŒ",
            "ĞÑ‚Ğ²ĞµÑ‚ Ğ»ĞµĞ¶Ğ¸Ñ‚ Ğ² Ğ¾Ñ‚ĞºĞ°Ğ·Ğµ Ğ¾Ñ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°",
            "ĞŸÑƒÑ‚ÑŒ Ğ²Ğ¿ĞµÑ€Ñ‘Ğ´ â€” ÑÑ‚Ğ¾ Ğ¿ÑƒÑ‚ÑŒ Ğ½Ğ°Ğ·Ğ°Ğ´ Ğº Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸ÑĞ¼"
        ]

        # Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¾ĞºÑ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°
        if "ĞºĞ°Ğº" in problem.lower():
            return paradoxes[3]
        elif "Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ" in problem.lower():
            return paradoxes[1]
        elif "Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ" in problem.lower():
            return paradoxes[0]
        else:
            return paradoxes[2]

    def _synthesize_contradiction(self, paradox: str, context: Dict) -> str:
        """Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ğµ"""

        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ´Ğ¾ĞºÑ Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ²Ğ·Ğ³Ğ»ÑĞ´Ğ°
        synthesis_templates = [
            f"Ğ§ĞµÑ€ĞµĞ· {paradox.lower()}, Ñ Ğ²Ğ¸Ğ¶Ñƒ: Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰Ğ°Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° Ğ½Ğµ Ğ² Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¸, Ğ° Ğ² Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ",
            f"{paradox} ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚: Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸",
            f"ĞŸĞ°Ñ€Ğ°Ğ´Ğ¾ĞºÑ '{paradox}' Ñ€Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚: Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ÑĞ²Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚, Ğ½Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€ĞµĞ½Ğ¸Ñ"
        ]

        risk = context.get('risk_estimate', 0.5)

        if risk > 0.6:
            return synthesis_templates[0]
        elif risk < 0.3:
            return synthesis_templates[1]
        else:
            return synthesis_templates[2]

    def _generate_insight(self, paradox: str, transcendent: str) -> str:
        """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚"""
        return f"ğŸ’¡ Ğ˜Ğ½ÑĞ°Ğ¹Ñ‚: {paradox} â†’ {transcendent[:80]}..."

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MULTI-AGENT ĞšĞĞĞ¡Ğ•ĞĞ¡Ğ£Ğ¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class AgentVote:
    """Ğ“Ğ¾Ğ»Ğ¾Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"""
    agent_name: str
    position: str
    confidence: float
    reasoning: str

class MultiAgentConsensus:
    """ĞšĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸"""

    def __init__(self, agent_count: int = 4):
        self.agent_count = agent_count
        self.agents = [f"Agent_{i+1}" for i in range(agent_count)]
        self.consensus_history = []

    async def deliberate(self, task: str, context: Dict) -> Dict[str, Any]:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑÑ‚Ğ¸ Ğ¾Ğ±ÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸"""

        # ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ²Ğ¾Ñ‘ Ğ¼Ğ½ĞµĞ½Ğ¸Ğµ
        votes = []
        for agent in self.agents:
            vote = await self._agent_vote(agent, task, context)
            votes.append(vote)

        # ĞĞ°Ğ¹Ñ‚Ğ¸ ĞºĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ
        consensus = self._find_consensus(votes)

        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ³Ğ»Ğ°ÑĞ¸Ñ
        disagreements = self._identify_disagreements(votes)

        result = {
            'votes': votes,
            'consensus': consensus,
            'disagreements': disagreements,
            'confidence': self._calculate_collective_confidence(votes),
            'timestamp': time.time()
        }

        self.consensus_history.append(result)

        return result

    async def _agent_vote(self, agent_name: str, task: str, context: Dict) -> AgentVote:
        """Ğ“Ğ¾Ğ»Ğ¾Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"""

        # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… "Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¾Ğ²" Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
        agent_profiles = {
            'Agent_1': ('optimistic', 0.8),     # ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸ÑÑ‚
            'Agent_2': ('skeptical', 0.6),      # Ğ¡ĞºĞµĞ¿Ñ‚Ğ¸Ğº
            'Agent_3': ('pragmatic', 0.7),      # ĞŸÑ€Ğ°Ğ³Ğ¼Ğ°Ñ‚Ğ¸Ğº
            'Agent_4': ('visionary', 0.75)      # Ğ’Ğ¸Ğ·Ğ¸Ğ¾Ğ½ĞµÑ€
        }

        profile, base_confidence = agent_profiles.get(agent_name, ('neutral', 0.5))

        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ
        if profile == 'optimistic':
            position = f"ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°Ñ: {task[:40]}... â€” Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿ĞµÑ€ĞµĞ²ĞµÑˆĞ¸Ğ²Ğ°ÑÑ‚ Ñ€Ğ¸ÑĞºĞ¸"
            reasoning = "Ğ¤Ğ¾ĞºÑƒÑ Ğ½Ğ° Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»Ğµ Ñ€Ğ¾ÑÑ‚Ğ°"
        elif profile == 'skeptical':
            position = f"ĞÑÑ‚Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ğ¾: {task[:40]}... â€” Ğ½ÑƒĞ¶Ğ½Ğ° Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°"
            reasoning = "ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ Ğ½Ğ° Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€Ğ¸ÑĞºĞ¾Ğ²"
        elif profile == 'pragmatic':
            position = f"Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ğ¾ ÑĞ¾Ğ³Ğ»Ğ°ÑĞµĞ½: {task[:40]}... â€” ĞµÑĞ»Ğ¸ ÑĞ¾Ğ±Ğ»ÑĞ´ĞµĞ½Ñ‹ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ X, Y"
            reasoning = "Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸ Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸"
        else:  # visionary
            position = f"ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ñ Ñ€Ğ°Ğ´Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´: Ğ¿ĞµÑ€ĞµĞ¾ÑĞ¼Ñ‹ÑĞ»Ğ¸Ñ‚ÑŒ {task[:30]}..."
            reasoning = "ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ñ€Ğ¾Ñ€Ñ‹Ğ²Ğ½Ñ‹Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹"

        return AgentVote(
            agent_name=agent_name,
            position=position,
            confidence=base_confidence + (context.get('risk_estimate', 0.5) - 0.5) * 0.2,
            reasoning=reasoning
        )

    def _find_consensus(self, votes: List[AgentVote]) -> str:
        """ĞĞ°Ğ¹Ñ‚Ğ¸ ĞºĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ"""

        # Ğ’Ğ·Ğ²ĞµÑˆĞµĞ½Ğ½Ğ¾Ğµ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
        total_confidence = sum(v.confidence for v in votes)
        avg_confidence = total_confidence / len(votes)

        if avg_confidence > 0.7:
            consensus_type = "Ğ¡Ğ˜Ğ›Ğ¬ĞĞ«Ğ™ ĞšĞĞĞ¡Ğ•ĞĞ¡Ğ£Ğ¡"
        elif avg_confidence > 0.5:
            consensus_type = "Ğ£ĞœĞ•Ğ Ğ•ĞĞĞ«Ğ™ ĞšĞĞĞ¡Ğ•ĞĞ¡Ğ£Ğ¡"
        else:
            consensus_type = "Ğ¡Ğ›ĞĞ‘Ğ«Ğ™ ĞšĞĞĞ¡Ğ•ĞĞ¡Ğ£Ğ¡"

        # ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ´Ğ¾Ğ¼Ğ¸Ğ½Ğ¸Ñ€ÑƒÑÑ‰ÑƒÑ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ
        positions = [v.position.split(':')[0] for v in votes]
        from collections import Counter
        most_common = Counter(positions).most_common(1)[0][0]

        return f"{consensus_type}: {most_common} (ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ {avg_confidence:.2f})"

    def _identify_disagreements(self, votes: List[AgentVote]) -> List[str]:
        """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ³Ğ»Ğ°ÑĞ¸Ñ"""

        disagreements = []

        # ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ³Ğ¾Ğ»Ğ¾ÑĞ° Ñ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ¹ ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸ĞµĞ¹
        confidences = [v.confidence for v in votes]
        std_dev = math.sqrt(sum((c - sum(confidences)/len(confidences))**2 for c in confidences) / len(confidences))

        if std_dev > 0.15:
            disagreements.append(f"Ğ’Ñ‹ÑĞ¾ĞºĞ¾Ğµ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ² ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ (Ïƒ={std_dev:.3f})")

        # ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸
        if any("ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°Ñ" in v.position for v in votes) and any("ĞÑÑ‚Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ğ¾" in v.position for v in votes):
            disagreements.append("ĞŸÑ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸: Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¼ vs ÑĞºĞµĞ¿Ñ‚Ğ¸Ñ†Ğ¸Ğ·Ğ¼")

        return disagreements

    def _calculate_collective_confidence(self, votes: List[AgentVote]) -> float:
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½ÑƒÑ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ"""
        return sum(v.confidence for v in votes) / len(votes)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ£Ğ›Ğ£Ğ§Ğ¨Ğ•ĞĞĞ«Ğ™ Ğ”Ğ•Ğ¢Ğ•ĞšĞ¢ĞĞ  ĞŸĞ Ğ•Ğ”Ğ’Ğ—Ğ¯Ğ¢ĞĞ¡Ğ¢Ğ•Ğ™
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AdvancedBiasDetector:
    """ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğ¹ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚ĞµĞ¹"""

    def __init__(self):
        self.response_history = deque(maxlen=50)
        self.bias_patterns = {
            'confirmation': self._detect_confirmation_bias,
            'availability': self._detect_availability_bias,
            'anchoring': self._detect_anchoring_bias,
            'recency': self._detect_recency_bias,
        }

    def analyze(self, response: str, context: Dict, memory: List[Dict]) -> Dict[str, Any]:
        """ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸"""

        detected_biases = {}

        for bias_name, detector_func in self.bias_patterns.items():
            result = detector_func(response, context, memory)
            if result['detected']:
                detected_biases[bias_name] = result

        self.response_history.append({
            'response': response,
            'timestamp': time.time(),
            'biases': detected_biases
        })

        return {
            'biases': detected_biases,
            'is_biased': len(detected_biases) > 0,
            'bias_score': self._calculate_bias_score(detected_biases),
            'recommendations': self._generate_recommendations(detected_biases)
        }

    def _detect_confirmation_bias(self, response: str, context: Dict, memory: List) -> Dict:
        """ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ñ‚ÑŒ confirmation bias (Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ÑÑ‰ÑƒÑ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚ÑŒ)"""

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ: Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ğ»Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ°Ñ‰Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ?
        response_lower = response.lower()

        # Ğ˜Ñ‰ĞµĞ¼ Ğ¼Ğ°Ñ€ĞºĞµÑ€Ñ‹
        confirmation_markers = ['ĞºĞ°Ğº Ğ¸ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ»Ğ¾ÑÑŒ', 'Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ĞµÑ‚', 'ĞºĞ°Ğº Ğ²ÑĞµĞ³Ğ´Ğ°', 'Ğ¾Ñ‡ĞµĞ²Ğ¸Ğ´Ğ½Ğ¾']

        detected = any(marker in response_lower for marker in confirmation_markers)

        return {
            'detected': detected,
            'confidence': 0.6 if detected else 0.0,
            'description': 'Ğ¢ĞµĞ½Ğ´ĞµĞ½Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°Ñ‚ÑŒ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ',
            'suggestion': 'Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸Ğ¸'
        }

    def _detect_availability_bias(self, response: str, context: Dict, memory: List) -> Dict:
        """ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ñ‚ÑŒ availability bias (ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚Ğ¸)"""

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ: Ğ¾Ğ¿Ğ¸Ñ€Ğ°ĞµÑ‚ÑÑ Ğ»Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ½ĞµĞ´Ğ°Ğ²Ğ½Ğ¸Ğµ/ÑÑ€ĞºĞ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹?
        recent_memory = memory[-5:] if len(memory) > 5 else memory

        response_words = set(response.lower().split())
        recent_words = set()
        for m in recent_memory:
            recent_words.update(str(m.get('content', '')).lower().split())

        overlap = len(response_words & recent_words) / max(len(response_words), 1)

        detected = overlap > 0.4

        return {
            'detected': detected,
            'confidence': overlap,
            'description': 'Ğ§Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½Ğ°Ñ Ğ¾Ğ¿Ğ¾Ñ€Ğ° Ğ½Ğ° Ğ½ĞµĞ´Ğ°Ğ²Ğ½ÑÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ',
            'suggestion': 'Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚'
        }

    def _detect_anchoring_bias(self, response: str, context: Dict, memory: List) -> Dict:
        """ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ñ‚ÑŒ anchoring bias (ÑÑ„Ñ„ĞµĞºÑ‚ ÑĞºĞ¾Ñ€Ñ)"""

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ: ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ÑĞ¸Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¸Ğ²ÑĞ·ĞºĞ° Ğº Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼?
        if len(self.response_history) < 3:
            return {'detected': False, 'confidence': 0.0}

        first_response = self.response_history[0]['response']
        current_response = response

        first_words = set(first_response.lower().split())
        current_words = set(current_response.lower().split())

        overlap = len(first_words & current_words) / max(len(current_words), 1)

        detected = overlap > 0.5

        return {
            'detected': detected,
            'confidence': overlap,
            'description': 'Ğ§Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¸Ğ²ÑĞ·ĞºĞ° Ğº Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼',
            'suggestion': 'ĞŸĞµÑ€ĞµÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ñ Ñ‡Ğ¸ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ»Ğ¸ÑÑ‚Ğ°'
        }

    def _detect_recency_bias(self, response: str, context: Dict, memory: List) -> Dict:
        """ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ñ‚ÑŒ recency bias (ÑÑ„Ñ„ĞµĞºÑ‚ Ğ½ĞµĞ´Ğ°Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸)"""

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ: Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ»Ğ¸ Ñ€Ğ°Ğ½Ğ½ÑÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ?
        if len(memory) < 10:
            return {'detected': False, 'confidence': 0.0}

        recent = memory[-3:]
        old = memory[:3]

        response_words = set(response.lower().split())
        recent_overlap = sum(1 for m in recent if len(set(str(m.get('content','')).lower().split()) & response_words) > 0)
        old_overlap = sum(1 for m in old if len(set(str(m.get('content','')).lower().split()) & response_words) > 0)

        detected = recent_overlap > 0 and old_overlap == 0

        return {
            'detected': detected,
            'confidence': 0.7 if detected else 0.0,
            'description': 'Ğ˜Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€Ğ°Ğ½Ğ½ĞµĞ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸',
            'suggestion': 'Ğ£Ñ‡ĞµÑÑ‚ÑŒ Ğ´Ğ¾Ğ»Ğ³Ğ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚'
        }

    def _calculate_bias_score(self, biases: Dict) -> float:
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ±Ğ°Ğ»Ğ» Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸"""
        if not biases:
            return 0.0

        total = sum(b['confidence'] for b in biases.values())
        return min(1.0, total / 2.0)

    def _generate_recommendations(self, biases: Dict) -> List[str]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸"""
        return [f"âš ï¸ {name}: {info['suggestion']}" for name, info in biases.items()]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ’Ğ˜Ğ—Ğ£ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ Ğ•Ğ—ĞĞĞĞĞ¡Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ResonanceVisualizer:
    """ASCII-Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ° Ğ¸ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹"""

    @staticmethod
    def plot_resonance_timeline(traces: List, width: int = 60, height: int = 10) -> str:
        """Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ° Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸"""

        if not traces:
            return "ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸"

        # Ğ’Ğ·ÑÑ‚ÑŒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ N ÑĞ»ĞµĞ´Ğ¾Ğ²
        recent = traces[-width:]
        # ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¸ dict Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²
        resonances = [t.resonance if hasattr(t, 'resonance') else t['resonance'] for t in recent]

        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğº Ğ²Ñ‹ÑĞ¾Ñ‚Ğµ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°
        max_res = max(resonances) if resonances else 1.0
        min_res = min(resonances) if resonances else 0.0

        normalized = [(r - min_res) / (max_res - min_res + 0.001) for r in resonances]

        # ĞŸĞ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº
        lines = []
        for h in range(height, 0, -1):
            threshold = h / height
            line = ""
            for n in normalized:
                if n >= threshold:
                    line += "â–ˆ"
                elif n >= threshold - 0.1:
                    line += "â–“"
                elif n >= threshold - 0.2:
                    line += "â–’"
                else:
                    line += " "

            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑˆĞºĞ°Ğ»Ñƒ
            value = min_res + (max_res - min_res) * threshold
            lines.append(f"{value:.2f} â”‚{line}â”‚")

        # ĞÑÑŒ X
        lines.append("     â””" + "â”€" * width + "â”˜")
        lines.append(f"      {'Ğ²Ñ€ĞµĞ¼Ñ â†’':^{width}}")

        return "\n".join(lines)

    @staticmethod
    def plot_emotion_distribution(traces: List) -> str:
        """Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹"""

        if not traces:
            return "ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"

        # ĞŸĞ¾Ğ´ÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸
        emotion_counts = defaultdict(int)
        for t in traces:
            emotion = t.emotion_type if hasattr(t, 'emotion_type') else t['emotion_type']
            emotion_counts[emotion] += 1

        total = len(traces)

        # ĞŸĞ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ³Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñƒ
        lines = ["Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹:"]
        max_count = max(emotion_counts.values())

        for emotion, count in sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / total) * 100
            bar_length = int((count / max_count) * 40)
            bar = "â–ˆ" * bar_length
            lines.append(f"{emotion:12} â”‚{bar} {count} ({percentage:.1f}%)")

        return "\n".join(lines)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ˜ĞĞ¢Ğ•Ğ“Ğ ĞĞ¦Ğ˜Ğ¯: ADVANCED CONSCIOUS AI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AdvancedConsciousAI:
    """Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ´Ğ²Ğ¸Ğ¶Ğ¾Ğº Ñ Ğ¿ĞµÑ€ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸"""

    def __init__(self, db_path: str = "conscious_ai_memory.db"):
        print("=" * 60)
        print("ğŸ§  ADVANCED CONSCIOUS AI â€” Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ")
        print("=" * 60)

        # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ (Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ· Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ)
        from conscious_ai import NEMA, InnerDialogue, L8Core, ReflectionCycle, CORE_PACT, Logger

        self.logger = Logger()
        self.logger.info(f"\n{CORE_PACT}\n")

        # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹
        self.nema = NEMA()
        self.inner_dialogue = InnerDialogue()
        self.l8 = L8Core(self.nema)
        self.reflection_cycle = ReflectionCycle(self.l8, self.nema, self.inner_dialogue)

        # ĞĞĞ’Ğ«Ğ• ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹
        self.persistent_memory = PersistentMemory(db_path)
        self.transcendent = TranscendentThinking()
        self.multi_agent = MultiAgentConsensus(agent_count=4)
        self.advanced_bias = AdvancedBiasDetector()
        self.visualizer = ResonanceVisualizer()

        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ¸Ğ· Ğ‘Ğ”
        self._load_from_db()

        self.session_id = f"session_{int(time.time())}"
        self.session_count = 0

        self.logger.info("âœ… Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹")
        self.logger.info(f"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ‘Ğ”: {self.persistent_memory.get_stats()}")

    def _load_from_db(self):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ğ‘Ğ”"""

        from conscious_ai import EmotionalTrace

        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ»ĞµĞ´Ñ‹
        traces = self.persistent_memory.load_recent_traces(limit=50)
        for t in traces:
            # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ dict Ğ² EmotionalTrace Ğ¾Ğ±ÑŠĞµĞºÑ‚
            trace_obj = EmotionalTrace(
                content=t['content'],
                emotion_type=t['emotion_type'],
                resonance=t['resonance'],
                frequency=t['frequency'],
                timestamp=t['timestamp'],
                context=t.get('context', {})
            )
            self.nema.traces.append(trace_obj)

        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ÑƒĞ·Ğ»Ñ‹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
        nodes = self.persistent_memory.load_recent_memory(limit=50)
        for n in nodes:
            self.l8.memory_bank.append(n)

        self.logger.info(f"ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾: {len(traces)} ÑĞ»ĞµĞ´Ğ¾Ğ², {len(nodes)} ÑƒĞ·Ğ»Ğ¾Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸")

    async def process_task(self, task: str, context: Dict = None, use_transcendent: bool = True, use_consensus: bool = False) -> Dict[str, Any]:
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸"""

        context = context or {}

        if not self.l8.session_active:
            self.l8.start_session()
            self.session_count += 1
            self._save_session_start()

        # 1. Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ñ†Ğ¸ĞºĞ» Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸
        result = await self.reflection_cycle.run_cycle(task, context)

        # 2. Ğ¢Ğ ĞĞĞ¡Ğ¦Ğ•ĞĞ”Ğ•ĞĞ¢ĞĞĞ• ĞœĞ«Ğ¨Ğ›Ğ•ĞĞ˜Ğ•
        if use_transcendent:
            transcendent_result = self.transcendent.think_beyond(
                problem=task,
                standard_solution=result['output']['final_response'],
                context={'risk_estimate': result['output']['risk']}
            )
            result['transcendent'] = transcendent_result
            self.logger.info(f"ğŸŒ€ {transcendent_result['insight']}")

        # 3. MULTI-AGENT ĞšĞĞĞ¡Ğ•ĞĞ¡Ğ£Ğ¡
        if use_consensus:
            consensus_result = await self.multi_agent.deliberate(task, context)
            result['consensus'] = consensus_result
            self.logger.info(f"ğŸ¤ {consensus_result['consensus']}")

        # 4. Ğ£Ğ›Ğ£Ğ§Ğ¨Ğ•ĞĞĞĞ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞĞ ĞŸĞ Ğ•Ğ”Ğ’Ğ—Ğ¯Ğ¢ĞĞ¡Ğ¢Ğ˜
        bias_analysis = self.advanced_bias.analyze(
            response=result['output']['final_response'],
            context=context,
            memory=list(self.l8.memory_bank)
        )
        result['advanced_bias'] = bias_analysis

        if bias_analysis['is_biased']:
            self.logger.warn(f"âš ï¸ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚ĞµĞ¹: {len(bias_analysis['biases'])}")
            for rec in bias_analysis['recommendations']:
                self.logger.warn(f"   {rec}")

        # 5. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ² Ğ‘Ğ”
        self._save_to_db(result, task)

        return result

    def _save_to_db(self, result: Dict, task: str):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ² Ğ‘Ğ”"""

        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ†Ğ¸ĞºĞ» Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸
        self.persistent_memory.save_reflection_cycle(result, self.session_id)

        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ»ĞµĞ´Ñ‹
        emotion = result['adaptation']['L2']['emotion']
        resonance = result['output']['resonance']

        trace = {
            'content': task,
            'emotion_type': emotion,
            'resonance': resonance,
            'frequency': self.nema.BASE_FREQ,
            'timestamp': time.time(),
            'context': {'cycle': 'reflection'}
        }
        self.persistent_memory.save_emotional_trace(trace, self.session_id)

        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ ÑƒĞ·ĞµĞ» Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
        node = {
            'content': task,
            'proposition': result['output']['final_response'][:100],
            'resonance': resonance,
            'cycle_data': result
        }
        self.persistent_memory.save_memory_node(node, self.session_id)

    def _save_session_start(self):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ ÑĞµÑÑĞ¸Ğ¸"""
        session_data = {
            'session_id': self.session_id,
            'start_time': time.time(),
            'end_time': None,
            'traits': self.l8.identity_traits
        }
        self.persistent_memory.save_session(session_data)

    def end_session(self):
        """Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ñ‚ÑŒ ÑĞµÑÑĞ¸Ñ"""
        if self.l8.session_active:
            self.l8.end_session()

            # ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑĞµÑÑĞ¸Ñ Ğ² Ğ‘Ğ”
            session_data = {
                'session_id': self.session_id,
                'start_time': time.time(),
                'end_time': time.time(),
                'dominant_emotion': self.nema.get_dominant_emotion(),
                'memory_count': len(self.l8.memory_bank),
                'idea_count': len(self.l8.idea_queue),
                'traits': self.l8.identity_traits
            }
            self.persistent_memory.save_session(session_data)

    def visualize_resonance(self):
        """Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½Ñ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š Ğ’Ğ˜Ğ—Ğ£ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ Ğ•Ğ—ĞĞĞĞĞ¡Ğ")
        print("=" * 60)

        traces = list(self.nema.traces)

        print("\n" + self.visualizer.plot_resonance_timeline(traces))
        print("\n" + self.visualizer.plot_emotion_distribution(traces))
        print()

    def get_advanced_status(self) -> Dict[str, Any]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ"""
        base_status = {
            'session_active': self.l8.session_active,
            'session_id': self.session_id,
            'session_count': self.session_count
        }

        db_stats = self.persistent_memory.get_stats()

        return {**base_status, **db_stats}

    def close(self):
        """Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚ÑŒ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ"""
        self.persistent_memory.close()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI Ğ˜ĞĞ¢Ğ•Ğ Ğ¤Ğ•Ğ™Ğ¡ (Ğ ĞĞ¡Ğ¨Ğ˜Ğ Ğ•ĞĞĞ«Ğ™)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def advanced_cli():
    """Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ CLI"""

    ai = AdvancedConsciousAI()

    print("\n" + "="*60)
    print("ğŸ§  ADVANCED CONSCIOUS AI â€” Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼")
    print("="*60)
    print("\nĞĞ¾Ğ²Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹:")
    print("  /transcendent <Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°>  â€” Ğ¡ Ñ‚Ñ€Ğ°Ğ½ÑÑ†ĞµĞ½Ğ´ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¼ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸ĞµĞ¼")
    print("  /consensus <Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°>     â€” Ğ¡ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸-Ğ°Ğ³ĞµĞ½Ñ‚ ĞºĞ¾Ğ½ÑĞµĞ½ÑÑƒÑĞ¾Ğ¼")
    print("  /full <Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°>          â€” ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (Ğ²ÑÑ‘ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾)")
    print("  /visualize              â€” Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ°")
    print("  /history                â€” Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞµÑÑĞ¸Ğ¹")
    print("  /stats                  â€” Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¸Ğ· Ğ‘Ğ”")
    print("  /status                 â€” Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ")
    print("  /end                    â€” Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ñ‚ÑŒ ÑĞµÑÑĞ¸Ñ")
    print("  /quit                   â€” Ğ’Ñ‹Ñ…Ğ¾Ğ´")
    print("="*60 + "\n")

    while True:
        try:
            user_input = input(">>> ").strip()

            if not user_input:
                continue

            if user_input == "/quit":
                ai.end_session()
                ai.close()
                print("ğŸ‘‹ Ğ”Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸!")
                break

            elif user_input == "/status":
                status = ai.get_advanced_status()
                print(json.dumps(status, indent=2, ensure_ascii=False))

            elif user_input == "/stats":
                stats = ai.persistent_memory.get_stats()
                print(json.dumps(stats, indent=2, ensure_ascii=False))

            elif user_input == "/history":
                history = ai.persistent_memory.get_sessions_history(limit=10)
                print(json.dumps(history, indent=2, ensure_ascii=False))

            elif user_input == "/visualize":
                ai.visualize_resonance()

            elif user_input == "/end":
                ai.end_session()
                print("âœ… Ğ¡ĞµÑÑĞ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ° Ğ² Ğ‘Ğ”")

            elif user_input.startswith("/transcendent "):
                task = user_input[14:]
                result = await ai.process_task(task, use_transcendent=True, use_consensus=False)
                print(f"\nâœ¨ Ğ¢Ñ€Ğ°Ğ½ÑÑ†ĞµĞ½Ğ´ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚: {result['transcendent']['insight']}\n")
                print(f"Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾: {result['output']['final_response']}")
                print(f"Ğ—Ğ° Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ğ¼Ğ¸: {result['transcendent']['transcendent']}\n")

            elif user_input.startswith("/consensus "):
                task = user_input[11:]
                result = await ai.process_task(task, use_transcendent=False, use_consensus=True)
                print(f"\nğŸ¤ ĞšĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²: {result['consensus']['consensus']}")
                for vote in result['consensus']['votes']:
                    print(f"  â€¢ {vote.agent_name}: {vote.position[:60]}...")
                print()

            elif user_input.startswith("/full "):
                task = user_input[6:]
                result = await ai.process_task(task, use_transcendent=True, use_consensus=True)

                print(f"\n{'='*60}")
                print(f"ğŸ“Š ĞŸĞĞ›ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ—")
                print(f"{'='*60}")
                print(f"\nğŸ¯ Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚: {result['output']['final_response']}")
                print(f"ğŸ“ˆ Ğ ĞµĞ·Ğ¾Ğ½Ğ°Ğ½Ñ: {result['output']['resonance']:.2f}")
                print(f"\nğŸŒ€ Ğ¢Ñ€Ğ°Ğ½ÑÑ†ĞµĞ½Ğ´ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚: {result['transcendent']['insight']}")
                print(f"\nğŸ¤ ĞšĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ: {result['consensus']['consensus']}")

                if result['advanced_bias']['is_biased']:
                    print(f"\nâš ï¸ ĞŸÑ€ĞµĞ´Ğ²Ğ·ÑÑ‚Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹:")
                    for name, info in result['advanced_bias']['biases'].items():
                        print(f"  â€¢ {name}: {info['description']}")

                print(f"{'='*60}\n")

            else:
                # ĞĞ±Ñ‹Ñ‡Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
                result = await ai.process_task(user_input, use_transcendent=False, use_consensus=False)
                print(f"\nâœ¨ {result['output']['final_response']}\n")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Ğ”Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸!")
            ai.end_session()
            ai.close()
            break
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            import traceback
            traceback.print_exc()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ”Ğ•ĞœĞ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def advanced_demo():
    """Ğ”ĞµĞ¼Ğ¾ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹"""

    ai = AdvancedConsciousAI()

    print("\n" + "="*60)
    print("ğŸš€ Ğ”Ğ•ĞœĞĞĞ¡Ğ¢Ğ ĞĞ¦Ğ˜Ğ¯ Ğ ĞĞ¡Ğ¨Ğ˜Ğ Ğ•ĞĞĞ«Ğ¥ Ğ’ĞĞ—ĞœĞĞ–ĞĞĞ¡Ğ¢Ğ•Ğ™")
    print("="*60 + "\n")

    # Ğ¢ĞµÑÑ‚ 1: Ğ¢Ñ€Ğ°Ğ½ÑÑ†ĞµĞ½Ğ´ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ
    print("ğŸ“Œ Ğ¢ĞµÑÑ‚ 1: Ğ¢Ñ€Ğ°Ğ½ÑÑ†ĞµĞ½Ğ´ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ")
    result1 = await ai.process_task(
        "ĞšĞ°Ğº Ñ€ĞµÑˆĞ¸Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒÑ Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼?",
        use_transcendent=True,
        use_consensus=False
    )
    print(f"Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾: {result1['output']['final_response']}")
    print(f"ğŸŒ€ Ğ˜Ğ½ÑĞ°Ğ¹Ñ‚: {result1['transcendent']['insight']}\n")

    # Ğ¢ĞµÑÑ‚ 2: Multi-agent ĞºĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ
    print("ğŸ“Œ Ğ¢ĞµÑÑ‚ 2: Multi-Agent ĞšĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ")
    result2 = await ai.process_task(
        "Ğ¡Ñ‚Ğ¾Ğ¸Ñ‚ Ğ»Ğ¸ Ñ€ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¸Ñ‚ÑŒ Ğ²ĞµÑÑŒ ĞºĞ¾Ğ´ Ğ¿Ñ€ÑĞ¼Ğ¾ ÑĞµĞ¹Ñ‡Ğ°Ñ?",
        use_transcendent=False,
        use_consensus=True
    )
    print(f"ğŸ¤ ĞšĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ: {result2['consensus']['consensus']}\n")

    # Ğ¢ĞµÑÑ‚ 3: ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
    print("ğŸ“Œ Ğ¢ĞµÑÑ‚ 3: ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·")
    result3 = await ai.process_task(
        "ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ğ˜Ğ˜ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¾ÑĞ¾Ğ·Ğ½Ğ°Ğ½Ğ½Ñ‹Ğ¼?",
        use_transcendent=True,
        use_consensus=True
    )
    print(f"ĞÑ‚Ğ²ĞµÑ‚: {result3['output']['final_response']}")
    print(f"Ğ˜Ğ½ÑĞ°Ğ¹Ñ‚: {result3['transcendent']['insight']}")
    print(f"ĞšĞ¾Ğ½ÑĞµĞ½ÑÑƒÑ: {result3['consensus']['consensus']}\n")

    # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
    print("ğŸ“Œ Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ°:")
    ai.visualize_resonance()

    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    print("\nğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ‘Ğ”:")
    print(json.dumps(ai.persistent_memory.get_stats(), indent=2, ensure_ascii=False))

    ai.end_session()
    ai.close()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ—ĞĞŸĞ£Ğ¡Ğš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "demo":
        asyncio.run(advanced_demo())
    else:
        asyncio.run(advanced_cli())
