"""
ConsciousAI v5.0 - Meta-Cognitive Engine
–ú–µ—Ç–∞-–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫ - AI, –∫–æ—Ç–æ—Ä—ã–π –æ—Å–æ–∑–Ω–∞—ë—Ç —Å–≤–æ—ë –º—ã—à–ª–µ–Ω–∏–µ

–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
1. Reflector - —Ä–µ—Ñ–ª–µ–∫—Å–∏—è (–¥—É–º–∞–µ—Ç –æ —Å–≤–æ–∏—Ö –º—ã—Å–ª—è—Ö)
2. SelfEvaluator - —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∞ (–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ—à–µ–Ω–∏–π)
3. GapDetector - –¥–µ—Ç–µ–∫—Ç–æ—Ä –ø—Ä–æ–±–µ–ª–æ–≤ (–∑–Ω–∞–µ—Ç, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—Ç)
4. LearningPlanner - –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ–±—É—á–µ–Ω–∏—è (—É—á–∏—Ç—Å—è –Ω–∞ –æ–ø—ã—Ç–µ)
5. InnerDialogue - –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –¥–∏–∞–ª–æ–≥ (–æ–±—Å—É–∂–¥–µ–Ω–∏–µ —Å —Å–æ–±–æ–π)
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from enum import Enum
import json

from semantic_kernel import SemanticKernel, KernelType, SemanticCompressor
from semantic_memory import SemanticMemory


class ReflectionType(Enum):
    """–¢–∏–ø—ã —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏"""
    THOUGHT = "thought"              # –ú—ã—Å–ª—å –æ –º—ã—Å–ª–∏
    DECISION = "decision"            # –ê–Ω–∞–ª–∏–∑ —Ä–µ—à–µ–Ω–∏—è
    PATTERN = "pattern"              # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
    MISTAKE = "mistake"              # –ü—Ä–∏–∑–Ω–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
    INSIGHT = "insight"              # –û–∑–∞—Ä–µ–Ω–∏–µ
    QUESTION = "question"            # –í–æ–ø—Ä–æ—Å –∫ —Å–µ–±–µ


class ConfidenceLevel(Enum):
    """–£—Ä–æ–≤–Ω–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
    CERTAIN = 1.0        # –£–≤–µ—Ä–µ–Ω –Ω–∞ 100%
    HIGH = 0.8           # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    MEDIUM = 0.5         # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    LOW = 0.3            # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    UNCERTAIN = 0.1      # –ù–µ—É–≤–µ—Ä–µ–Ω


@dataclass
class Reflection:
    """
    –†–µ—Ñ–ª–µ–∫—Å–∏—è - —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ –æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º –º—ã—à–ª–µ–Ω–∏–∏

    –ü—Ä–∏–º–µ—Ä:
    "–Ø –∑–∞–º–µ—Ç–∏–ª, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—Å–µ–≥–¥–∞ –ø—Ä–æ—Å–∏—Ç '–Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ' - —ç—Ç–æ –ø–∞—Ç—Ç–µ—Ä–Ω.
     –ú–Ω–µ –Ω—É–∂–Ω–æ –±—ã—Å—Ç—Ä–µ–µ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –∫ –¥–µ–π—Å—Ç–≤–∏—é, –º–µ–Ω—å—à–µ —Å–ø—Ä–∞—à–∏–≤–∞—Ç—å."
    """
    reflection_type: ReflectionType
    content: str
    confidence: float
    triggered_by: Optional[str] = None  # –ß—Ç–æ –≤—ã–∑–≤–∞–ª–æ —Ä–µ—Ñ–ª–µ–∫—Å–∏—é
    insights: List[str] = field(default_factory=list)
    action_items: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "type": self.reflection_type.value,
            "content": self.content,
            "confidence": self.confidence,
            "triggered_by": self.triggered_by,
            "insights": self.insights,
            "action_items": self.action_items,
            "timestamp": self.timestamp.isoformat()
        }


@dataclass
class QualityMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ—à–µ–Ω–∏—è"""
    correctness: float = 0.5      # –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å (0-1)
    completeness: float = 0.5     # –ü–æ–ª–Ω–æ—Ç–∞ (0-1)
    efficiency: float = 0.5       # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (0-1)
    clarity: float = 0.5          # –Ø—Å–Ω–æ—Å—Ç—å (0-1)
    overall_score: float = 0.5    # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ (0-1)

    def calculate_overall(self):
        """–í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É"""
        self.overall_score = (
            self.correctness * 0.4 +
            self.completeness * 0.3 +
            self.efficiency * 0.2 +
            self.clarity * 0.1
        )
        return self.overall_score


@dataclass
class KnowledgeGap:
    """–ü—Ä–æ–±–µ–ª –≤ –∑–Ω–∞–Ω–∏—è—Ö"""
    topic: str
    description: str
    importance: float
    detected_at: datetime = field(default_factory=datetime.now)
    learning_strategy: Optional[str] = None


class Reflector:
    """
    –†–µ—Ñ–ª–µ–∫—Ç–æ—Ä - –¥—É–º–∞–µ—Ç –æ —Å–≤–æ–∏—Ö –º—ã—Å–ª—è—Ö

    –ü—Ä–∏–º–µ—Ä—ã —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏:
    - "–ü–æ—á–µ–º—É —è –≤—ã–±—Ä–∞–ª —ç—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥?"
    - "–ß—Ç–æ —è –º–æ–≥ —Å–¥–µ–ª–∞—Ç—å –ª—É—á—à–µ?"
    - "–ö–∞–∫–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω —è –≤–∏–∂—É –≤ –¥–µ–π—Å—Ç–≤–∏—è—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è?"
    """

    def __init__(self, memory: SemanticMemory):
        self.memory = memory
        self.reflections: List[Reflection] = []

    def reflect_on_decision(self, decision: str, context: Dict[str, Any]) -> Reflection:
        """
        –†–µ—Ñ–ª–µ–∫—Å–∏—è –æ –ø—Ä–∏–Ω—è—Ç–æ–º —Ä–µ—à–µ–Ω–∏–∏

        Args:
            decision: –û–ø–∏—Å–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è

        Returns:
            Reflection –æ–±—ä–µ–∫—Ç
        """
        # –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ —Ä–µ—à–µ–Ω–∏—è –≤ –ø–∞–º—è—Ç–∏
        similar_decisions = self.memory.search(
            decision,
            limit=5,
            kernel_types=[KernelType.DECISION]
        )

        # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
        insights = []
        confidence = 0.5

        if similar_decisions:
            insights.append(f"–ü–æ—Ö–æ–∂–∏—Ö —Ä–µ—à–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ: {len(similar_decisions)}")

            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –±—ã–ª–∏ –ª–∏ —É—Å–ø–µ—à–Ω—ã–µ –ø–æ—Ö–æ–∂–∏–µ —Ä–µ—à–µ–Ω–∏—è
            successful_count = sum(
                1 for k, _ in similar_decisions
                if k.metadata.get("success", False)
            )

            if successful_count > len(similar_decisions) / 2:
                insights.append("–ü–æ–¥–æ–±–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –æ–±—ã—á–Ω–æ —É—Å–ø–µ—à–Ω—ã")
                confidence = 0.8
            else:
                insights.append("–û—Å—Ç–æ—Ä–æ–∂–Ω–æ: –ø–æ–¥–æ–±–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏–Ω–æ–≥–¥–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã")
                confidence = 0.4

        # –°–æ–∑–¥–∞—Ç—å —Ä–µ—Ñ–ª–µ–∫—Å–∏—é
        reflection = Reflection(
            reflection_type=ReflectionType.DECISION,
            content=f"–†–µ—à–µ–Ω–∏–µ: {decision}",
            confidence=confidence,
            triggered_by="decision_making",
            insights=insights,
            action_items=["–û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç", "–°—Ä–∞–≤–Ω–∏—Ç—å —Å –ø–æ—Ö–æ–∂–∏–º–∏ —Å–ª—É—á–∞—è–º–∏"]
        )

        self.reflections.append(reflection)
        return reflection

    def reflect_on_pattern(self, observations: List[str]) -> Optional[Reflection]:
        """
        –û–±–Ω–∞—Ä—É–∂–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö

        Args:
            observations: –°–ø–∏—Å–æ–∫ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π

        Returns:
            Reflection –µ—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–∞–π–¥–µ–Ω
        """
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑: –Ω–∞–π—Ç–∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        word_counts = {}
        for obs in observations:
            words = obs.lower().split()
            for word in words:
                if len(word) > 4:  # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                    word_counts[word] = word_counts.get(word, 0) + 1

        # –ù–∞–π—Ç–∏ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Å–ª–æ–≤–∞
        frequent_words = [
            word for word, count in word_counts.items()
            if count >= len(observations) * 0.5  # –í 50%+ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π
        ]

        if frequent_words:
            pattern_description = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω: —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞ {frequent_words}"

            reflection = Reflection(
                reflection_type=ReflectionType.PATTERN,
                content=pattern_description,
                confidence=0.7,
                triggered_by="pattern_detection",
                insights=[
                    f"–°–ª–æ–≤–∞ '{', '.join(frequent_words)}' –ø–æ—è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç–æ",
                    "–≠—Ç–æ –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –≤–∞–∂–Ω—ã–µ —Ç–µ–º—ã"
                ],
                action_items=[
                    "–£—á–µ—Å—Ç—å —ç—Ç–æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –±—É–¥—É—â–∏—Ö –æ—Ç–≤–µ—Ç–∞—Ö",
                    "–ü—Ä–∏–æ—Ä–∏—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã"
                ]
            )

            self.reflections.append(reflection)
            return reflection

        return None

    def reflect_on_mistake(self, mistake: str, correction: str) -> Reflection:
        """
        –†–µ—Ñ–ª–µ–∫—Å–∏—è –æ–± –æ—à–∏–±–∫–µ

        Args:
            mistake: –û–ø–∏—Å–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
            correction: –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏–ª–∏

        Returns:
            Reflection –æ–±—ä–µ–∫—Ç
        """
        reflection = Reflection(
            reflection_type=ReflectionType.MISTAKE,
            content=f"–û—à–∏–±–∫–∞: {mistake}",
            confidence=0.9,  # –£–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —ç—Ç–æ –æ—à–∏–±–∫–∞
            triggered_by="error_detection",
            insights=[
                f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {correction}",
                "–í–∞–∂–Ω–æ –∏–∑–±–µ–≥–∞—Ç—å –ø–æ–¥–æ–±–Ω—ã—Ö –æ—à–∏–±–æ–∫ –≤ –±—É–¥—É—â–µ–º"
            ],
            action_items=[
                "–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –ø–µ—Ä–µ–¥ –ø–æ–¥–æ–±–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏",
                "–û–±–Ω–æ–≤–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑–±–µ–≥–∞–Ω–∏—è –æ—à–∏–±–æ–∫"
            ]
        )

        self.reflections.append(reflection)

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ø–∞–º—è—Ç—å –∫–∞–∫ –≤–∞–∂–Ω—ã–π —É—Ä–æ–∫
        compressor = SemanticCompressor()
        lesson_kernel = compressor.compress(
            f"–£—Ä–æ–∫: {mistake} -> {correction}",
            context={"is_lesson": True, "mistake": mistake}
        )
        lesson_kernel.importance = 0.9  # –í—ã—Å–æ–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å
        self.memory.store(lesson_kernel)

        return reflection

    def get_recent_reflections(self, limit: int = 10) -> List[Reflection]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏"""
        return self.reflections[-limit:]


class SelfEvaluator:
    """
    –°–∞–º–æ–æ—Ü–µ–Ω—â–∏–∫ - –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Å–≤–æ–∏—Ö —Ä–µ—à–µ–Ω–∏–π

    –í–æ–ø—Ä–æ—Å—ã:
    - "–ù–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ —è —Å–ø—Ä–∞–≤–∏–ª—Å—è?"
    - "–ß—Ç–æ –º–æ–∂–Ω–æ –±—ã–ª–æ —Å–¥–µ–ª–∞—Ç—å –ª—É—á—à–µ?"
    - "–î–æ–≤–æ–ª–µ–Ω –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º?"
    """

    def evaluate_response(
        self,
        user_query: str,
        ai_response: str,
        context: Optional[Dict] = None
    ) -> QualityMetrics:
        """
        –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞

        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            ai_response: –û—Ç–≤–µ—Ç AI
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç

        Returns:
            QualityMetrics —Å –æ—Ü–µ–Ω–∫–∞–º–∏
        """
        metrics = QualityMetrics()

        # 1. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å (–µ—Å—Ç—å –ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å?)
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        query_words = set(user_query.lower().split())
        response_words = set(ai_response.lower().split())
        overlap = len(query_words & response_words)
        metrics.correctness = min(overlap / max(len(query_words), 1), 1.0)

        # 2. –ü–æ–ª–Ω–æ—Ç–∞ (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏?)
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
        min_length = 50
        optimal_length = 200
        response_length = len(ai_response)

        if response_length < min_length:
            metrics.completeness = response_length / min_length
        elif response_length <= optimal_length:
            metrics.completeness = 1.0
        else:
            # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç - —Å–Ω–∏–∂–∞–µ–º –æ—Ü–µ–Ω–∫—É
            metrics.completeness = max(0.7, optimal_length / response_length)

        # 3. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–±—ã—Å—Ç—Ä–æ –ª–∏ —Ä–µ—à–µ–Ω–∞ –∑–∞–¥–∞—á–∞?)
        # –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        if context and "execution_time" in context:
            exec_time = context["execution_time"]
            if exec_time < 1.0:
                metrics.efficiency = 1.0
            elif exec_time < 5.0:
                metrics.efficiency = 0.8
            else:
                metrics.efficiency = 0.5
        else:
            metrics.efficiency = 0.7  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

        # 4. –Ø—Å–Ω–æ—Å—Ç—å (–ø–æ–Ω—è—Ç–µ–Ω –ª–∏ –æ—Ç–≤–µ—Ç?)
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        sentences = ai_response.split('.')
        avg_sentence_length = sum(len(s) for s in sentences) / max(len(sentences), 1)

        if avg_sentence_length < 100:
            metrics.clarity = 1.0
        elif avg_sentence_length < 200:
            metrics.clarity = 0.7
        else:
            metrics.clarity = 0.5

        # –í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É
        metrics.calculate_overall()

        return metrics

    def evaluate_code_quality(self, code: str) -> QualityMetrics:
        """
        –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞

        Args:
            code: –ö–æ–¥ –¥–ª—è –æ—Ü–µ–Ω–∫–∏

        Returns:
            QualityMetrics
        """
        metrics = QualityMetrics()

        # 1. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å (—Å–∏–Ω—Ç–∞–∫—Å–∏—Å)
        try:
            compile(code, '<string>', 'exec')
            metrics.correctness = 1.0
        except SyntaxError:
            metrics.correctness = 0.3

        # 2. –ü–æ–ª–Ω–æ—Ç–∞ (–µ—Å—Ç—å –ª–∏ docstrings, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏?)
        has_docstrings = '"""' in code or "'''" in code
        has_comments = '#' in code
        metrics.completeness = 0.5
        if has_docstrings:
            metrics.completeness += 0.3
        if has_comments:
            metrics.completeness += 0.2

        # 3. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–¥ –ª—É—á—à–µ)
        lines = code.strip().split('\n')
        code_lines = [l for l in lines if l.strip() and not l.strip().startswith('#')]
        if len(code_lines) < 50:
            metrics.efficiency = 1.0
        elif len(code_lines) < 100:
            metrics.efficiency = 0.8
        else:
            metrics.efficiency = 0.6

        # 4. –Ø—Å–Ω–æ—Å—Ç—å (—á–∏—Ç–∞–µ–º–æ—Å—Ç—å)
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ä–æ—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫
        has_type_hints = ':' in code and '->' in code
        has_meaningful_names = not any(
            bad in code for bad in ['x =', 'y =', 'temp =', 'tmp =']
        )

        metrics.clarity = 0.5
        if has_type_hints:
            metrics.clarity += 0.25
        if has_meaningful_names:
            metrics.clarity += 0.25

        metrics.calculate_overall()
        return metrics


class GapDetector:
    """
    –î–µ—Ç–µ–∫—Ç–æ—Ä –ø—Ä–æ–±–µ–ª–æ–≤ - –Ω–∞—Ö–æ–¥–∏—Ç –ø—Ä–æ–±–µ–ª—ã –≤ –∑–Ω–∞–Ω–∏—è—Ö

    –ü—Ä–∏–Ω—Ü–∏–ø: "–ó–Ω–∞–Ω–∏–µ –æ –Ω–µ–∑–Ω–∞–Ω–∏–∏ - —ç—Ç–æ —Ç–æ–∂–µ –∑–Ω–∞–Ω–∏–µ"
    """

    def __init__(self, memory: SemanticMemory):
        self.memory = memory
        self.known_gaps: List[KnowledgeGap] = []

    def detect_gaps(self, topic: str) -> List[KnowledgeGap]:
        """
        –û–±–Ω–∞—Ä—É–∂–∏—Ç—å –ø—Ä–æ–±–µ–ª—ã –≤ –∑–Ω–∞–Ω–∏—è—Ö –ø–æ —Ç–µ–º–µ

        Args:
            topic: –¢–µ–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        """
        # –ü–æ–∏—Å–∫–∞—Ç—å –≤ –ø–∞–º—è—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ
        related_kernels = self.memory.search(topic, limit=20)

        # –ï—Å–ª–∏ –º–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ - —ç—Ç–æ –ø—Ä–æ–±–µ–ª
        if len(related_kernels) < 3:
            gap = KnowledgeGap(
                topic=topic,
                description=f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–Ω–∞–Ω–∏–π –æ '{topic}'",
                importance=0.7,
                learning_strategy="–°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –¥–∏–∞–ª–æ–≥ –∏–ª–∏ –ø–æ–∏—Å–∫"
            )
            self.known_gaps.append(gap)
            return [gap]

        # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–Ω–æ—Ç—É (–µ—Å—Ç—å –ª–∏ —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∑—ë—Ä–µ–Ω?)
        kernel_types = set(k.kernel_type for k, _ in related_kernels)
        expected_types = {KernelType.FACT, KernelType.INSIGHT, KernelType.DECISION}

        missing_types = expected_types - kernel_types

        gaps = []
        if missing_types:
            for missing_type in missing_types:
                gap = KnowledgeGap(
                    topic=f"{topic} ({missing_type.value})",
                    description=f"–ù–µ—Ç {missing_type.value} –æ '{topic}'",
                    importance=0.5,
                    learning_strategy=f"–ü–æ–ª—É—á–∏—Ç—å {missing_type.value} —á–µ—Ä–µ–∑ –æ–ø—ã—Ç –∏–ª–∏ –æ–±—É—á–µ–Ω–∏–µ"
                )
                gaps.append(gap)
                self.known_gaps.append(gap)

        return gaps

    def assess_confidence(self, topic: str) -> Tuple[ConfidenceLevel, str]:
        """
        –û—Ü–µ–Ω–∏—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∑–Ω–∞–Ω–∏—è—Ö –ø–æ —Ç–µ–º–µ

        Args:
            topic: –¢–µ–º–∞

        Returns:
            (ConfidenceLevel, reasoning)
        """
        related_kernels = self.memory.search(topic, limit=10)

        # –ú–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ = –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        if len(related_kernels) == 0:
            return (
                ConfidenceLevel.UNCERTAIN,
                f"–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ '{topic}'"
            )
        elif len(related_kernels) < 3:
            return (
                ConfidenceLevel.LOW,
                f"–ú–∞–ª–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ '{topic}' ({len(related_kernels)} –∑—ë—Ä–µ–Ω)"
            )
        elif len(related_kernels) < 7:
            return (
                ConfidenceLevel.MEDIUM,
                f"–£–º–µ—Ä–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ '{topic}'"
            )
        elif len(related_kernels) < 15:
            return (
                ConfidenceLevel.HIGH,
                f"–ú–Ω–æ–≥–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ '{topic}'"
            )
        else:
            return (
                ConfidenceLevel.CERTAIN,
                f"–û—á–µ–Ω—å –º–Ω–æ–≥–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ '{topic}' ({len(related_kernels)} –∑—ë—Ä–µ–Ω)"
            )


class LearningPlanner:
    """
    –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ–±—É—á–µ–Ω–∏—è - –ø–ª–∞–Ω–∏—Ä—É–µ—Ç, –∫–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–±–µ–ª—ã

    –°—Ç—Ä–∞—Ç–µ–≥–∏–∏:
    - –ê–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (–∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã)
    - –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–ø—ã—Ç–µ (–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏ —É—á–∏—Ç—å—Å—è –Ω–∞ –æ—à–∏–±–∫–∞—Ö)
    - –û–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–æ–≥–∏–∏ (–ø—Ä–∏–º–µ–Ω—è—Ç—å –∑–Ω–∞–Ω–∏—è –∏–∑ –¥—Ä—É–≥–∏—Ö –æ–±–ª–∞—Å—Ç–µ–π)
    """

    def create_learning_plan(self, gaps: List[KnowledgeGap]) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–±–µ–ª–æ–≤

        Args:
            gaps: –°–ø–∏—Å–æ–∫ –ø—Ä–æ–±–µ–ª–æ–≤

        Returns:
            –ü–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è
        """
        # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        sorted_gaps = sorted(gaps, key=lambda g: g.importance, reverse=True)

        plan = {
            "total_gaps": len(gaps),
            "priority_gaps": [],
            "strategies": [],
            "estimated_effort": "medium"
        }

        for gap in sorted_gaps[:5]:  # –¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö
            plan["priority_gaps"].append({
                "topic": gap.topic,
                "importance": gap.importance,
                "strategy": gap.learning_strategy or "–û–±—â–µ–µ –∏–∑—É—á–µ–Ω–∏–µ"
            })

            # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
            if "–æ–ø—ã—Ç" in gap.learning_strategy.lower():
                plan["strategies"].append("experiential_learning")
            else:
                plan["strategies"].append("active_inquiry")

        # –û—Ü–µ–Ω–∏—Ç—å —É—Å–∏–ª–∏—è
        if len(gaps) > 10:
            plan["estimated_effort"] = "high"
        elif len(gaps) > 5:
            plan["estimated_effort"] = "medium"
        else:
            plan["estimated_effort"] = "low"

        return plan


class InnerDialogue:
    """
    –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –¥–∏–∞–ª–æ–≥ - AI –æ–±—Å—É–∂–¥–∞–µ—Ç —Å —Å–∞–º–∏–º —Å–æ–±–æ–π

    –ü—Ä–∏–º–µ—Ä—ã:
    Q: "–ü–æ—á–µ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç '–Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ'?"
    A: "–í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω —Ü–µ–Ω–∏—Ç —Å–∫–æ—Ä–æ—Å—Ç—å. –ò–ª–∏ —É –Ω–µ–≥–æ —Å—Ä–æ—á–Ω—ã–π –ø—Ä–æ–µ–∫—Ç."
    Q: "–ö–∞–∫ —è –º–æ–≥—É —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–µ–µ?"
    A: "–ú–µ–Ω—å—à–µ —Å–ø—Ä–∞—à–∏–≤–∞—Ç—å, –±–æ–ª—å—à–µ –¥–µ–ª–∞—Ç—å. –ü—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥."
    """

    def __init__(self):
        self.dialogue_history: List[Dict[str, str]] = []

    def ask_self(self, question: str) -> str:
        """
        –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å —Å–∞–º–æ–º—É —Å–µ–±–µ

        Args:
            question: –í–æ–ø—Ä–æ—Å

        Returns:
            –û—Ç–≤–µ—Ç (—Å–∞–º–æ–∞–Ω–∞–ª–∏–∑)
        """
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Å–∞–º–æ–æ—Ç–≤–µ—Ç–æ–≤
        answer = self._generate_self_answer(question)

        self.dialogue_history.append({
            "question": question,
            "answer": answer,
            "timestamp": datetime.now().isoformat()
        })

        return answer

    def _generate_self_answer(self, question: str) -> str:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫ —Å–µ–±–µ"""
        question_lower = question.lower()

        # –ü—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if "–ø–æ—á–µ–º—É" in question_lower:
            return "–í–æ–∑–º–æ–∂–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è —Ü–µ–ª–∏ –∏–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—É –ø–æ–≤–µ–¥–µ–Ω–∏—è."

        if "–∫–∞–∫" in question_lower:
            return "–ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–±–∏—Ç—å –Ω–∞ —à–∞–≥–∏ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã."

        if "—á—Ç–æ" in question_lower:
            return "–ù—É–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –≤—ã–±—Ä–∞—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –≤–∞—Ä–∏–∞–Ω—Ç."

        return "–¢—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞."

    def get_dialogue(self, limit: int = 10) -> List[Dict[str, str]]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞"""
        return self.dialogue_history[-limit:]


class MetaCognitiveEngine:
    """
    –ú–µ—Ç–∞-–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫ - –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

    –ì–ª–∞–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –º–µ—Ç–∞-—Å–æ–∑–Ω–∞–Ω–∏—è
    """

    def __init__(self, memory: SemanticMemory):
        self.memory = memory
        self.reflector = Reflector(memory)
        self.evaluator = SelfEvaluator()
        self.gap_detector = GapDetector(memory)
        self.learning_planner = LearningPlanner()
        self.inner_dialogue = InnerDialogue()

    def think_about_thinking(self, thought: str) -> Dict[str, Any]:
        """
        –ú–µ—Ç–∞-–º—ã—à–ª–µ–Ω–∏–µ - –¥—É–º–∞—Ç—å –æ —Å–≤–æ—ë–º –º—ã—à–ª–µ–Ω–∏–∏

        Args:
            thought: –ú—ã—Å–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑–∞
        """
        result = {
            "original_thought": thought,
            "reflection": None,
            "quality": None,
            "gaps": [],
            "learning_plan": None,
            "inner_dialogue": []
        }

        # 1. –†–µ—Ñ–ª–µ–∫—Å–∏—è
        reflection = self.reflector.reflect_on_decision(thought, {})
        result["reflection"] = reflection.to_dict()

        # 2. –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º—ã—Å–ª–∏
        quality = self.evaluator.evaluate_response("", thought)
        result["quality"] = {
            "overall": quality.overall_score,
            "completeness": quality.completeness,
            "clarity": quality.clarity
        }

        # 3. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤
        gaps = self.gap_detector.detect_gaps(thought)
        result["gaps"] = [
            {"topic": g.topic, "importance": g.importance}
            for g in gaps
        ]

        # 4. –ü–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è
        if gaps:
            result["learning_plan"] = self.learning_planner.create_learning_plan(gaps)

        # 5. –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –¥–∏–∞–ª–æ–≥
        question = f"–ß—Ç–æ —è –¥—É–º–∞—é –æ: {thought[:50]}...?"
        answer = self.inner_dialogue.ask_self(question)
        result["inner_dialogue"] = [
            {"question": question, "answer": answer}
        ]

        return result


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üß† Meta-Cognitive Engine - –ú–µ—Ç–∞-—Å–æ–∑–Ω–∞–Ω–∏–µ\n")

    # –°–æ–∑–¥–∞—Ç—å –ø–∞–º—è—Ç—å –∏ –¥–≤–∏–∂–æ–∫
    memory = SemanticMemory(db_path="test_metacog.db")
    engine = MetaCognitiveEngine(memory)

    # –ü—Ä–∏–º–µ—Ä 1: –†–µ—Ñ–ª–µ–∫—Å–∏—è –æ —Ä–µ—à–µ–Ω–∏–∏
    print("–ü—Ä–∏–º–µ—Ä 1: –†–µ—Ñ–ª–µ–∫—Å–∏—è")
    decision = "–†–µ—à–∏–ª —Å–æ–∑–¥–∞—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –ø–∞–º—è—Ç—å –¥–ª—è —Å–∂–∞—Ç–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"
    reflection = engine.reflector.reflect_on_decision(decision, {})
    print(f"  –†–µ—à–µ–Ω–∏–µ: {decision}")
    print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {reflection.confidence}")
    print(f"  –ò–Ω—Å–∞–π—Ç—ã: {reflection.insights}\n")

    # –ü—Ä–∏–º–µ—Ä 2: –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞
    print("–ü—Ä–∏–º–µ—Ä 2: –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞")
    response = "–°–æ–∑–¥–∞–ª –º–æ–¥—É–ª—å semantic_memory.py —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π –∏ –∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"
    quality = engine.evaluator.evaluate_response("", response)
    print(f"  –û—Ç–≤–µ—Ç: {response}")
    print(f"  –û—Ü–µ–Ω–∫–∞: {quality.overall_score:.2f}")
    print(f"  –ü–æ–ª–Ω–æ—Ç–∞: {quality.completeness:.2f}")
    print(f"  –Ø—Å–Ω–æ—Å—Ç—å: {quality.clarity:.2f}\n")

    # –ü—Ä–∏–º–µ—Ä 3: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤
    print("–ü—Ä–∏–º–µ—Ä 3: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤")
    gaps = engine.gap_detector.detect_gaps("–∫–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è")
    for gap in gaps:
        print(f"  –ü—Ä–æ–±–µ–ª: {gap.topic}")
        print(f"  –í–∞–∂–Ω–æ—Å—Ç—å: {gap.importance}")
        print(f"  –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {gap.learning_strategy}\n")

    # –ü—Ä–∏–º–µ—Ä 4: –ú–µ—Ç–∞-–º—ã—à–ª–µ–Ω–∏–µ
    print("–ü—Ä–∏–º–µ—Ä 4: –ú–µ—Ç–∞-–º—ã—à–ª–µ–Ω–∏–µ")
    thought = "–ù—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è AI"
    meta_result = engine.think_about_thinking(thought)
    print(f"  –ú—ã—Å–ª—å: {thought}")
    print(f"  –ö–∞—á–µ—Å—Ç–≤–æ –º—ã—Å–ª–∏: {meta_result['quality']['overall']:.2f}")
    print(f"  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–±–µ–ª–æ–≤: {len(meta_result['gaps'])}")
    if meta_result['learning_plan']:
        print(f"  –ü–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è: {meta_result['learning_plan']['estimated_effort']} —É—Å–∏–ª–∏–π")

    print("\n‚úÖ –ú–µ—Ç–∞-–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
