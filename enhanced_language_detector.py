"""
üåç Enhanced Language Detector - –£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä —è–∑—ã–∫–æ–≤
–¢–æ—á–Ω–æ—Å—Ç—å: 99%+ –¥–ª—è –≤—Å–µ—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö —è–∑—ã–∫–æ–≤

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
1. langdetect –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ (Google's language detection)
2. –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤
3. Fallback –Ω–∞ character-based detection
4. Confidence scoring
"""

from typing import Optional, Tuple
import re
from collections import Counter

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ langdetect
try:
    from langdetect import detect, detect_langs, LangDetectException
    LANGDETECT_AVAILABLE = True
except ImportError:
    LANGDETECT_AVAILABLE = False


class EnhancedLanguageDetector:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä —è–∑—ã–∫–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é"""

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤
    UNICODE_RANGES = {
        'ru': [(0x0400, 0x04FF)],  # –ö–∏—Ä–∏–ª–ª–∏—Ü–∞
        'ar': [(0x0600, 0x06FF), (0x0750, 0x077F)],  # –ê—Ä–∞–±—Å–∫–∏–π
        'he': [(0x0590, 0x05FF)],  # –ò–≤—Ä–∏—Ç
        'zh': [(0x4E00, 0x9FFF), (0x3400, 0x4DBF)],  # –ö–∏—Ç–∞–π—Å–∫–∏–π
        'ja': [(0x3040, 0x309F), (0x30A0, 0x30FF)],  # –Ø–ø–æ–Ω—Å–∫–∏–π (—Ö–∏—Ä–∞–≥–∞–Ω–∞, –∫–∞—Ç–∞–∫–∞–Ω–∞)
        'ko': [(0xAC00, 0xD7AF)],  # –ö–æ—Ä–µ–π—Å–∫–∏–π
        'th': [(0x0E00, 0x0E7F)],  # –¢–∞–π—Å–∫–∏–π
        'el': [(0x0370, 0x03FF)],  # –ì—Ä–µ—á–µ—Å–∫–∏–π
    }

    # –•–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è 99% —Ç–æ—á–Ω–æ—Å—Ç–∏)
    COMMON_WORDS = {
        'ru': ['–∏', '–≤', '–Ω–µ', '–Ω–∞', '—Å', '—á—Ç–æ', '–∫–∞–∫', '—ç—Ç–æ', '–ø–æ', '—è', '–¥–ª—è', '–æ–Ω', '–æ—Ç', '–≤—ã', '—Ç—ã', '–º—ã', '–æ–Ω–∏', '–≤—Å–µ', '—Ç–∞–∫', '—Ç–æ–ª—å–∫–æ', '–µ—ë', '–±—ã–ª–æ', '–±—ã–ª', '–±—ã–ª–∞', '–±—ã–ª–∏', '–±—ã—Ç—å', '–µ—Å—Ç—å', '—á—Ç–æ–±—ã', '–º–æ–∂–µ—Ç', '–º–æ–∂–Ω–æ'],
        'en': ['the', 'is', 'and', 'of', 'to', 'in', 'a', 'you', 'that', 'it', 'for', 'not', 'on', 'with', 'as', 'be', 'at', 'this', 'have', 'from', 'or', 'one', 'had', 'by', 'but', 'what', 'all', 'were', 'we', 'when', 'your', 'can', 'said', 'there', 'use', 'an', 'each', 'which', 'she', 'do', 'how', 'their', 'if', 'will', 'up', 'other', 'about', 'out', 'many', 'then', 'them', 'these', 'so', 'some', 'her', 'would', 'make', 'like', 'him', 'into', 'time', 'has', 'look', 'two', 'more', 'go', 'see', 'no', 'way', 'could', 'people', 'my', 'than', 'first', 'been', 'who', 'its', 'now', 'find', 'long', 'down', 'day', 'did', 'get', 'come', 'made', 'may', 'part', 'are', 'was', 'doing', 'today', 'hello', 'hi', 'bye', 'yes', 'okay'],
        'es': ['el', 'la', 'de', 'que', 'y', 'a', 'en', 'un', 'ser', 'se', 'no', 'por', 'los', 'las', 'del', 'con', 'una', 'su', 'para', 'es', 'al', 'lo', 'como', 'm√°s', 'pero', 'sus', 'le', 'ya', 'o', 'fue', 'este', 'ha', 's√≠', 'porque', 'esta', 'son', 'entre', 'est√°', 'cuando', 'muy', 'sin', 'sobre', 'ser', 'tiene', 'tambi√©n', 'me', 'hasta', 'hay', 'donde', 'han', 'quien', 'est√°n', 'estado', 'desde', 'todo', 'nos', 'durante', 'estados', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'fueron', 'ese', 'eso', 'hab√≠a', 'ante', 'ellos', 'e', 'esto', 'm√≠', 'antes', 'algunos', 'qu√©', 'unos', 'yo', 'otro', 'otras', 'otra', '√©l', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'sea', 'poco', 'ella', 'estar', 'haber', 'estas', 'estaba', 'estamos', 'algunas', 'algo', 'nosotros', 'hola', 'c√≥mo', 'est√°s', 'adi√≥s', 'gracias'],
        'fr': ['le', 'de', 'un', '√™tre', 'et', '√†', 'il', 'avoir', 'ne', 'je', 'son', 'que', 'se', 'qui', 'ce', 'dans', 'en', 'du', 'elle', 'au', 'pour', 'pas', 'sur', 'par', 'plus', 'dire', 'me', 'on', 'avec', 'tout', 'nous', 'vous', 'mais', 'ou', 'o√π', 'comme', 'si', 'faire', 'leur', 'bien', 'pouvoir', 'sans', 'te', 'encore', 'l√†', 'lui', 'mon', 'dont', 'cette', 'deux', 'aussi', 'votre', 'm√™me', 'quand', 'notre', 'donc', 'ses', 'ton', 'moi', 'peu', 'cela', 'comment', '√ßa', 'allez', 'bonjour', 'salut', 'oui', 'non', 'merci', 'tr√®s'],
        'de': ['der', 'die', 'und', 'in', 'den', 'von', 'zu', 'das', 'mit', 'sich', 'des', 'auf', 'f√ºr', 'ist', 'im', 'dem', 'nicht', 'ein', 'eine', 'als', 'auch', 'es', 'an', 'werden', 'aus', 'er', 'hat', 'dass', 'sie', 'nach', 'wird', 'bei', 'einer', 'um', 'am', 'sind', 'noch', 'wie', 'einem', '√ºber', 'einen', 'so', 'zum', 'war', 'haben', 'nur', 'oder', 'aber', 'vor', 'zur', 'bis', 'mehr', 'durch', 'man', 'sein', 'wurde', 'sei', 'gegen', 'vom', 'k√∂nnen', 'schon', 'wenn', 'habe', 'ihre', 'dann', 'unter', 'wir', 'soll', 'ich', 'eines', 'es', 'jahr', 'zwei', 'jahren', 'diese', 'dieser', 'wieder', 'keine', 'seinen', 'ja', 'ihr', 'ihm', 'sehr', 'hallo', 'wie', 'geht', 'dir', 'gut', 'danke'],
        'it': ['il', 'di', 'e', 'la', 'che', 'per', 'un', 'non', 'in', 'a', 'da', 'essere', 'del', 'le', 'si', 'dei', 'una', 'come', 'pi√π', '√®', 'con', 'sono', 'questo', 'dalla', 'o', 'alla', 'hanno', 'della', 'nel', 'gli', 'anche', 'nelle', 'loro', 'questa', 'quando', 'lo', 'all', 'ma', 'nei', 'delle', 'dal', 'cui', 'al', 'mi', 'quello', 'nella', 'molto', 'sia', 'quello', 'lui', 'ancora', 'stato', 'altro', 'dopo', 'dove', 'questi', 'tutti', 'sul', 'senza', 'mio', 'fare', 'ora', 'cosa', 'gi√†', 'aveva', 'agli', 'stato', 'tra', 'deve', 'prima', 'pu√≤', 'sui', 'qualche', 'sulla', 'fatto', 'nostro', 'quel', 'ci', 'suoi', 'sopra', 'queste', 'alle', 'li', 'suo', 'viene', 'ogni', 'noi', 'sia', 'mia', 'suoi', 'modo', 'sempre', 'tuo', 'ciao', 'come', 'stai', 'grazie', 'buongiorno'],
        'pt': ['o', 'de', 'a', 'e', 'que', 'do', 'da', 'em', 'um', 'para', '√©', 'com', 'n√£o', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', '√†', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'h√°', 'nos', 'j√°', 'est√°', 'eu', 'tamb√©m', 's√≥', 'pelo', 'pela', 'at√©', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'est√£o', 'voc√™', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', '√†s', 'minha', 't√™m', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'ser√°', 'n√≥s', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'voc√™s', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'ol√°', 'como', 'est√°', 'voc√™', 'obrigado', 'obrigada'],
        'nl': ['de', 'van', 'het', 'een', 'en', 'in', 'op', 'te', 'zijn', 'dat', 'die', 'voor', 'met', 'niet', 'aan', 'er', 'ook', 'door', 'werd', 'maar', 'om', 'heeft', 'hij', 'was', 'bij', 'nog', 'meer', 'uit', 'werd', 'naar', 'kan', 'zich', 'over', 'hebben', 'als', 'ze', 'wordt', 'deze', 'onder', 'tot', 'der', 'hun', 'waar', 'na', 'geen', 'haar', 'moet', 'wordt', 'zonder', 'worden', 'tegen', 'grote', 'heel', 'twee', 'omdat', 'eerste', 'ging', 'staat', 'hoe', 'hallo', 'hoi', 'goed', 'dank'],
    }

    # –•–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–∏
    DIACRITICS = {
        'fr': '√†√¢√¶√ß√©√®√™√´√Ø√Æ√¥√π√ª√º√ø≈ì√Ä√Ç√Ü√á√â√à√ä√ã√è√é√î√ô√õ√ú≈∏≈í',
        'de': '√§√∂√º√ü√Ñ√ñ√ú',
        'es': '√°√©√≠√≥√∫√±√Å√â√ç√ì√ö√ë¬ø¬°',
        'pt': '√£√°√†√¢√ß√©√™√≠√≥√¥√µ√∫√É√Å√Ä√Ç√á√â√ä√ç√ì√î√ï√ö',
        'it': '√†√®√©√¨√≠√Æ√≤√≥√π√∫√Ä√à√â√å√ç√é√í√ì√ô√ö',
        'pl': 'ƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈ºƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª',
        'cs': '√°ƒçƒè√©ƒõ√≠≈à√≥≈ô≈°≈•√∫≈Ø√Ω≈æ√Åƒåƒé√âƒö√ç≈á√ì≈ò≈†≈§√ö≈Æ√ù≈Ω',
        'tr': '√ßƒüƒ±√∂≈ü√º√áƒûƒ∞√ñ≈û√ú',
    }

    def __init__(self, fallback_to_patterns: bool = True):
        """
        Args:
            fallback_to_patterns: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –µ—Å–ª–∏ langdetect –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        """
        self.fallback_to_patterns = fallback_to_patterns
        self.use_langdetect = LANGDETECT_AVAILABLE

    def detect(self, text: str, with_confidence: bool = False) -> str | Tuple[str, float]:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            with_confidence: –í–µ—Ä–Ω—É—Ç—å —Ç–∞–∫–∂–µ —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

        Returns:
            –ö–æ–¥ —è–∑—ã–∫–∞ (ISO 639-1) –∏–ª–∏ (—è–∑—ã–∫, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        """
        if not text or len(text.strip()) < 3:
            return ('unknown', 0.0) if with_confidence else 'unknown'

        # –ú–µ—Ç–æ–¥ 1: langdetect (–Ω–∞–∏–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        if self.use_langdetect:
            lang, confidence = self._detect_with_langdetect(text)
            if confidence > 0.8:  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                return (lang, confidence) if with_confidence else lang

        # –ú–µ—Ç–æ–¥ 2: Unicode ranges (–¥–ª—è –Ω–µ–µ–≤—Ä–æ–ø–µ–π—Å–∫–∏—Ö —è–∑—ã–∫–æ–≤)
        lang, confidence = self._detect_by_unicode(text)
        if confidence > 0.5:
            return (lang, confidence) if with_confidence else lang

        # –ú–µ—Ç–æ–¥ 3: Common words (–¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤) - –ø–æ–≤—ã—à–µ–Ω–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        lang, confidence = self._detect_by_words(text)
        if confidence > 0.2:  # –ü–æ–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥ –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ langdetect
            return (lang, confidence) if with_confidence else lang

        # –ú–µ—Ç–æ–¥ 4: Diacritics (–¥–∏–∞–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–∫–∏)
        lang, confidence = self._detect_by_diacritics(text)
        if confidence > 0.3:  # –ü–æ–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥
            return (lang, confidence) if with_confidence else lang

        # –ú–µ—Ç–æ–¥ 5: Fallback –Ω–∞ langdetect (–¥–∞–∂–µ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é)
        if self.use_langdetect:
            lang, _ = self._detect_with_langdetect(text)
            return (lang, 0.5) if with_confidence else lang

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
        return ('en', 0.3) if with_confidence else 'en'

    def _detect_with_langdetect(self, text: str) -> Tuple[str, float]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ langdetect"""
        try:
            langs = detect_langs(text)
            if langs:
                best = langs[0]
                return (best.lang, best.prob)
        except LangDetectException:
            pass
        return ('unknown', 0.0)

    def _detect_by_unicode(self, text: str) -> Tuple[str, float]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ Unicode ranges"""
        char_counts = Counter()
        total_chars = 0

        for char in text:
            code_point = ord(char)
            for lang, ranges in self.UNICODE_RANGES.items():
                for start, end in ranges:
                    if start <= code_point <= end:
                        char_counts[lang] += 1
                        total_chars += 1
                        break

        if total_chars > 0:
            most_common = char_counts.most_common(1)
            if most_common:
                lang, count = most_common[0]
                confidence = count / total_chars
                if confidence > 0.3:  # –ú–∏–Ω–∏–º—É–º 30% —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                    return (lang, confidence)

        return ('unknown', 0.0)

    def _detect_by_diacritics(self, text: str) -> Tuple[str, float]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –∑–Ω–∞–∫–∞–º"""
        diacritic_counts = Counter()
        total_diacritics = 0

        for lang, diacritics in self.DIACRITICS.items():
            count = sum(1 for char in text if char in diacritics)
            if count > 0:
                diacritic_counts[lang] = count
                total_diacritics += count

        if total_diacritics >= 2:  # –ú–∏–Ω–∏–º—É–º 2 –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–∏
            most_common = diacritic_counts.most_common(1)
            if most_common:
                lang, count = most_common[0]
                confidence = min(count / 5.0, 1.0)  # –ú–∞–∫—Å 5 –¥–∏–∞–∫—Ä–∏—Ç–∏–∫ –¥–ª—è 100%
                return (lang, confidence)

        return ('unknown', 0.0)

    def _detect_by_words(self, text: str) -> Tuple[str, float]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–º —Å–ª–æ–≤–∞–º"""
        text_lower = text.lower()
        words = re.findall(r'\w+', text_lower)

        if len(words) == 0:
            return ('unknown', 0.0)

        word_counts = Counter()
        total_word_count = len(words)

        for lang, common_words in self.COMMON_WORDS.items():
            matches = sum(1 for word in words if word in common_words)
            if matches > 0:
                word_counts[lang] = matches

        if word_counts:
            # –í—ã–±—Ä–∞—Ç—å —è–∑—ã–∫ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            most_common = word_counts.most_common(1)
            if most_common:
                lang, count = most_common[0]

                # –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á—ë—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ (1-3 —Å–ª–æ–≤–∞): –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã 1 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ = –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                # –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                if total_word_count <= 3:
                    confidence = min(count * 0.4, 1.0)  # 1 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ = 40%, 2 = 80%, 3 = 100%
                else:
                    confidence = min(count / total_word_count + 0.2, 1.0)  # +20% –±–æ–Ω—É—Å

                return (lang, confidence)

        return ('unknown', 0.0)

    def detect_multiple(self, text: str, top_n: int = 3) -> list[Tuple[str, float]]:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —è–∑—ã–∫–æ–≤ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏

        Returns:
            List of (language, confidence) tuples
        """
        if not self.use_langdetect:
            # Fallback: –≤–µ—Ä–Ω—É—Ç—å –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            lang, conf = self.detect(text, with_confidence=True)
            return [(lang, conf)]

        try:
            langs = detect_langs(text)
            return [(lang.lang, lang.prob) for lang in langs[:top_n]]
        except LangDetectException:
            return [('unknown', 0.0)]

    def is_language(self, text: str, expected_lang: str, threshold: float = 0.7) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–º —è–∑—ã–∫–æ–º

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            expected_lang: –û–∂–∏–¥–∞–µ–º—ã–π —è–∑—ã–∫ (ISO 639-1)
            threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å

        Returns:
            True –µ—Å–ª–∏ —è–∑—ã–∫ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        """
        lang, confidence = self.detect(text, with_confidence=True)
        return lang == expected_lang and confidence >= threshold


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_detector = None


def get_detector() -> EnhancedLanguageDetector:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä (singleton)"""
    global _detector
    if _detector is None:
        _detector = EnhancedLanguageDetector()
    return _detector


def detect_language(text: str) -> str:
    """–ë—ã—Å—Ç—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞"""
    return get_detector().detect(text)


def detect_language_with_confidence(text: str) -> Tuple[str, float]:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —è–∑—ã–∫ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é"""
    return get_detector().detect(text, with_confidence=True)


# === –î–ï–ú–û ===
if __name__ == "__main__":
    print("üåç –î–µ–º–æ: Enhanced Language Detector")
    print("=" * 60)

    detector = EnhancedLanguageDetector()

    test_cases = [
        "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞? –ß—Ç–æ –Ω–æ–≤–æ–≥–æ?",
        "Hello, how are you doing today?",
        "Bonjour, comment allez-vous?",
        "¬°Hola! ¬øC√≥mo est√°s?",
        "Hallo, wie geht es dir?",
        "Ciao, come stai?",
        "‰Ω†Â•ΩÔºå‰Ω†Â•ΩÂêóÔºü",
        "„Åì„Çì„Å´„Å°„ÅØ„ÄÅÂÖÉÊ∞ó„Åß„Åô„ÅãÔºü",
        "ŸÖÿ±ÿ≠ÿ®ÿßÿå ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉÿü",
        "Ol√°, como voc√™ est√°?",
    ]

    print(f"\nLangdetect –¥–æ—Å—Ç—É–ø–µ–Ω: {LANGDETECT_AVAILABLE}")
    print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:\n")

    for text in test_cases:
        lang, confidence = detector.detect(text, with_confidence=True)
        confidence_bar = "‚ñà" * int(confidence * 10)
        print(f"{text[:40]:40} -> {lang:5} [{confidence_bar:10}] {confidence:.2%}")

    # –¢–µ—Å—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    print("\n" + "=" * 60)
    print("–¢–µ—Å—Ç: –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n")

    mixed_text = "Hello, this is English. Bonjour, c'est fran√ßais!"
    results = detector.detect_multiple(mixed_text, top_n=3)

    print(f"–¢–µ–∫—Å—Ç: {mixed_text}")
    print("–í–æ–∑–º–æ–∂–Ω—ã–µ —è–∑—ã–∫–∏:")
    for lang, prob in results:
        print(f"  {lang}: {prob:.2%}")

    print("\n‚úÖ –î–µ–º–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
