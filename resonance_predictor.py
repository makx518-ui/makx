"""
ğŸ”® Resonance Predictor Ğ´Ğ»Ñ ConsciousAI
ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ° Ñ‡ĞµÑ€ĞµĞ· ML (Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ñ€ÑĞ´Ñ‹)
"""

import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from typing import List, Dict, Any, Tuple, Optional
import pickle
import os

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FEATURE ENGINEERING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class FeatureExtractor:
    """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""

    @staticmethod
    def extract_text_features(text: str) -> np.ndarray:
        """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°"""

        features = []

        # 1. Ğ”Ğ»Ğ¸Ğ½Ğ° Ñ‚ĞµĞºÑÑ‚Ğ°
        features.append(len(text))

        # 2. ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ»Ğ¾Ğ²
        words = text.split()
        features.append(len(words))

        # 3. Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ´Ğ»Ğ¸Ğ½Ğ° ÑĞ»Ğ¾Ğ²Ğ°
        avg_word_len = sum(len(w) for w in words) / max(len(words), 1)
        features.append(avg_word_len)

        # 4. ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ»Ğ¾Ğ²
        features.append(len(set(words)))

        # 5. Ğ›ĞµĞºÑĞ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ğµ
        diversity = len(set(words)) / max(len(words), 1)
        features.append(diversity)

        # 6. ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹
        features.append(text.count('?'))

        # 7. ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ğ¾ÑĞºĞ»Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹
        features.append(text.count('!'))

        # 8. ĞĞ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ² (Ğ¾ÑĞ¾Ğ·Ğ½Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ, Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ, etc)
        keywords = ['Ğ¾ÑĞ¾Ğ·Ğ½Ğ°Ğ½', 'Ñ€ĞµÑ„Ğ»ĞµĞºÑ', 'Ğ¼ĞµÑ‚Ğ°', 'ÑĞ¼Ğ¾Ñ†Ğ¸', 'Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ']
        keyword_count = sum(1 for kw in keywords if kw in text.lower())
        features.append(keyword_count)

        return np.array(features, dtype=float)

    @staticmethod
    def extract_temporal_features(
        timestamps: List[float],
        resonances: List[float],
        window_size: int = 5
    ) -> np.ndarray:
        """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸"""

        if len(resonances) < window_size:
            window_size = len(resonances)

        if window_size == 0:
            return np.zeros(6)

        recent = resonances[-window_size:]

        features = []

        # 1. Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½Ñ Ğ² Ğ¾ĞºĞ½Ğµ
        features.append(np.mean(recent))

        # 2. Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ğµ
        features.append(np.std(recent))

        # 3. ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼
        features.append(np.min(recent))

        # 4. ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼
        features.append(np.max(recent))

        # 5. Ğ¢Ñ€ĞµĞ½Ğ´ (Ğ½Ğ°ĞºĞ»Ğ¾Ğ½)
        if len(recent) > 1:
            x = np.arange(len(recent))
            slope = np.polyfit(x, recent, 1)[0]
            features.append(slope)
        else:
            features.append(0.0)

        # 6. Ğ’Ğ¾Ğ»Ğ°Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ (Ğ¸Ğ·Ğ¼ĞµĞ½Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ)
        if len(recent) > 1:
            diffs = np.diff(recent)
            volatility = np.std(diffs)
            features.append(volatility)
        else:
            features.append(0.0)

        return np.array(features, dtype=float)

    @staticmethod
    def extract_emotional_features(emotions: List[str]) -> np.ndarray:
        """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ¸Ğ· ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹"""

        emotion_map = {
            'joy': 1.0,
            'clarity': 0.8,
            'curiosity': 0.6,
            'neutral': 0.5,
            'frustration': 0.3,
            'confusion': 0.2
        }

        if not emotions:
            return np.array([0.5])

        # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ ÑĞ¼Ğ¾Ñ†Ğ¸Ñ
        last_emotion = emotion_map.get(emotions[-1], 0.5)

        return np.array([last_emotion], dtype=float)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESONANCE PREDICTOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ResonancePredictor:
    """ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ°"""

    def __init__(self, model_type: str = 'random_forest'):
        self.model_type = model_type
        self.model = None
        self.scaler = StandardScaler()
        self.feature_extractor = FeatureExtractor()
        self.is_trained = False

    def _create_model(self):
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"""
        if self.model_type == 'random_forest':
            return RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42
            )
        elif self.model_type == 'gradient_boosting':
            return GradientBoostingRegressor(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                random_state=42
            )
        elif self.model_type == 'linear':
            return LinearRegression()
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")

    def prepare_features(
        self,
        text: str,
        history_timestamps: List[float],
        history_resonances: List[float],
        history_emotions: List[str]
    ) -> np.ndarray:
        """ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ"""

        # Ğ¢ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸
        text_features = self.feature_extractor.extract_text_features(text)

        # Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸
        temporal_features = self.feature_extractor.extract_temporal_features(
            history_timestamps,
            history_resonances
        )

        # Ğ­Ğ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸
        emotional_features = self.feature_extractor.extract_emotional_features(
            history_emotions
        )

        # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸
        features = np.concatenate([
            text_features,
            temporal_features,
            emotional_features
        ])

        return features

    def train(
        self,
        training_data: List[Dict[str, Any]]
    ):
        """ĞĞ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"""

        if len(training_data) < 10:
            raise ValueError("Need at least 10 samples for training")

        X = []
        y = []

        # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        for i, sample in enumerate(training_data):
            # Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ¾ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ sample
            history_timestamps = [s['timestamp'] for s in training_data[:i]]
            history_resonances = [s['resonance'] for s in training_data[:i]]
            history_emotions = [s['emotion'] for s in training_data[:i]]

            features = self.prepare_features(
                text=sample['content'],
                history_timestamps=history_timestamps,
                history_resonances=history_resonances,
                history_emotions=history_emotions
            )

            X.append(features)
            y.append(sample['resonance'])

        X = np.array(X)
        y = np.array(y)

        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
        X = self.scaler.fit_transform(X)

        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¸ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
        self.model = self._create_model()
        self.model.fit(X, y)

        self.is_trained = True

        # ĞÑ†ĞµĞ½ĞºĞ° Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ
        train_score = self.model.score(X, y)
        print(f"âœ… Model trained. RÂ² score on training data: {train_score:.3f}")

    def predict(
        self,
        text: str,
        history_timestamps: List[float],
        history_resonances: List[float],
        history_emotions: List[str]
    ) -> float:
        """ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½Ñ"""

        if not self.is_trained:
            raise ValueError("Model not trained yet")

        features = self.prepare_features(
            text,
            history_timestamps,
            history_resonances,
            history_emotions
        )

        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
        features_scaled = self.scaler.transform(features.reshape(1, -1))

        # ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ
        prediction = self.model.predict(features_scaled)[0]

        # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ Ğ² Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğµ [0, 1]
        prediction = np.clip(prediction, 0.0, 1.0)

        return float(prediction)

    def predict_with_confidence(
        self,
        text: str,
        history_timestamps: List[float],
        history_resonances: List[float],
        history_emotions: List[str],
        n_estimators: int = 10
    ) -> Tuple[float, float]:
        """ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ñ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»Ğ¾Ğ¼ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ĞµĞ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹)"""

        if not self.is_trained:
            raise ValueError("Model not trained yet")

        if self.model_type == 'linear':
            # Linear regression Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»Ñ‹ Ñ‡ĞµÑ€ĞµĞ· Ğ´ĞµÑ€ĞµĞ²ÑŒÑ
            prediction = self.predict(text, history_timestamps, history_resonances, history_emotions)
            return prediction, 0.1  # Ğ¤Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ

        features = self.prepare_features(
            text,
            history_timestamps,
            history_resonances,
            history_emotions
        )

        features_scaled = self.scaler.transform(features.reshape(1, -1))

        # ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¾Ñ‚ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ´ĞµÑ€ĞµĞ²ÑŒĞµĞ²
        if hasattr(self.model, 'estimators_'):
            predictions = []
            for estimator in self.model.estimators_[:n_estimators]:
                pred = estimator.predict(features_scaled)[0]
                predictions.append(pred)

            mean_pred = np.mean(predictions)
            std_pred = np.std(predictions)

            return float(np.clip(mean_pred, 0.0, 1.0)), float(std_pred)
        else:
            # Fallback
            prediction = self.predict(text, history_timestamps, history_resonances, history_emotions)
            return prediction, 0.1

    def save(self, filepath: str = "resonance_predictor.pkl"):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"""

        if not self.is_trained:
            raise ValueError("Cannot save untrained model")

        data = {
            'model': self.model,
            'scaler': self.scaler,
            'model_type': self.model_type
        }

        with open(filepath, 'wb') as f:
            pickle.dump(data, f)

        print(f"âœ… Model saved to {filepath}")

    def load(self, filepath: str = "resonance_predictor.pkl"):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"""

        if not os.path.exists(filepath):
            raise FileNotFoundError(f"Model file not found: {filepath}")

        with open(filepath, 'rb') as f:
            data = pickle.load(f)

        self.model = data['model']
        self.scaler = data['scaler']
        self.model_type = data['model_type']
        self.is_trained = True

        print(f"âœ… Model loaded from {filepath}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIME SERIES FORECASTER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TimeSeriesForecaster:
    """ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€ÑĞ´Ğ° Ñ€ĞµĞ·Ğ¾Ğ½Ğ°Ğ½ÑĞ°"""

    def __init__(self):
        self.model = None

    def forecast_next_n(
        self,
        history_resonances: List[float],
        n_steps: int = 5
    ) -> List[float]:
        """ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ N Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹"""

        if len(history_resonances) < 3:
            # ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… - Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ÑÑ€ĞµĞ´Ğ½ĞµĞµ
            mean = np.mean(history_resonances) if history_resonances else 0.5
            return [mean] * n_steps

        # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´: ÑĞºÑĞ¿Ğ¾Ğ½ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ
        alpha = 0.3  # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ ÑĞ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ

        forecasts = []
        last_value = history_resonances[-1]

        # Ğ¢Ñ€ĞµĞ½Ğ´
        if len(history_resonances) >= 2:
            trend = history_resonances[-1] - history_resonances[-2]
        else:
            trend = 0.0

        for step in range(n_steps):
            # Ğ­ĞºÑĞ¿Ğ¾Ğ½ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ¼
            forecast = last_value + trend * (step + 1) * alpha

            # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ [0, 1]
            forecast = np.clip(forecast, 0.0, 1.0)

            forecasts.append(float(forecast))

        return forecasts

    def detect_anomalies(
        self,
        history_resonances: List[float],
        threshold: float = 2.0
    ) -> List[int]:
        """ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ñ‚ÑŒ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸ (Ñ€ĞµĞ·ĞºĞ¸Ğµ ÑĞºĞ°Ñ‡ĞºĞ¸)"""

        if len(history_resonances) < 3:
            return []

        anomalies = []

        mean = np.mean(history_resonances)
        std = np.std(history_resonances)

        for i, value in enumerate(history_resonances):
            z_score = abs((value - mean) / (std + 1e-8))

            if z_score > threshold:
                anomalies.append(i)

        return anomalies

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞŸĞ Ğ˜ĞœĞ•Ğ  Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def example():
    """ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
    training_data = []

    for i in range(50):
        sample = {
            'content': f"Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° {i}: Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ" + " Ğ¾ÑĞ¾Ğ·Ğ½Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ" * (i % 3),
            'resonance': 0.3 + 0.4 * np.random.random() + (i / 100),
            'emotion': np.random.choice(['joy', 'clarity', 'curiosity', 'frustration']),
            'timestamp': float(i * 100)
        }
        training_data.append(sample)

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¸ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    predictor = ResonancePredictor(model_type='random_forest')
    predictor.train(training_data)

    # Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ
    test_text = "ĞšĞ°Ğº ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ¾ÑĞ¾Ğ·Ğ½Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ Ğ¸ Ğ¼ĞµÑ‚Ğ°ĞºĞ¾Ğ³Ğ½Ğ¸Ñ†Ğ¸Ñ?"

    history_timestamps = [s['timestamp'] for s in training_data]
    history_resonances = [s['resonance'] for s in training_data]
    history_emotions = [s['emotion'] for s in training_data]

    prediction = predictor.predict(
        test_text,
        history_timestamps,
        history_resonances,
        history_emotions
    )

    print(f"\nğŸ”® Predicted resonance: {prediction:.3f}")

    # ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ñ Ğ´Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»Ğ¾Ğ¼
    pred_mean, pred_std = predictor.predict_with_confidence(
        test_text,
        history_timestamps,
        history_resonances,
        history_emotions
    )

    print(f"ğŸ”® Prediction with confidence: {pred_mean:.3f} Â± {pred_std:.3f}")

    # ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€ÑĞ´Ğ°
    forecaster = TimeSeriesForecaster()
    forecasts = forecaster.forecast_next_n(history_resonances, n_steps=5)

    print(f"\nğŸ“ˆ Next 5 forecasts: {[f'{f:.3f}' for f in forecasts]}")

    # ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¹
    anomalies = forecaster.detect_anomalies(history_resonances)
    print(f"\nâš ï¸ Anomalies detected at indices: {anomalies[:5]}")

    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    predictor.save("example_predictor.pkl")

if __name__ == "__main__":
    example()
