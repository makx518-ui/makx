"""
ConsciousAI - SQLite —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è MemoryStore
–ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å SQL

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –¥–ª—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
"""

import sqlite3
import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from pathlib import Path

from .base import (
    BaseMemoryStore,
    SemanticKernel,
    SearchQuery,
    SearchResult,
    KernelType,
)
from ..utils import get_logger, MemoryStorageError, MemoryRetrievalError, handle_error

logger = get_logger(__name__)


class SQLiteMemoryStore(BaseMemoryStore):
    """
    SQLite —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–∞–º—è—Ç–∏

    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –Ω–∞ –¥–∏—Å–∫)
    - –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    - –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    - Connection pooling (–≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ)
    """

    def __init__(self, db_path: str = "semantic_memory.db"):
        self.db_path = db_path
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SQLite store: {db_path}")
        self._init_database()

    def _init_database(self):
        """–°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã –∏ –∏–Ω–¥–µ–∫—Å—ã"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # –¢–∞–±–ª–∏—Ü–∞ –∑—ë—Ä–µ–Ω
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS kernels (
                    id TEXT PRIMARY KEY,
                    essence TEXT NOT NULL,
                    concepts TEXT NOT NULL,
                    kernel_type TEXT NOT NULL,
                    importance REAL NOT NULL,
                    priority INTEGER DEFAULT 0,
                    timestamp TEXT NOT NULL,
                    activation_count INTEGER DEFAULT 0,
                    last_accessed TEXT,
                    ttl INTEGER,
                    tags TEXT,
                    source TEXT DEFAULT 'user',
                    metadata TEXT
                )
            ''')

            # –¢–∞–±–ª–∏—Ü–∞ —Å–≤—è–∑–µ–π
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS connections (
                    kernel_id TEXT NOT NULL,
                    connected_id TEXT NOT NULL,
                    strength REAL DEFAULT 1.0,
                    created_at TEXT NOT NULL,
                    PRIMARY KEY (kernel_id, connected_id),
                    FOREIGN KEY (kernel_id) REFERENCES kernels(id) ON DELETE CASCADE,
                    FOREIGN KEY (connected_id) REFERENCES kernels(id) ON DELETE CASCADE
                )
            ''')

            # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_importance ON kernels(importance DESC)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON kernels(timestamp DESC)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_type ON kernels(kernel_type)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_priority ON kernels(priority DESC)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_source ON kernels(source)')

            conn.commit()
            conn.close()
            logger.info("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
            raise MemoryStorageError(f"Cannot initialize database: {e}")

    def _get_connection(self) -> sqlite3.Connection:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.execute("PRAGMA foreign_keys = ON")
            return conn
        except Exception as e:
            raise MemoryStorageError(f"Cannot connect to database: {e}")

    @handle_error
    def save(self, kernel: SemanticKernel) -> str:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–µ—Ä–Ω–æ –≤ SQLite"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('''
                INSERT OR REPLACE INTO kernels
                (id, essence, concepts, kernel_type, importance, priority,
                 timestamp, activation_count, last_accessed, ttl, tags, source, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                kernel.id,
                kernel.essence,
                json.dumps(kernel.concepts),
                kernel.kernel_type.value,
                kernel.importance,
                kernel.priority,
                kernel.timestamp.isoformat(),
                kernel.activation_count,
                kernel.last_accessed.isoformat() if kernel.last_accessed else None,
                kernel.ttl,
                json.dumps(kernel.tags),
                kernel.source,
                json.dumps(kernel.metadata)
            ))

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–≤—è–∑–∏
            for connected_id in kernel.connections:
                cursor.execute('''
                    INSERT OR IGNORE INTO connections (kernel_id, connected_id, created_at)
                    VALUES (?, ?, ?)
                ''', (kernel.id, connected_id, datetime.now().isoformat()))

            conn.commit()
            logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∑–µ—Ä–Ω–æ: {kernel.id[:8]}...")
            return kernel.id

        finally:
            conn.close()

    @handle_error
    def get(self, kernel_id: str, activate: bool = True) -> Optional[SemanticKernel]:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–µ—Ä–Ω–æ –ø–æ ID"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('SELECT * FROM kernels WHERE id = ?', (kernel_id,))
            row = cursor.fetchone()

            if not row:
                return None

            # –ü–æ–ª—É—á–∏—Ç—å —Å–≤—è–∑–∏
            cursor.execute(
                'SELECT connected_id FROM connections WHERE kernel_id = ?',
                (kernel_id,)
            )
            connections = [r[0] for r in cursor.fetchall()]

            kernel = self._row_to_kernel(row, connections)

            # –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å
            if activate:
                kernel.activate()
                cursor.execute('''
                    UPDATE kernels
                    SET activation_count = ?, last_accessed = ?
                    WHERE id = ?
                ''', (kernel.activation_count, kernel.last_accessed.isoformat(), kernel.id))
                conn.commit()

            return kernel

        finally:
            conn.close()

    @handle_error
    def search(self, query: SearchQuery) -> List[SearchResult]:
        """–ü–æ–∏—Å–∫ –∑—ë—Ä–µ–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å SQL –∑–∞–ø—Ä–æ—Å
            sql = 'SELECT * FROM kernels WHERE 1=1'
            params = []

            # –§–∏–ª—å—Ç—Ä –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            sql += ' AND importance >= ? AND importance <= ?'
            params.extend([query.min_importance, query.max_importance])

            # –§–∏–ª—å—Ç—Ä –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
            sql += ' AND priority >= ?'
            params.append(query.min_priority)

            # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É
            if query.kernel_types:
                placeholders = ','.join('?' * len(query.kernel_types))
                sql += f' AND kernel_type IN ({placeholders})'
                params.extend([kt.value for kt in query.kernel_types])

            # –§–∏–ª—å—Ç—Ä –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É
            if query.source:
                sql += ' AND source = ?'
                params.append(query.source)

            cursor.execute(sql, params)
            rows = cursor.fetchall()

            # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            for row in rows:
                # –ü–æ–ª—É—á–∏—Ç—å —Å–≤—è–∑–∏
                cursor.execute(
                    'SELECT connected_id FROM connections WHERE kernel_id = ?',
                    (row[0],)
                )
                connections = [r[0] for r in cursor.fetchall()]
                kernel = self._row_to_kernel(row, connections)

                # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏—Å—Ç—ë–∫—à–∏–µ
                if not query.include_expired and kernel.is_expired():
                    continue

                # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–≥–∞–º
                if query.tags:
                    if not set(query.tags).intersection(set(kernel.tags)):
                        continue

                # –í—ã—á–∏—Å–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                score = self._calculate_score(query, kernel)

                if score > 0 or not query.text:  # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞, –≤—Å–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã
                    results.append(SearchResult(
                        kernel=kernel,
                        score=score,
                        match_reason=f"Relevance: {score:.2f}"
                    ))

            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
            if query.sort_by == "relevance":
                results.sort(key=lambda r: r.score, reverse=query.sort_order == "desc")
            elif query.sort_by == "importance":
                results.sort(key=lambda r: r.kernel.importance, reverse=query.sort_order == "desc")
            elif query.sort_by == "timestamp":
                results.sort(key=lambda r: r.kernel.timestamp, reverse=query.sort_order == "desc")
            elif query.sort_by == "activation":
                results.sort(key=lambda r: r.kernel.activation_count, reverse=query.sort_order == "desc")

            # –ü–∞–≥–∏–Ω–∞—Ü–∏—è
            return results[query.offset:query.offset + query.limit]

        finally:
            conn.close()

    def _calculate_score(self, query: SearchQuery, kernel: SemanticKernel) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–µ—Ä–Ω–∞ –∫ –∑–∞–ø—Ä–æ—Å—É"""
        score = 0.0

        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ essence
        if query.text:
            text_lower = query.text.lower()
            essence_lower = kernel.essence.lower()

            # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            if text_lower in essence_lower:
                score += 0.5

            # –°–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
            query_words = set(text_lower.split())
            essence_words = set(essence_lower.split())
            word_overlap = len(query_words.intersection(essence_words))
            if query_words:
                score += (word_overlap / len(query_words)) * 0.2

            # –°–ª–æ–≤–∞ –≤ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è—Ö
            kernel_concepts = set(c.lower() for c in kernel.concepts)
            concept_overlap = len(query_words.intersection(kernel_concepts))
            if query_words:
                score += (concept_overlap / len(query_words)) * 0.2

        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        if query.concepts:
            query_concepts = set(c.lower() for c in query.concepts)
            kernel_concepts = set(c.lower() for c in kernel.concepts)
            overlap = len(query_concepts.intersection(kernel_concepts))
            if query_concepts:
                score += (overlap / len(query_concepts)) * 0.3

        # –ë–æ–Ω—É—Å –∑–∞ –≤–∞–∂–Ω–æ—Å—Ç—å
        score += kernel.importance * 0.1

        return min(score, 1.0)

    @handle_error
    def delete(self, kernel_id: str) -> bool:
        """–£–¥–∞–ª–∏—Ç—å –∑–µ—Ä–Ω–æ"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('DELETE FROM kernels WHERE id = ?', (kernel_id,))
            deleted = cursor.rowcount > 0
            conn.commit()

            if deleted:
                logger.debug(f"–£–¥–∞–ª–µ–Ω–æ –∑–µ—Ä–Ω–æ: {kernel_id[:8]}...")

            return deleted

        finally:
            conn.close()

    @handle_error
    def update(self, kernel: SemanticKernel) -> bool:
        """–û–±–Ω–æ–≤–∏—Ç—å –∑–µ—Ä–Ω–æ"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('''
                UPDATE kernels SET
                    essence = ?,
                    concepts = ?,
                    kernel_type = ?,
                    importance = ?,
                    priority = ?,
                    activation_count = ?,
                    last_accessed = ?,
                    ttl = ?,
                    tags = ?,
                    source = ?,
                    metadata = ?
                WHERE id = ?
            ''', (
                kernel.essence,
                json.dumps(kernel.concepts),
                kernel.kernel_type.value,
                kernel.importance,
                kernel.priority,
                kernel.activation_count,
                kernel.last_accessed.isoformat() if kernel.last_accessed else None,
                kernel.ttl,
                json.dumps(kernel.tags),
                kernel.source,
                json.dumps(kernel.metadata),
                kernel.id
            ))

            updated = cursor.rowcount > 0
            conn.commit()
            return updated

        finally:
            conn.close()

    @handle_error
    def stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            # –í—Å–µ–≥–æ –∑—ë—Ä–µ–Ω
            cursor.execute('SELECT COUNT(*) FROM kernels')
            total_kernels = cursor.fetchone()[0]

            # –ü–æ —Ç–∏–ø–∞–º
            cursor.execute('SELECT kernel_type, COUNT(*) FROM kernels GROUP BY kernel_type')
            by_type = dict(cursor.fetchall())

            # –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å
            cursor.execute('SELECT AVG(importance) FROM kernels')
            avg_importance = cursor.fetchone()[0] or 0

            # –í—Å–µ–≥–æ —Å–≤—è–∑–µ–π
            cursor.execute('SELECT COUNT(*) FROM connections')
            total_connections = cursor.fetchone()[0]

            # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = Path(self.db_path).stat().st_size if Path(self.db_path).exists() else 0

            return {
                "total_kernels": total_kernels,
                "by_type": by_type,
                "avg_importance": avg_importance,
                "total_connections": total_connections // 2,
                "storage_size_bytes": file_size
            }

        finally:
            conn.close()

    @handle_error
    def cleanup(self, days_old: int = 30, importance_threshold: float = 0.2) -> int:
        """–û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –Ω–µ–≤–∞–∂–Ω—ã–µ –∑—ë—Ä–Ω–∞"""
        cutoff_date = datetime.now() - timedelta(days=days_old)

        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('''
                DELETE FROM kernels
                WHERE importance < ? AND timestamp < ?
            ''', (importance_threshold, cutoff_date.isoformat()))

            deleted_count = cursor.rowcount
            conn.commit()

            logger.info(f"–û—á–∏—â–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö –∑—ë—Ä–µ–Ω")
            return deleted_count

        finally:
            conn.close()

    def _row_to_kernel(self, row: tuple, connections: List[str] = None) -> SemanticKernel:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É –ë–î –≤ SemanticKernel"""
        if connections is None:
            connections = []

        return SemanticKernel(
            id=row[0],
            essence=row[1],
            concepts=json.loads(row[2]),
            kernel_type=KernelType(row[3]),
            importance=row[4],
            priority=row[5],
            timestamp=datetime.fromisoformat(row[6]),
            activation_count=row[7],
            last_accessed=datetime.fromisoformat(row[8]) if row[8] else None,
            ttl=row[9],
            tags=json.loads(row[10]) if row[10] else [],
            source=row[11],
            metadata=json.loads(row[12]) if row[12] else {},
            connections=connections
        )


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üóÑÔ∏è  –¢–µ—Å—Ç SQLite MemoryStore:\n")

    store = SQLiteMemoryStore(db_path="test_sqlite_store.db")

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–µ—Ä–Ω–æ
    kernel = SemanticKernel(
        essence="SQLite —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!",
        concepts=["sqlite", "—Ö—Ä–∞–Ω–∏–ª–∏—â–µ", "—Ç–µ—Å—Ç"],
        kernel_type=KernelType.FACT,
        importance=0.8,
        priority=5,
        tags=["test", "sqlite"]
    )

    kid = store.save(kernel)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {kid[:8]}...")

    # –ü–æ–ª—É—á–∏—Ç—å
    retrieved = store.get(kid)
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {retrieved.essence}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = store.stats()
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  –ó—ë—Ä–µ–Ω: {stats['total_kernels']}")
    print(f"  –†–∞–∑–º–µ—Ä –ë–î: {stats['storage_size_bytes']} –±–∞–π—Ç")

    print("\n‚úÖ SQLite MemoryStore —Ä–∞–±–æ—Ç–∞–µ—Ç!")
