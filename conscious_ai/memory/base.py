"""
ConsciousAI - –ë–∞–∑–æ–≤—ã–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –¥–ª—è –ø–∞–º—è—Ç–∏
–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å MemoryStore
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from enum import Enum
import uuid


class KernelType(Enum):
    """–¢–∏–ø—ã —Å–º—ã—Å–ª–æ–≤—ã—Ö –∑—ë—Ä–µ–Ω"""
    FACT = "fact"
    INSIGHT = "insight"
    DECISION = "decision"
    PATTERN = "pattern"
    GOAL = "goal"
    RELATIONSHIP = "relationship"
    PREFERENCE = "preference"
    CONTEXT = "context"
    EMOTION = "emotion"
    REFLECTION = "reflection"


@dataclass
class SemanticKernel:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–º—ã—Å–ª–æ–≤–æ–≥–æ –∑–µ—Ä–Ω–∞

    –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pydantic
    TODO: –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –Ω–∞ pydantic –≤ —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    essence: str = ""
    concepts: List[str] = field(default_factory=list)
    kernel_type: KernelType = KernelType.FACT
    importance: float = 0.5
    connections: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)
    activation_count: int = 0
    last_accessed: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    # –ù–æ–≤—ã–µ –ø–æ–ª—è –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ GPT-5
    ttl: Optional[int] = None  # Time-to-live –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    priority: int = 0  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç (0-10)
    tags: List[str] = field(default_factory=list)  # –¢–µ–≥–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    source: str = "user"  # –ò—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

    def activate(self):
        """–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –∑–µ—Ä–Ω–æ (—É–≤–µ–ª–∏—á–∏—Ç—å —Å—á—ë—Ç—á–∏–∫)"""
        self.activation_count += 1
        self.last_accessed = datetime.now()

    def is_expired(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ç—ë–∫ –ª–∏ TTL"""
        if self.ttl is None:
            return False
        elapsed = (datetime.now() - self.timestamp).total_seconds()
        return elapsed > self.ttl

    def to_dict(self) -> Dict[str, Any]:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        data = asdict(self)
        data['kernel_type'] = self.kernel_type.value
        data['timestamp'] = self.timestamp.isoformat()
        if self.last_accessed:
            data['last_accessed'] = self.last_accessed.isoformat()
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SemanticKernel':
        """–î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        data = data.copy()
        data['kernel_type'] = KernelType(data['kernel_type'])
        data['timestamp'] = datetime.fromisoformat(data['timestamp'])
        if data.get('last_accessed'):
            data['last_accessed'] = datetime.fromisoformat(data['last_accessed'])
        return cls(**data)


@dataclass
class SearchQuery:
    """
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

    –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –î–æ–±–∞–≤–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∏ scoring
    """
    text: str = ""
    concepts: List[str] = field(default_factory=list)
    kernel_types: Optional[List[KernelType]] = None
    min_importance: float = 0.0
    max_importance: float = 1.0
    min_priority: int = 0
    tags: Optional[List[str]] = None
    source: Optional[str] = None
    limit: int = 10
    offset: int = 0
    include_expired: bool = False
    sort_by: str = "relevance"  # relevance, importance, timestamp, activation
    sort_order: str = "desc"


@dataclass
class SearchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞"""
    kernel: SemanticKernel
    score: float  # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å 0-1
    match_reason: str = ""


class BaseMemoryStore(ABC):
    """
    –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–∞–º—è—Ç–∏

    –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è GPT-5: –í—Å–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å —ç—Ç–æ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

    –ú–µ—Ç–æ–¥—ã:
        save() - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–µ—Ä–Ω–æ
        get() - –ø–æ–ª—É—á–∏—Ç—å –ø–æ ID
        search() - –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É
        delete() - —É–¥–∞–ª–∏—Ç—å
        update() - –æ–±–Ω–æ–≤–∏—Ç—å
        stats() - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    """

    @abstractmethod
    def save(self, kernel: SemanticKernel) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –∑–µ—Ä–Ω–æ

        Args:
            kernel: –ó–µ—Ä–Ω–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

        Returns:
            ID —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ –∑–µ—Ä–Ω–∞

        Raises:
            MemoryStorageError: –ü—Ä–∏ –æ—à–∏–±–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        pass

    @abstractmethod
    def get(self, kernel_id: str, activate: bool = True) -> Optional[SemanticKernel]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∑–µ—Ä–Ω–æ –ø–æ ID

        Args:
            kernel_id: ID –∑–µ—Ä–Ω–∞
            activate: –£–≤–µ–ª–∏—á–∏—Ç—å —Å—á—ë—Ç—á–∏–∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–π

        Returns:
            SemanticKernel –∏–ª–∏ None

        Raises:
            MemoryRetrievalError: –ü—Ä–∏ –æ—à–∏–±–∫–µ —á—Ç–µ–Ω–∏—è
        """
        pass

    @abstractmethod
    def search(self, query: SearchQuery) -> List[SearchResult]:
        """
        –ü–æ–∏—Å–∫ –∑—ë—Ä–µ–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É

        Args:
            query: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

        Returns:
            –°–ø–∏—Å–æ–∫ SearchResult –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ score

        Raises:
            MemoryRetrievalError: –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø–æ–∏—Å–∫–∞
        """
        pass

    @abstractmethod
    def delete(self, kernel_id: str) -> bool:
        """
        –£–¥–∞–ª–∏—Ç—å –∑–µ—Ä–Ω–æ

        Args:
            kernel_id: ID –∑–µ—Ä–Ω–∞

        Returns:
            True –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω–æ, False –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        """
        pass

    @abstractmethod
    def update(self, kernel: SemanticKernel) -> bool:
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –∑–µ—Ä–Ω–æ

        Args:
            kernel: –ó–µ—Ä–Ω–æ —Å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

        Returns:
            True –µ—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–æ, False –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        """
        pass

    @abstractmethod
    def stats(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ö—Ä–∞–Ω–∏–ª–∏—â–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π:
            - total_kernels: int
            - by_type: Dict[str, int]
            - avg_importance: float
            - total_connections: int
            - storage_size_bytes: int
        """
        pass

    @abstractmethod
    def cleanup(self, days_old: int = 30, importance_threshold: float = 0.2) -> int:
        """
        –û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –Ω–µ–≤–∞–∂–Ω—ã–µ –∑—ë—Ä–Ω–∞

        Args:
            days_old: –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
            importance_threshold: –£–¥–∞–ª–∏—Ç—å —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –∑—ë—Ä–µ–Ω
        """
        pass

    def save_batch(self, kernels: List[SemanticKernel]) -> List[str]:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑—ë—Ä–µ–Ω (batch –æ–ø–µ—Ä–∞—Ü–∏—è)

        Args:
            kernels: –°–ø–∏—Å–æ–∫ –∑—ë—Ä–µ–Ω

        Returns:
            –°–ø–∏—Å–æ–∫ ID —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –∑—ë—Ä–µ–Ω

        –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ.
        –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
        """
        return [self.save(k) for k in kernels]

    def get_batch(self, kernel_ids: List[str]) -> List[SemanticKernel]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑—ë—Ä–µ–Ω (batch –æ–ø–µ—Ä–∞—Ü–∏—è)

        Args:
            kernel_ids: –°–ø–∏—Å–æ–∫ ID

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑—ë—Ä–µ–Ω
        """
        results = []
        for kid in kernel_ids:
            kernel = self.get(kid, activate=False)
            if kernel:
                results.append(kernel)
        return results

    def connect(self, kernel_id1: str, kernel_id2: str, strength: float = 1.0) -> bool:
        """
        –°–æ–∑–¥–∞—Ç—å —Å–≤—è–∑—å –º–µ–∂–¥—É –∑—ë—Ä–Ω–∞–º–∏

        Args:
            kernel_id1: ID –ø–µ—Ä–≤–æ–≥–æ –∑–µ—Ä–Ω–∞
            kernel_id2: ID –≤—Ç–æ—Ä–æ–≥–æ –∑–µ—Ä–Ω–∞
            strength: –°–∏–ª–∞ —Å–≤—è–∑–∏ (0-1)

        Returns:
            True –µ—Å–ª–∏ —Å–≤—è–∑—å —Å–æ–∑–¥–∞–Ω–∞
        """
        kernel1 = self.get(kernel_id1, activate=False)
        kernel2 = self.get(kernel_id2, activate=False)

        if not kernel1 or not kernel2:
            return False

        # –î–æ–±–∞–≤–∏—Ç—å —Å–≤—è–∑–∏ (–¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ)
        if kernel_id2 not in kernel1.connections:
            kernel1.connections.append(kernel_id2)
            self.update(kernel1)

        if kernel_id1 not in kernel2.connections:
            kernel2.connections.append(kernel_id1)
            self.update(kernel2)

        return True

    def get_connected(self, kernel_id: str) -> List[SemanticKernel]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∑—ë—Ä–Ω–∞

        Args:
            kernel_id: ID –∑–µ—Ä–Ω–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∑—ë—Ä–µ–Ω
        """
        kernel = self.get(kernel_id, activate=False)
        if not kernel:
            return []

        return self.get_batch(kernel.connections)


class InMemoryStore(BaseMemoryStore):
    """
    In-memory —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

    –ë—ã—Å—Ç—Ä–∞—è, –Ω–æ –Ω–µ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞—è
    """

    def __init__(self):
        self._storage: Dict[str, SemanticKernel] = {}

    def save(self, kernel: SemanticKernel) -> str:
        self._storage[kernel.id] = kernel
        return kernel.id

    def get(self, kernel_id: str, activate: bool = True) -> Optional[SemanticKernel]:
        kernel = self._storage.get(kernel_id)
        if kernel and activate:
            kernel.activate()
        return kernel

    def search(self, query: SearchQuery) -> List[SearchResult]:
        results = []

        for kernel in self._storage.values():
            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏—Å—Ç—ë–∫—à–∏–µ
            if not query.include_expired and kernel.is_expired():
                continue

            # –§–∏–ª—å—Ç—Ä—ã
            if kernel.importance < query.min_importance:
                continue
            if kernel.importance > query.max_importance:
                continue
            if kernel.priority < query.min_priority:
                continue
            if query.kernel_types and kernel.kernel_type not in query.kernel_types:
                continue
            if query.tags and not set(query.tags).intersection(set(kernel.tags)):
                continue
            if query.source and kernel.source != query.source:
                continue

            # –í—ã—á–∏—Å–ª–∏—Ç—å score
            score = self._calculate_score(query, kernel)
            if score > 0:
                results.append(SearchResult(
                    kernel=kernel,
                    score=score,
                    match_reason=f"Score: {score:.2f}"
                ))

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
        if query.sort_by == "relevance":
            results.sort(key=lambda r: r.score, reverse=query.sort_order == "desc")
        elif query.sort_by == "importance":
            results.sort(key=lambda r: r.kernel.importance, reverse=query.sort_order == "desc")
        elif query.sort_by == "timestamp":
            results.sort(key=lambda r: r.kernel.timestamp, reverse=query.sort_order == "desc")
        elif query.sort_by == "activation":
            results.sort(key=lambda r: r.kernel.activation_count, reverse=query.sort_order == "desc")

        # –ü–∞–≥–∏–Ω–∞—Ü–∏—è
        return results[query.offset:query.offset + query.limit]

    def _calculate_score(self, query: SearchQuery, kernel: SemanticKernel) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"""
        score = 0.0

        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        if query.text:
            text_lower = query.text.lower()
            if text_lower in kernel.essence.lower():
                score += 0.5
            # –°–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –≤ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è—Ö
            query_words = set(text_lower.split())
            kernel_concepts = set(c.lower() for c in kernel.concepts)
            overlap = len(query_words.intersection(kernel_concepts))
            if query_words:
                score += (overlap / len(query_words)) * 0.3

        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        if query.concepts:
            query_concepts = set(c.lower() for c in query.concepts)
            kernel_concepts = set(c.lower() for c in kernel.concepts)
            overlap = len(query_concepts.intersection(kernel_concepts))
            if query_concepts:
                score += (overlap / len(query_concepts)) * 0.2

        # –ë–æ–Ω—É—Å –∑–∞ –≤–∞–∂–Ω–æ—Å—Ç—å
        score += kernel.importance * 0.1

        return min(score, 1.0)

    def delete(self, kernel_id: str) -> bool:
        if kernel_id in self._storage:
            del self._storage[kernel_id]
            return True
        return False

    def update(self, kernel: SemanticKernel) -> bool:
        if kernel.id in self._storage:
            self._storage[kernel.id] = kernel
            return True
        return False

    def stats(self) -> Dict[str, Any]:
        total = len(self._storage)
        by_type = {}
        total_importance = 0.0
        total_connections = 0

        for kernel in self._storage.values():
            type_name = kernel.kernel_type.value
            by_type[type_name] = by_type.get(type_name, 0) + 1
            total_importance += kernel.importance
            total_connections += len(kernel.connections)

        return {
            "total_kernels": total,
            "by_type": by_type,
            "avg_importance": total_importance / total if total > 0 else 0,
            "total_connections": total_connections // 2,  # –î–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ
            "storage_size_bytes": 0  # In-memory
        }

    def cleanup(self, days_old: int = 30, importance_threshold: float = 0.2) -> int:
        from datetime import timedelta
        cutoff = datetime.now() - timedelta(days=days_old)
        to_delete = []

        for kid, kernel in self._storage.items():
            if kernel.importance < importance_threshold and kernel.timestamp < cutoff:
                to_delete.append(kid)

        for kid in to_delete:
            del self._storage[kid]

        return len(to_delete)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üß† –¢–µ—Å—Ç –±–∞–∑–æ–≤—ã—Ö –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π –ø–∞–º—è—Ç–∏:\n")

    # –°–æ–∑–¥–∞—Ç—å in-memory —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    store = InMemoryStore()

    # –°–æ–∑–¥–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑—ë—Ä–Ω–∞
    kernel1 = SemanticKernel(
        essence="AI —Å –º–µ—Ç–∞-—Å–æ–∑–Ω–∞–Ω–∏–µ–º",
        concepts=["ai", "–º–µ—Ç–∞", "—Å–æ–∑–Ω–∞–Ω–∏–µ"],
        kernel_type=KernelType.GOAL,
        importance=0.9,
        priority=10,
        tags=["core", "vision"]
    )

    kernel2 = SemanticKernel(
        essence="–°–º—ã—Å–ª–æ–≤–∞—è –ø–∞–º—è—Ç—å —Å–∂–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç",
        concepts=["–ø–∞–º—è—Ç—å", "—Å–∂–∞—Ç–∏–µ", "–∫–æ–Ω—Ç–µ–∫—Å—Ç"],
        kernel_type=KernelType.FACT,
        importance=0.7,
        tags=["memory"]
    )

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
    id1 = store.save(kernel1)
    id2 = store.save(kernel2)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ 2 –∑–µ—Ä–Ω–∞")

    # –ü–æ–∏—Å–∫
    query = SearchQuery(
        text="–º–µ—Ç–∞-—Å–æ–∑–Ω–∞–Ω–∏–µ",
        min_importance=0.5,
        limit=5
    )

    results = store.search(query)
    print(f"\nüîç –ü–æ–∏—Å–∫ '–º–µ—Ç–∞-—Å–æ–∑–Ω–∞–Ω–∏–µ':")
    for res in results:
        print(f"  Score: {res.score:.2f} | {res.kernel.essence}")

    # –°–≤—è–∑–∞—Ç—å
    store.connect(id1, id2)
    print(f"\nüîó –°–æ–∑–¥–∞–Ω–∞ —Å–≤—è–∑—å –º–µ–∂–¥—É –∑—ë—Ä–Ω–∞–º–∏")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = store.stats()
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  –í—Å–µ–≥–æ –∑—ë—Ä–µ–Ω: {stats['total_kernels']}")
    print(f"  –ü–æ —Ç–∏–ø–∞–º: {stats['by_type']}")
    print(f"  –°–≤—è–∑–µ–π: {stats['total_connections']}")

    print("\n‚úÖ –ë–∞–∑–æ–≤—ã–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç!")
